{"id": "1", "original_text": "GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data ## Margarita Belova Department of Electrical and Computer Engineering, Princeton University ## Jiaxin Xiao Department of Electrical and Computer Engineering, Princeton University ## Shikhar Tuli Department of Electrical and Computer Engineering, Princeton University ## Niraj K. Jha Department of Electrical and Computer Engineering, Princeton University ## Abstract Researchers have pursued neurosymbolic artificial intelligence (AI) applications for nearly three decades because symbolic components provide abstraction while neural components provide generalization. Thus, a marriage of the two components can lead to rapid advancements in AI. Yet, the field has not realized this promise since most neurosymbolic AI frameworks fail to scale. In addition, the implicit representations and approximate reasoning of purely neural approaches limit interpretability and trust. Knowledge graphs (KGs), a gold-standard representation of explicit semantic knowledge, can address the symbolic side. However, automatically deriving reliable KGs from text corpora has remained an open problem. We address the above challenges by introducing GraphMERT , a tiny graphical encoder-only model that distills high-quality KGs from unstructured text corpora and its own internal representations. Together, GraphMERT and its equivalent KG form a modular neurosymbolic stack: neural learning of abstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the first efficient and scalable neurosymbolic model to achieve state-of-the-art benchmark accuracy along with superior symbolic representations relative to baselines. More concretely, we target reliable domain-specific KGs that are both (1) factual (with provenance) and (2) valid (ontology-consistent relations with domain-appropriate semantics). When an off-the-shelf large language model (LLM), e.g., Qwen3-32B, generates domainspecific KGs, it falls short on the reliability front due to prompt sensitivity, shallow domain expertise, and hallucinated relations. Thus, practitioners should avoid employing LLMgenerated KGs in high-stakes domains, e.g., medicine, law, business, education, etc. On text obtained from PubMed papers related to diabetes, our KG extraction pipeline with a small 80M-parameter GraphMERT yields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG that achieves only a 40.2% FActScore. The GraphMERT -extracted KG also achieves a significantly higher ValidityScore of 68.8%, compared to an LLM-generated baseline (43.0%), demonstrating its ability to preserve ontology alignment. Finally, human experts can edit and audit the extracted KGs, further increasing their reliability. This is nearly impossible with purely-neural representations. Hence, GraphMERT enables efficient, scalable, transparent (interpretable and explainable), attributable (with provenance), accountable (with governance), editable, auditable, and continually improvable state-of-the-art neurosymbolic AI. Index Terms : Hallucinations, interpretability, knowledge graphs, language models, neurosymbolic methods, retrieval-augmented generation. margarita.bel@princeton.edu jx0800@princeton.edu stuli@alumni.princeton.edu jha@princeton.edu ## 1 Introduction Artificial intelligence (AI) has long oscillated between two dominant paradigms: symbolic reasoning and neural learning (Shavlik et al., 1991; d'Avila Garcez et al., 2002). Symbolic systems excel at explicit (rulebased) inference, providing interpretability and strong exact reasoning. This assumes precise and consistent symbolic abstractions. However, such systems struggle with noisy or ambiguous data. Neural approaches, by contrast, thrive on large-scale and general-purpose pattern recognition, often outperforming hand-coded explicit representations (Sutton, 2019). Nevertheless, neural networks operate as black boxes, offering little transparency in their decision-making (Sharkey et al., 2025). Their representations are approximate: ambiguous, difficult to control, and not grounded in explicit rules. Thus, each paradigm, taken alone, has critical gaps. Neurosymbolic AI is a synthesis of the two paradigms, aiming to combine the flexibility of neural models with the rigor and interpretability of symbolic systems. By uniting these complementary strengths, it opens up a path toward systems capable of both scalable learning and sound reasoning - a longstanding ambition of the field (Garcez &amp; Lamb, 2023; Towell, 1994; d'Avila Garcez et al., 2019). Large language models (LLMs) have generated enormous excitement, but their reasoning is ultimately probabilistic and often unable to perform causal inference, opaque to humans, and prone to hallucinations, especially during multi-step reasoning (Marcus, 2018; Ji et al., 2023). Their opaqueness raises serious concerns about whether such models can be trusted (von Eschenbach, 2021; Alzubaidi et al., 2023). LLMs trained on general text corpora may also fail to adapt to specialized domains or incorporate new knowledge without undergoing expensive retraining (Zhao et al., 2025). These limitations highlight the need for external, explicit sources of factual grounding in high-stakes use cases (Fan et al., 2024). Unifying knowledge graphs (KGs) with LLMs could help overcome some of these limitations, as KGs offer a natural complement (Ibrahim et al., 2024). By encoding knowledge in a structured, symbolic form of head-relation-tail triples with explicit and verifiable relations, KGs offer interpretability, auditability, and domain-specific depth that LLMs lack (Pan et al., 2023a). Thus, KGs can guide LLM inference and enable robust evolution of background knowledge, while LLMs contribute flexible reasoning, efficient handling of ambiguity through approximate inference, and serve as a natural language interface (Pan et al., 2023b). This synergy can enable KG-guided exploration and learning, support agentic workflows driven by interaction with an editable knowledge base, and enhance the trustworthiness of LLMs in high-stakes application domains by reinforcing factuality and enabling immediate knowledge updates. Yet, constructing a KG from scratch in a new domain is a notoriously arduous task (Zhong et al., 2023; Ji et al., 2022). The process typically involves cleaning and pre-processing heterogeneous data, multi-step knowledge acquisition, and post-processing. Ensuring that the resulting KG is reliable and factual is even more challenging, often requiring extensive manual inspection and crowdsourcing (Wang et al., 2021). In fields where no ground-truth KG or domain-specific benchmarks exist, this task becomes infeasible without expert intervention. This makes existing approaches unscalable. Given these obstacles, we propose characteristics that an effective KG construction method should provide: 1. Factuality and provenance: Triples grounded in source text with verifiable citations. 2. Validity: Adherence to ontological schema constraints, appropriate term granularity, and domaincorrect relations. 3. Automation: End-to-end extraction without expert oversight; usable by non-specialists. 4. Scalability: Robust performance as data volume and compute grow. 5. Domain generality: Principles that transfer across subject areas. 6. Global integration: Cross-document linking of concepts, not just within local spans. We refer to KGs that are both factual and valid as reliable ; hence, we classify methods that produce factual and valid triples as reliable. Recently, KG generation with decoder-based LLMs has become the most widely used and studied method (Xu et al., 2024), especially for commonsense knowledge extraction (West et al., 2022). Nonetheless, we demonstrate that LLMs are unable to construct reliable domain-specific KGs. The factuality challenge faced by LLMs intersects with several other pressing issues, such as hallucinations, outdated knowledge, and lack of depth in given domains (e.g., in health, law, and finance applications) (Wang et al., 2025a). Despite their ease of use, versatility, broad knowledge coverage, and impressive general-purpose language skills (Minaee et al., 2025), LLMs as KG constructors are known to underperform on domain-specific datasets (Zhu et al., 2024) and are susceptible to domain-irrelevant noise in the context (Chen et al., 2024). For example, Yang et al. (2025) highlight limitations of LLM-based KG creation in handling domain-specific medical terms and encoding context-dependent relations beyond generic predicates. Hallucinations further restrict text-generative approaches from producing fully accurate and trustworthy domain-specific KGs without human validation (Ghanem &amp; Cruz, 2025), often resulting in inclusion of fabricated facts in the KG (Huang et al., 2025a). Since LLMs are oblivious to their training sources (Khalifa et al., 2024), promptbased KG distillation from an LLM's weights does not provide source attribution and obfuscates knowledge provenance, thus casting doubts on its reliability (Pan et al., 2023a). Fine-tuned models demonstrate significantly higher accuracy compared to zero-shot and few-shot prompting, exhibit enhanced extraction fidelity in the domains they are adapted to, and often produce much fewer hallucinated facts (Ghanem &amp; Cruz, 2025). Without fine-tuning, LLMs are inclined to leak general knowledge obtained through pretraining, potentially overlooking vital domain-specific information. This calls into question their usefulness in specialized domains (Yang et al., 2023). In addition, because LLMs are highly prompt-dependent, their behavior can only be steered through prompting; without fine-tuning, prompted outputs may not align with task requirements. However, fine-tuning of LLMs requires labeled training data, negatively impacts generalization in heterogeneous domains, and ultimately reduces adaptability to knowledge domains that differ from the fine-tuning set (Ghanem &amp; Cruz, 2025). Finally, KG extraction from text corpora with off-the-shelf LLMs is not global in the sense that the extracted triples are confined to a single text chunk presented in the context window. Such triples are often local, i.e, they may only reflect a spurious correlation based on co-occurrence of various terms, as opposed to global triples obtained from the larger text corpora that can generally be deemed as universal facts. Extending context length is not a solution to countering this problem because it is known to degrade output quality. In particular, hallucinations become more frequent in this situation (An et al., 2024), thus affecting the model's capability to harness information from lengthy input contexts. The current approaches fail to meet all six requirements for KGs we listed above (Hofer et al., 2024). A method that satisfies all six could unlock numerous downstream applications. However, a reliable KG can be extracted only if the data are of high quality (Rejeleene et al., 2024; Geiger et al., 2020; Wang et al., 2023). Yet, such data are scarce. This leads us to the central question: ## How can we build a reliable domain-specific KG from limited high-quality sources? To address this challenge, we propose a novel framework, GraphMERT (Graphical Multidirectional Encoder Representations from Transformers), for reliable KG extraction from small high-quality domain-specific data. GraphMERT relies on an encoder-only transformer that distills a symbolic representation from its weights. It jointly learns cross-modal representations: semantic - from a small expert-curated initial seed KG, and syntactic - from unstructured sentence-level text by minimizing the standard masked language modeling (MLM) and the proposed masked node modeling (MNM) losses. We automatically extract a KG that captures factual knowledge by training GraphMERT on high-quality texts with a small seed KG (e.g., 100+ triples per relation). The framework is domain-agnostic and only requires a seed KG along with a small, high-quality, domain-specific dataset (e.g., ∼ 100M tokens). To the best of our knowledge, GraphMERT -powered KG extraction is the first framework that possesses all six characteristics of an effective KG mentioned earlier: 1. Factuality and provenance: We implement triple extraction at the sentence level. One can trace back each triple to its source sequence, thus supporting knowledge provenance. FActScore, which quantifies the factuality of a KG (more details in Sec. 6.2), for the GraphMERT -generated KG (69.8%) is much higher than that of an LLM-generated one (40.2%). 2. Validity: The resulting KG preserves the relation usage patterns imposed by the ontological structure of the seed KG, which enhances the validity of the relations in the extracted KG relative to the LLMextracted baseline KG. ValidityScore, which quantifies the ontological alignment of a KG (more details in Sec. 6.2), for our KG (68.8%) is much higher than that of the baseline (43.0%). 3. Automation: It does not need manual feature selection, rule handcrafting, or human experts in the loop. It leverages a neural-to-symobolic converter, i.e., GraphMERT , to automatically and reliably generate a KG. 4. Scalability: We obtain training data only from credible sources and the compact GraphMERT (with just 80M parameters) eliminates the need for pretraining on large unverified text, making the approach much more practical than employing expensive LLMs (with billions or trillions of parameters). It can be scaled when provided with more data and given extra compute resources. 5. Domain ge", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "GraphMERT", "Relation": "distills", "Tail": "knowledge graphs"}, {"Head": "GraphMERT", "Relation": "is implemented as", "Tail": "encoder-only transformer"}, {"Head": "GraphMERT", "Relation": "leverages", "Tail": "masked language modeling"}, {"Head": "GraphMERT", "Relation": "leverages", "Tail": "masked node modeling"}, {"Head": "GraphMERT", "Relation": "is trained on", "Tail": "high-quality domain-specific texts"}, {"Head": "GraphMERT", "Relation": "is trained with", "Tail": "seed KG"}, {"Head": "GraphMERT", "Relation": "produces", "Tail": "factual and valid domain-specific KG"}, {"Head": "GraphMERT-extracted KG", "Relation": "achieves", "Tail": "69.8% FActScore"}, {"Head": "32B-parameter LLM baseline", "Relation": "achieves", "Tail": "40.2% FActScore"}, {"Head": "GraphMERT-extracted KG", "Relation": "achieves", "Tail": "68.8% ValidityScore"}, {"Head": "LLM-generated KG baseline", "Relation": "achieves", "Tail": "43.0% ValidityScore"}, {"Head": "LLMs (e.g., Qwen3-32B)", "Relation": "suffer from", "Tail": "prompt sensitivity and hallucinations"}, {"Head": "LLMs", "Relation": "lack", "Tail": "provenance for generated facts"}, {"Head": "Knowledge graphs", "Relation": "provide", "Tail": "interpretability and provenance"}, {"Head": "Seed KG", "Relation": "imposes", "Tail": "ontological relation usage patterns"}, {"Head": "GraphMERT framework", "Relation": "requires", "Tail": "small seed KG and ∼100M tokens"}, {"Head": "GraphMERT (80M parameters)", "Relation": "is more efficient than", "Tail": "large LLMs (billions of parameters)"}, {"Head": "Human experts", "Relation": "can", "Tail": "edit and audit extracted KGs"}, {"Head": "Neurosymbolic AI stack", "Relation": "is formed by", "Tail": "GraphMERT and its equivalent KG"}, {"Head": "GraphMERT + KG", "Relation": "enables", "Tail": "attributable, editable, and auditable AI"}], "entity_relation_output": "[{\"Head\": \"GraphMERT\", \"Relation\": \"distills\", \"Tail\": \"knowledge graphs\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"is implemented as\", \"Tail\": \"encoder-only transformer\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"leverages\", \"Tail\": \"masked language modeling\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"leverages\", \"Tail\": \"masked node modeling\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"is trained on\", \"Tail\": \"high-quality domain-specific texts\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"is trained with\", \"Tail\": \"seed KG\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"produces\", \"Tail\": \"factual and valid domain-specific KG\"}, {\"Head\": \"GraphMERT-extracted KG\", \"Relation\": \"achieves\", \"Tail\": \"69.8% FActScore\"}, {\"Head\": \"32B-parameter LLM baseline\", \"Relation\": \"achieves\", \"Tail\": \"40.2% FActScore\"}, {\"Head\": \"GraphMERT-extracted KG\", \"Relation\": \"achieves\", \"Tail\": \"68.8% ValidityScore\"}, {\"Head\": \"LLM-generated KG baseline\", \"Relation\": \"achieves\", \"Tail\": \"43.0% ValidityScore\"}, {\"Head\": \"LLMs (e.g., Qwen3-32B)\", \"Relation\": \"suffer from\", \"Tail\": \"prompt sensitivity and hallucinations\"}, {\"Head\": \"LLMs\", \"Relation\": \"lack\", \"Tail\": \"provenance for generated facts\"}, {\"Head\": \"Knowledge graphs\", \"Relation\": \"provide\", \"Tail\": \"interpretability and provenance\"}, {\"Head\": \"Seed KG\", \"Relation\": \"imposes\", \"Tail\": \"ontological relation usage patterns\"}, {\"Head\": \"GraphMERT framework\", \"Relation\": \"requires\", \"Tail\": \"small seed KG and ∼100M tokens\"}, {\"Head\": \"GraphMERT (80M parameters)\", \"Relation\": \"is more efficient than\", \"Tail\": \"large LLMs (billions of parameters)\"}, {\"Head\": \"Human experts\", \"Relation\": \"can\", \"Tail\": \"edit and audit extracted KGs\"}, {\"Head\": \"Neurosymbolic AI stack\", \"Relation\": \"is formed by\", \"Tail\": \"GraphMERT and its equivalent KG\"}, {\"Head\": \"GraphMERT + KG\", \"Relation\": \"enables\", \"Tail\": \"attributable, editable, and auditable AI\"}]", "event_entity_dict": [{"Event": "Researchers have pursued neurosymbolic artificial intelligence (AI) applications for nearly three decades because symbolic components provide abstraction while neural components provide generalization.", "Entity": ["Researchers", "neurosymbolic artificial intelligence (AI) applications", "symbolic components", "neural components"]}, {"Event": "A marriage of the two components can lead to rapid advancements in AI.", "Entity": ["symbolic components", "neural components", "AI"]}, {"Event": "Most neurosymbolic AI frameworks fail to scale.", "Entity": ["neurosymbolic AI frameworks"]}, {"Event": "The implicit representations and approximate reasoning of purely neural approaches limit interpretability and trust.", "Entity": ["implicit representations", "approximate reasoning", "purely neural approaches", "interpretability", "trust"]}, {"Event": "Knowledge graphs (KGs), a gold-standard representation of explicit semantic knowledge, can address the symbolic side.", "Entity": ["Knowledge graphs (KGs)", "explicit semantic knowledge", "symbolic side"]}, {"Event": "Automatically deriving reliable KGs from text corpora has remained an open problem.", "Entity": ["automatic KG derivation", "reliable KGs", "text corpora"]}, {"Event": "We address the above challenges by introducing GraphMERT, a tiny graphical encoder-only model that distills high-quality KGs from unstructured text corpora and its own internal representations.", "Entity": ["We", "GraphMERT", "graphical encoder-only model", "high-quality KGs", "unstructured text corpora", "internal representations"]}, {"Event": "GraphMERT and its equivalent KG form a modular neurosymbolic stack: neural learning of abstractions; symbolic KGs for verifiable reasoning.", "Entity": ["GraphMERT", "equivalent KG", "modular neurosymbolic stack", "neural learning", "symbolic KGs"]}, {"Event": "GraphMERT + KG is the first efficient and scalable neurosymbolic model to achieve state-of-the-art benchmark accuracy along with superior symbolic representations relative to baselines.", "Entity": ["GraphMERT + KG", "neurosymbolic model", "benchmark accuracy", "symbolic representations", "baselines"]}, {"Event": "We target reliable domain-specific KGs that are both factual (with provenance) and valid (ontology-consistent relations with domain-appropriate semantics).", "Entity": ["We", "reliable domain-specific KGs", "factual (with provenance)", "valid (ontology-consistent relations)"]}, {"Event": "When an off-the-shelf large language model (LLM), e.g., Qwen3-32B, generates domain-specific KGs, it falls short on the reliability front due to prompt sensitivity, shallow domain expertise, and hallucinated relations.", "Entity": ["off-the-shelf large language model (LLM)", "Qwen3-32B", "domain-specific KGs", "prompt sensitivity", "shallow domain expertise", "hallucinated relations"]}, {"Event": "Practitioners should avoid employing LLM-generated KGs in high-stakes domains, e.g., medicine, law, business, education.", "Entity": ["Practitioners", "LLM-generated KGs", "high-stakes domains", "medicine", "law", "business", "education"]}, {"Event": "On text obtained from PubMed papers related to diabetes, our KG extraction pipeline with a small 80M-parameter GraphMERT yields a KG with a 69.8% FActScore.", "Entity": ["text from PubMed papers related to diabetes", "KG extraction pipeline", "80M-parameter GraphMERT", "KG", "69.8% FActScore"]}, {"Event": "A 32B-parameter baseline LLM yields a KG that achieves only a 40.2% FActScore.", "Entity": ["32B-parameter baseline LLM", "KG", "40.2% FActScore"]}, {"Event": "The GraphMERT-extracted KG also achieves a significantly higher ValidityScore of 68.8% compared to an LLM-generated baseline (43.0%).", "Entity": ["GraphMERT-extracted KG", "ValidityScore 68.8%", "LLM-generated baseline", "43.0%"]}, {"Event": "Human experts can edit and audit the extracted KGs, further increasing their reliability.", "Entity": ["Human experts", "extracted KGs", "edit", "audit", "reliability"]}, {"Event": "This is nearly impossible with purely-neural representations.", "Entity": ["purely-neural representations", "editing and auditing capability"]}, {"Event": "GraphMERT enables efficient, scalable, transparent, attributable, accountable, editable, auditable, and continually improvable state-of-the-art neurosymbolic AI.", "Entity": ["GraphMERT", "neurosymbolic AI", "efficient", "scalable", "transparent", "attributable", "accountable", "editable", "auditable", "continually improvable"]}, {"Event": "Artificial intelligence (AI) has long oscillated between two dominant paradigms: symbolic reasoning and neural learning.", "Entity": ["Artificial intelligence (AI)", "symbolic reasoning", "neural learning"]}, {"Event": "Symbolic systems excel at explicit (rule-based) inference, providing interpretability and strong exact reasoning, but they struggle with noisy or ambiguous data.", "Entity": ["Symbolic systems", "explicit inference", "interpretability", "exact reasoning", "noisy or ambiguous data"]}, {"Event": "Neural approaches thrive on large-scale and general-purpose pattern recognition, often outperforming hand-coded explicit representations.", "Entity": ["Neural approaches", "large-scale pattern recognition", "hand-coded explicit representations"]}, {"Event": "Neural networks operate as black boxes, offering little transparency in their decision-making and producing approximate, ambiguous, and difficult-to-control representations.", "Entity": ["Neural networks", "black boxes", "transparency", "approximate representations"]}, {"Event": "Neurosymbolic AI is a synthesis that aims to combine the flexibility of neural models with the rigor and interpretability of symbolic systems.", "Entity": ["Neurosymbolic AI", "neural models", "symbolic systems", "flexibility", "rigor", "interpretability"]}, {"Event": "Large language models (LLMs) have generated enormous excitement, but their reasoning is probabilistic, often unable to perform causal inference, opaque to humans, and prone to hallucinations.", "Entity": ["Large language models (LLMs)", "probabilistic reasoning", "causal inference", "opacity", "hallucinations"]}, {"Event": "LLMs trained on general text corpora may fail to adapt to specialized domains or incorporate new knowledge without expensive retraining.", "Entity": ["LLMs", "general text corpora", "specialized domains", "new knowledge", "expensive retraining"]}, {"Event": "These limitations highlight the need for external, explicit sources of factual grounding in high-stakes use cases.", "Entity": ["limitations of LLMs", "external explicit sources", "factual grounding", "high-stakes use cases"]}, {"Event": "Unifying knowledge graphs (KGs) with LLMs could help overcome some of these limitations because KGs encode knowledge in structured, verifiable head-relation-tail triples.", "Entity": ["Knowledge graphs (KGs)", "LLMs", "structured head-relation-tail triples", "verifiable knowledge"]}, {"Event": "KGs offer interpretability, auditability, and domain-specific depth that LLMs lack and can guide LLM inference while LLMs provide flexible reasoning and a natural language interface.", "Entity": ["KGs", "interpretability", "auditability", "domain-specific depth", "LLMs", "flexible reasoning", "natural language interface"]}, {"Event": "Constructing a KG from scratch in a new domain is a notoriously arduous task involving cleaning, preprocessing, multi-step knowledge acquisition, and post-processing.", "Entity": ["Constructing a KG", "new domain", "cleaning", "preprocessing", "multi-step knowledge acquisition", "post"]}], "event_entity_output": "[{\"Event\": \"Researchers have pursued neurosymbolic artificial intelligence (AI) applications for nearly three decades because symbolic components provide abstraction while neural components provide generalization.\", \"Entity\": [\"Researchers\", \"neurosymbolic artificial intelligence (AI) applications\", \"symbolic components\", \"neural components\"]}, {\"Event\": \"A marriage of the two components can lead to rapid advancements in AI.\", \"Entity\": [\"symbolic components\", \"neural components\", \"AI\"]}, {\"Event\": \"Most neurosymbolic AI frameworks fail to scale.\", \"Entity\": [\"neurosymbolic AI frameworks\"]}, {\"Event\": \"The implicit representations and approximate reasoning of purely neural approaches limit interpretability and trust.\", \"Entity\": [\"implicit representations\", \"approximate reasoning\", \"purely neural approaches\", \"interpretability\", \"trust\"]}, {\"Event\": \"Knowledge graphs (KGs), a gold-standard representation of explicit semantic knowledge, can address the symbolic side.\", \"Entity\": [\"Knowledge graphs (KGs)\", \"explicit semantic knowledge\", \"symbolic side\"]}, {\"Event\": \"Automatically deriving reliable KGs from text corpora has remained an open problem.\", \"Entity\": [\"automatic KG derivation\", \"reliable KGs\", \"text corpora\"]}, {\"Event\": \"We address the above challenges by introducing GraphMERT, a tiny graphical encoder-only model that distills high-quality KGs from unstructured text corpora and its own internal representations.\", \"Entity\": [\"We\", \"GraphMERT\", \"graphical encoder-only model\", \"high-quality KGs\", \"unstructured text corpora\", \"internal representations\"]}, {\"Event\": \"GraphMERT and its equivalent KG form a modular neurosymbolic stack: neural learning of abstractions; symbolic KGs for verifiable reasoning.\", \"Entity\": [\"GraphMERT\", \"equivalent KG\", \"modular neurosymbolic stack\", \"neural learning\", \"symbolic KGs\"]}, {\"Event\": \"GraphMERT + KG is the first efficient and scalable neurosymbolic model to achieve state-of-the-art benchmark accuracy along with superior symbolic representations relative to baselines.\", \"Entity\": [\"GraphMERT + KG\", \"neurosymbolic model\", \"benchmark accuracy\", \"symbolic representations\", \"baselines\"]}, {\"Event\": \"We target reliable domain-specific KGs that are both factual (with provenance) and valid (ontology-consistent relations with domain-appropriate semantics).\", \"Entity\": [\"We\", \"reliable domain-specific KGs\", \"factual (with provenance)\", \"valid (ontology-consistent relations)\"]}, {\"Event\": \"When an off-the-shelf large language model (LLM), e.g., Qwen3-32B, generates domain-specific KGs, it falls short on the reliability front due to prompt sensitivity, shallow domain expertise, and hallucinated relations.\", \"Entity\": [\"off-the-shelf large language model (LLM)\", \"Qwen3-32B\", \"domain-specific KGs\", \"prompt sensitivity\", \"shallow domain expertise\", \"hallucinated relations\"]}, {\"Event\": \"Practitioners should avoid employing LLM-generated KGs in high-stakes domains, e.g., medicine, law, business, education.\", \"Entity\": [\"Practitioners\", \"LLM-generated KGs\", \"high-stakes domains\", \"medicine\", \"law\", \"business\", \"education\"]}, {\"Event\": \"On text obtained from PubMed papers related to diabetes, our KG extraction pipeline with a small 80M-parameter GraphMERT yields a KG with a 69.8% FActScore.\", \"Entity\": [\"text from PubMed papers related to diabetes\", \"KG extraction pipeline\", \"80M-parameter GraphMERT\", \"KG\", \"69.8% FActScore\"]}, {\"Event\": \"A 32B-parameter baseline LLM yields a KG that achieves only a 40.2% FActScore.\", \"Entity\": [\"32B-parameter baseline LLM\", \"KG\", \"40.2% FActScore\"]}, {\"Event\": \"The GraphMERT-extracted KG also achieves a significantly higher ValidityScore of 68.8% compared to an LLM-generated baseline (43.0%).\", \"Entity\": [\"GraphMERT-extracted KG\", \"ValidityScore 68.8%\", \"LLM-generated baseline\", \"43.0%\"]}, {\"Event\": \"Human experts can edit and audit the extracted KGs, further increasing their reliability.\", \"Entity\": [\"Human experts\", \"extracted KGs\", \"edit\", \"audit\", \"reliability\"]}, {\"Event\": \"This is nearly impossible with purely-neural representations.\", \"Entity\": [\"purely-neural representations\", \"editing and auditing capability\"]}, {\"Event\": \"GraphMERT enables efficient, scalable, transparent, attributable, accountable, editable, auditable, and continually improvable state-of-the-art neurosymbolic AI.\", \"Entity\": [\"GraphMERT\", \"neurosymbolic AI\", \"efficient\", \"scalable\", \"transparent\", \"attributable\", \"accountable\", \"editable\", \"auditable\", \"continually improvable\"]}, {\"Event\": \"Artificial intelligence (AI) has long oscillated between two dominant paradigms: symbolic reasoning and neural learning.\", \"Entity\": [\"Artificial intelligence (AI)\", \"symbolic reasoning\", \"neural learning\"]}, {\"Event\": \"Symbolic systems excel at explicit (rule-based) inference, providing interpretability and strong exact reasoning, but they struggle with noisy or ambiguous data.\", \"Entity\": [\"Symbolic systems\", \"explicit inference\", \"interpretability\", \"exact reasoning\", \"noisy or ambiguous data\"]}, {\"Event\": \"Neural approaches thrive on large-scale and general-purpose pattern recognition, often outperforming hand-coded explicit representations.\", \"Entity\": [\"Neural approaches\", \"large-scale pattern recognition\", \"hand-coded explicit representations\"]}, {\"Event\": \"Neural networks operate as black boxes, offering little transparency in their decision-making and producing approximate, ambiguous, and difficult-to-control representations.\", \"Entity\": [\"Neural networks\", \"black boxes\", \"transparency\", \"approximate representations\"]}, {\"Event\": \"Neurosymbolic AI is a synthesis that aims to combine the flexibility of neural models with the rigor and interpretability of symbolic systems.\", \"Entity\": [\"Neurosymbolic AI\", \"neural models\", \"symbolic systems\", \"flexibility\", \"rigor\", \"interpretability\"]}, {\"Event\": \"Large language models (LLMs) have generated enormous excitement, but their reasoning is probabilistic, often unable to perform causal inference, opaque to humans, and prone to hallucinations.\", \"Entity\": [\"Large language models (LLMs)\", \"probabilistic reasoning\", \"causal inference\", \"opacity\", \"hallucinations\"]}, {\"Event\": \"LLMs trained on general text corpora may fail to adapt to specialized domains or incorporate new knowledge without expensive retraining.\", \"Entity\": [\"LLMs\", \"general text corpora\", \"specialized domains\", \"new knowledge\", \"expensive retraining\"]}, {\"Event\": \"These limitations highlight the need for external, explicit sources of factual grounding in high-stakes use cases.\", \"Entity\": [\"limitations of LLMs\", \"external explicit sources\", \"factual grounding\", \"high-stakes use cases\"]}, {\"Event\": \"Unifying knowledge graphs (KGs) with LLMs could help overcome some of these limitations because KGs encode knowledge in structured, verifiable head-relation-tail triples.\", \"Entity\": [\"Knowledge graphs (KGs)\", \"LLMs\", \"structured head-relation-tail triples\", \"verifiable knowledge\"]}, {\"Event\": \"KGs offer interpretability, auditability, and domain-specific depth that LLMs lack and can guide LLM inference while LLMs provide flexible reasoning and a natural language interface.\", \"Entity\": [\"KGs\", \"interpretability\", \"auditability\", \"domain-specific depth\", \"LLMs\", \"flexible reasoning\", \"natural language interface\"]}, {\"Event\": \"Constructing a KG from scratch in a new domain is a notoriously arduous task involving cleaning, preprocessing, multi-step knowledge acquisition, and post-processing.\", \"Entity\": [\"Constructing a KG\", \"new domain\", \"cleaning\", \"preprocessing\", \"multi-step knowledge acquisition\", \"post\"]}]", "event_relation_dict": [{"Head": "Neurosymbolic AI synthesizes neural learning with symbolic reasoning", "Relation": "because", "Tail": "uniting the two paradigms combines flexibility with interpretability and sound reasoning"}, {"Head": "Most neurosymbolic AI frameworks fail to scale", "Relation": "because", "Tail": "implicit representations and approximate reasoning of purely neural approaches limit interpretability and trust"}, {"Head": "Automatically deriving reliable KGs from text corpora has remained an open problem", "Relation": "because", "Tail": "existing approaches do not meet the requirements for factuality, validity, automation, scalability, domain generality, and global integration"}, {"Head": "GraphMERT distills high-quality KGs from unstructured text and internal representations", "Relation": "to the same time", "Tail": "GraphMERT and its equivalent KG form a modular neurosymbolic stack"}, {"Head": "GraphMERT + KG achieves state-of-the-art benchmark accuracy and superior symbolic representations", "Relation": "as a result", "Tail": "GraphMERT is the first efficient and scalable neurosymbolic model to do so relative to baselines"}, {"Head": "Off-the-shelf LLMs generate domain-specific KGs that fall short on reliability", "Relation": "because", "Tail": "LLMs suffer from prompt sensitivity, shallow domain expertise, and hallucinated relations"}, {"Head": "An 80M-parameter GraphMERT yields a KG with a 69.8% FActScore on PubMed diabetes text", "Relation": "as a result", "Tail": "a 32B-parameter baseline LLM yields a KG with only a 40.2% FActScore"}, {"Head": "The GraphMERT-extracted KG achieves a higher ValidityScore than the LLM baseline", "Relation": "because", "Tail": "GraphMERT preserves ontology alignment and relation usage patterns from the seed KG"}, {"Head": "Human experts can edit and audit the extracted KGs", "Relation": "as a result", "Tail": "the reliability of the extracted KGs can be further increased"}, {"Head": "LLMs are oblivious to their training sources", "Relation": "because", "Tail": "prompt-based KG distillation from an LLM's weights does not provide source attribution"}, {"Head": "Fine-tuned models demonstrate higher accuracy and fewer hallucinations", "Relation": "because", "Tail": "fine-tuning adapts models to the domains they are trained on"}, {"Head": "Fine-tuning requires labeled training data", "Relation": "as a result", "Tail": "fine-tuning negatively impacts generalization and reduces adaptability to other knowledge domains"}, {"Head": "KG extraction from off-the-shelf LLMs is confined to a single context window", "Relation": "as a result", "Tail": "extracted triples are often local and may reflect spurious correlations rather than global facts"}, {"Head": "Extending context length degrades output quality", "Relation": "as a result", "Tail": "hallucinations become more frequent and the model's ability to harness lengthy input degrades"}, {"Head": "High-quality data are scarce", "Relation": "as a result", "Tail": "building a reliable domain-specific KG from limited high-quality sources becomes the central question"}, {"Head": "GraphMERT jointly learns semantic representations from a seed KG and syntactic representations from text", "Relation": "because", "Tail": "it minimizes masked language modeling and masked node modeling losses"}], "event_relation_output": "[{\"Head\": \"Neurosymbolic AI synthesizes neural learning with symbolic reasoning\", \"Relation\": \"because\", \"Tail\": \"uniting the two paradigms combines flexibility with interpretability and sound reasoning\"}, {\"Head\": \"Most neurosymbolic AI frameworks fail to scale\", \"Relation\": \"because\", \"Tail\": \"implicit representations and approximate reasoning of purely neural approaches limit interpretability and trust\"}, {\"Head\": \"Automatically deriving reliable KGs from text corpora has remained an open problem\", \"Relation\": \"because\", \"Tail\": \"existing approaches do not meet the requirements for factuality, validity, automation, scalability, domain generality, and global integration\"}, {\"Head\": \"GraphMERT distills high-quality KGs from unstructured text and internal representations\", \"Relation\": \"to the same time\", \"Tail\": \"GraphMERT and its equivalent KG form a modular neurosymbolic stack\"}, {\"Head\": \"GraphMERT + KG achieves state-of-the-art benchmark accuracy and superior symbolic representations\", \"Relation\": \"as a result\", \"Tail\": \"GraphMERT is the first efficient and scalable neurosymbolic model to do so relative to baselines\"}, {\"Head\": \"Off-the-shelf LLMs generate domain-specific KGs that fall short on reliability\", \"Relation\": \"because\", \"Tail\": \"LLMs suffer from prompt sensitivity, shallow domain expertise, and hallucinated relations\"}, {\"Head\": \"An 80M-parameter GraphMERT yields a KG with a 69.8% FActScore on PubMed diabetes text\", \"Relation\": \"as a result\", \"Tail\": \"a 32B-parameter baseline LLM yields a KG with only a 40.2% FActScore\"}, {\"Head\": \"The GraphMERT-extracted KG achieves a higher ValidityScore than the LLM baseline\", \"Relation\": \"because\", \"Tail\": \"GraphMERT preserves ontology alignment and relation usage patterns from the seed KG\"}, {\"Head\": \"Human experts can edit and audit the extracted KGs\", \"Relation\": \"as a result\", \"Tail\": \"the reliability of the extracted KGs can be further increased\"}, {\"Head\": \"LLMs are oblivious to their training sources\", \"Relation\": \"because\", \"Tail\": \"prompt-based KG distillation from an LLM's weights does not provide source attribution\"}, {\"Head\": \"Fine-tuned models demonstrate higher accuracy and fewer hallucinations\", \"Relation\": \"because\", \"Tail\": \"fine-tuning adapts models to the domains they are trained on\"}, {\"Head\": \"Fine-tuning requires labeled training data\", \"Relation\": \"as a result\", \"Tail\": \"fine-tuning negatively impacts generalization and reduces adaptability to other knowledge domains\"}, {\"Head\": \"KG extraction from off-the-shelf LLMs is confined to a single context window\", \"Relation\": \"as a result\", \"Tail\": \"extracted triples are often local and may reflect spurious correlations rather than global facts\"}, {\"Head\": \"Extending context length degrades output quality\", \"Relation\": \"as a result\", \"Tail\": \"hallucinations become more frequent and the model's ability to harness lengthy input degrades\"}, {\"Head\": \"High-quality data are scarce\", \"Relation\": \"as a result\", \"Tail\": \"building a reliable domain-specific KG from limited high-quality sources becomes the central question\"}, {\"Head\": \"GraphMERT jointly learns semantic representations from a seed KG and syntactic representations from text\", \"Relation\": \"because\", \"Tail\": \"it minimizes masked language modeling and masked node modeling losses\"}]"}
{"id": "1", "original_text": "nerality: It relies on domain-agnostic principles. We do not hard-code any domain-specific parameters to the proposed GraphMERT pipeline. 6. Global integration: It can connect global concepts across the whole dataset throughout training, in contrast to extracting disconnected information from isolated text. The rest of the article is organized as follows. In Sec. 2, we review different KG extraction techniques and motivate the need for a reliable KG. In Sec. 3, we provide a brief motivational example. In Sec. 4, we give a detailed overview of our proposed GraphMERT framework and its architecture. In Sec. 5, we describe the experimental setup. In Sec. 6, we provide experimental results. In Sec. 7, we discuss the limitations of our methodology and discuss future work. Finally, we conclude in Sec. 8. ## 2 Background and Related Work In this section, we review prior research that is relevant to our work, including applications of neurosymbolic AI and KGs. We then examine existing KG extraction methods, their limitations, and how our framework addresses these gaps. Finally, we provide the technical background on graph transformer architectures that is necessary to understand the remainder of this work. ## 2.1 Knowledge Graphs The term 'Knowledge Graph' was coined by Google in a blog (Singhal, 2012) in 2012. Google anticipated a great potential of graph representation in web search for discerning semantic connections in vast web data to respond to user queries. Since then, KGs have sparked a great deal of research on knowledge-aware applications (Zhang et al., 2024a). A KG G = ( V, E ) can be viewed as a directed graph where nodes V represent real-world entities and directed edges E ⊆ V × V represent relationships between them (see Fig. 1 for a toy example). Each directed edge e = ( u, v ) ∈ E connects two nodes u, v ∈ V and encodes a relationship r between the corresponding entities. Semantically, a KG can be thought of as a set of triples G = 〈 h, r, t 〉 = 〈 head, relation, tail 〉 , where head and tail denote two KG entities connected by a directed relation. For example, in Fig. 1, 〈 Metformin , TREATS , Type 2 Diabetes 〉 (note the implied directionality in the representation) is one of the triples in the toy KG. ## 2.2 Importance of KGs in Neurosymbolic AI Reasoning is the defining challenge in neurosymbolic AI. Researchers have long struggled to combine the efficiency of neural learning with the rigor and interpretability of symbolic inference (Zhang et al., 2021). Figure 1: A toy KG example from the medical domain. <!-- image --> ## 2.2.1 The Representation Dilemma: Neural or Symbolic? Traditional AI research overwhelmingly associates reasoning with purely symbolic systems, such as expert systems (van Melle, 1978; Lindsay et al., 1993) or logic-based AI (McCarthy, 1980; Colmerauer &amp; Roussel, 1996). For decades, this paradigm shaped AI practice under the premise that human intelligence could be reduced to formal logic operating on symbols (Newell &amp; Simon, 1976; Haugeland, 1985). Symbolic methods offer clarity and structure by explicitly encoding rules over discrete concepts (Newell &amp; Simon, 1976) and are reliable, given suitable abstractions. The symbolic approach governed the AI field till the 90s, when its drawbacks became evident: Symbolic systems struggle with ambiguity, contextualization, and the fluidity of real-world knowledge (Harnad, 1990). In addition, computational complexity limits scalability of systems that are already prone to brittleness: Complete symbolic grounding of a knowledge base leads to a worst-case combinatorial explosion (Chen &amp; Suen, 1994). In contrast, neural approaches rely on multidimensional embeddings as their representations and approximate knowledge grounding through gradient-based learning over a continuous parameter space (LeCun et al., 2015). They are robust against outliers and inaccuracies in data, and scale learning and inference well (Hitzler et al., 2022). Modern deep learning (DL) excels in domains such as image classification (Krizhevsky et al., 2012) and machine translation (Bahdanau et al., 2016). Neural systems are efficient learners but forfeit transparency: Their decision pathways remain opaque and lack the verifiable interpretability of symbolic inference (Tran et al., 2025). They tend to memorize, thus undermining reliable generalization beyond observed facts, especially in out-of-distribution domains. Furthermore, while probabilistic and approximate inference accommodates ambiguities, it yields imprecise logical inference. A fundamental trade-off is apparent: Symbolic reasoning offers precision and interpretability but lacks scalability, while neural reasoning is scalable and flexible but lacks transparency. The central question remains: Which representation best fits a given task? Tasks that involve complex, high-volume, and noisy data, particularly those centered on pattern recognition, primarily favor neural DL systems. In contrast, symbolic forms are best suited to problems that require human interpretability or necessitate verifiable reasoning, e.g., in critical decision-making domains (Rudin, 2019). Tasks that require explainability or involve abstract symbolic data structures (Wolfram Research Inc.) naturally favor symbolic systems, which are inherently self-explanatory (Hitzler et al., 2022). For instance, graph-based symbolic reasoning reduces many queries to reachability checks, yielding verifiable answers. Due to these complementary advantages and limitations, researchers are increasingly focused on neurosymbolic integration (Tran et al., 2025) for complex AI challenges that cannot be solved by either approach individually. ## 2.2.2 KG with Neural Network: Unifying the Representations In many tasks, the solution is not to pit symbolic and neural approaches against each other but to combine them in hybrid, modular systems. Neural networks discover statistical patterns through gradient descent; symbolic layers then manipulate extracted structure efficiently (Garcez &amp; Lamb, 2023). This integration enables knowledge extraction from neural models. Within such a neurosymbolic framework, KGs can naturally serve as symbolic memory and rule repositories. Coupled with neural networks, they provide modularity and cross-representation translation. KGs may handle tasks better suited to symbolic representation, mitigating the weaknesses of implicit neural reasoning. Moreover, when a KG is distilled directly from a neural network itself, it provides a transparent view of the learned representations of the model, fostering trust and enabling cross-domain transfer. By decoupling learning (implicit, neural) from reasoning (explicit, symbolic), KGs address interpretability, verifiability, and factuality gaps in modern AI systems that are dominated by neural approaches (Besold et al., 2017). ## 2.2.3 KG Applications in Neurosymbolic Frameworks KGs with high-quality expert knowledge enable a range of downstream applications. Explicit reasoning and knowledge transfer: Symbolic inference over KGs is efficient and interpretable (Cheng et al., 2024). For instance, retrieving all drugs ( d ) that (1) target a protein ( p ) associated with Type 2 Diabetes and (2) are approved by the FDA, expressed as the conjunctive query: <!-- formula-not-decoded --> Explicit rules can also be transferred across related domains. Neural reasoning complements this by leveraging KG embeddings to exploit graph structure while ignoring explicit constraints, enabling it to handle ambiguity and subtle semantic variations (Zhang et al., 2021). Reliability in critical fields: In sensitive domains, auditable and editable KGs can serve as a persistent knowledge base: Facts can be inspected, verified, and updated directly (Pan et al., 2023a). LLMs, by contrast, embed knowledge implicitly in parameters, making tracing and verification difficult (Akyurek et al., 2022), and are prone to hallucinations (Huang et al., 2025b). Updating LLMs is resource-intensive, requiring finetuning or retrieval-augmented generation (RAG), and resolving contradictions demands complex methods such as context-aware decoding. Verification of generated content against a factual KG minimizes the risk of inaccuracies or hallucinations (Luo et al., 2024; Hron et al., 2024). Furthermore, a KG offers the 'ability to forget': Information can be erased if required by legal regulations or upon user request. By contrast, removing knowledge from LLM requires complex interventions and sophisticated strategies that risk catastrophic unlearning (Si et al., 2023), raising concerns about access to harmful content, user privacy, and copyright violations (Tian et al., 2024). RAG factuality and scalability: To enhance factuality, RAG can be replaced with GraphRAG (Edge et al., 2024). In standard RAG, answer accuracy depends heavily on the relevance and quality of retrieved text. This often fails when information is buried in long passages or scattered across documents. Further, vector-based RAG depends on textual embeddings that may fail to correlate semantically similar concepts dispersed in spatiotemporally disparate sources. KGs provide an anchoring structure for LLMs to maintain context, and make evidence clear, verifiable, and lightweight for efficient retrieval. This improves scalability and lowers generation costs. Recent work by Rao et al. (2024) shows GraphRAG outperforming vector RAG and HybridRAG (Sarmah et al., 2024) on arXiv datasets, demonstrating superior factual accuracy and reasoning. These results highlight GraphRAG's potential, especially for tasks requiring multi-hop reasoning and sustained context understanding. Reinforcement learning: KGs are effective for policy-guided walks in reinforcement learning with logical rules (Uddin et al., 2025; Liu et al., 2021), as they encode explicit relations and allow rule-based constraints on transitions. This structured setting maintains logical consistency and supports optimal path learning. By contrast, using unstructured text as the environment leads to noisy and inconsistent transitions, making rule-aware exploration more challenging. Interpretability of neural network decisions: Extracting a KG from a model, which externalizes neural associations into explicit, structured relations, unveils acquired knowledge (Swamy et al., 2021). It maps hidden representations onto human-understandable concepts, enabling tracing of predictions, posthoc explanation, and auditing. Unlike raw embeddings or hidden activations, which remain opaque, KGs provide a symbolic layer for inspecting reasoning chains, thus bridging neural representations with semantic knowledge. Discoveries: KGs uncover hidden insights by linking concepts, which appear unconnected, through explicit graph paths. This connectivity underpins applications such as recommendations, where relevant entities are suggested based on graph neighborhoods, and analogical discovery, where cross-domain parallels emerge through reasoning over paths. Unlike unstructured text or embeddings, KGs provide verifiable relations, enabling trustworthy discoveries. In biomedicine, for example, a path like drug → protein target → pathway →disease can reveal repurposing opportunities, such as a hypertension drug acting on pathways implicated in diabetes. ## 2.3 KGs for Domain-specific Superintelligence In the near future, a natural scarcity of high-quality text sources may impede the scalability of ever-larger LLMs, necessitating a paradigm shift that favors smaller language models with domain-specific expertise. This would shift focus from general-purpose artificial general intelligence to domain-specific superintelligence: from breadth to depth. Superintelligence (Bostrom, 2014), an entity whose intelligence surpasses human capability and may diverge from anthropomorphic reasoning, could excel in task-specific reasoning, generate disruptive insights, and exceed human-level creativity (Szocik et al., 2020). A recent study by Dedhia et al. (2025) illustrates one path toward this goal by translating multi-hop KG paths to composite natural language statements, effectively linking knowledge depth to KG path length. They demonstrate how to boost reasoning ability in a chosen domain using a high-quality domain-specific KG: fine-tuning a small language model based on deep, multi-hop KG knowledge. The longer the paths used for fine-tuning, the better their reasoning - a key property for domain-specific superintelligence. Seen from this perspective, conventional text datasets resemble one-hop knowledge: They only touch the surface and thus produce models that elicit surface-level understanding. In this context, a high-quality, domain-specific KG that explicitly encodes the wealth of knowledge through concise and unambiguous semantic relationships serves as a powerful tool for unlocking deeper intelligence. Such a structured knowledge simplifies learning of meaningful semantic representations, particularly where models would otherwise be overwhelmed with the syntactic complexity of lengthy yet less informative sentences. This indicates that a scalable method for automatic extraction of high-quality KGs would open up a path to scalable superintelligence. ## 2.4 Existing KG-extraction Methods Next, we briefly review existing KG-extraction methods. For further details, we direct the reader to a comprehensive review on KG construction (Zhong et al., 2023). We discuss the following categories: (1) task-specific natural language processing (NLP) methods, (2) triple embedding-based, and, the most recent, (3) generative", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "GraphMERT pipeline", "Relation": "relies on", "Tail": "domain-agnostic principles"}, {"Head": "GraphMERT pipeline", "Relation": "connects", "Tail": "global concepts across the dataset"}, {"Head": "Knowledge Graph", "Relation": "was coined by", "Tail": "Google"}, {"Head": "Knowledge Graph", "Relation": "is represented as", "Tail": "directed graph (V, E)"}, {"Head": "KG node", "Relation": "represents", "Tail": "real-world entities"}, {"Head": "KG directed edge", "Relation": "encodes", "Tail": "relationships between entities"}, {"Head": "KG triple", "Relation": "captures", "Tail": "head relation tail"}, {"Head": "Metformin", "Relation": "treats", "Tail": "Type 2 Diabetes"}, {"Head": "Neurosymbolic AI", "Relation": "faces", "Tail": "reasoning challenge"}, {"Head": "Symbolic methods", "Relation": "encode", "Tail": "explicit rules over discrete concepts"}, {"Head": "Symbolic methods", "Relation": "offer", "Tail": "interpretability and verifiability"}, {"Head": "Symbolic methods", "Relation": "suffer from", "Tail": "scalability and brittleness issues"}, {"Head": "Neural approaches", "Relation": "use", "Tail": "multidimensional embeddings and gradient-based learning"}, {"Head": "Neural approaches", "Relation": "provide", "Tail": "scalability and robustness to noise"}, {"Head": "Neural approaches", "Relation": "lack", "Tail": "transparency and verifiable interpretability"}, {"Head": "Neurosymbolic integration", "Relation": "combines", "Tail": "neural networks and symbolic layers"}, {"Head": "Knowledge Graphs", "Relation": "serve as", "Tail": "symbolic memory and rule repositories"}, {"Head": "KG distilled from a neural network", "Relation": "provides", "Tail": "transparent view of learned representations"}, {"Head": "KGs", "Relation": "enable", "Tail": "explicit reasoning and knowledge transfer"}, {"Head": "KGs", "Relation": "support", "Tail": "auditable and editable persistent knowledge bases"}, {"Head": "LLMs", "Relation": "embed knowledge", "Tail": "implicitly in parameters"}, {"Head": "LLMs", "Relation": "are prone to", "Tail": "hallucinations"}, {"Head": "Updating LLMs", "Relation": "requires", "Tail": "resource-intensive fine-tuning or RAG"}, {"Head": "GraphRAG", "Relation": "outperforms", "Tail": "vector RAG and HybridRAG on arXiv datasets"}, {"Head": "KGs", "Relation": "anchor", "Tail": "LLM context and evidence for retrieval"}, {"Head": "KGs", "Relation": "improve", "Tail": "scalability and factuality of retrieval"}, {"Head": "KGs", "Relation": "enable", "Tail": "policy-guided walks in reinforcement learning"}, {"Head": "KG extraction from models", "Relation": "enables", "Tail": "interpretability and auditing of neural decisions"}, {"Head": "KGs", "Relation": "support", "Tail": "discoveries via linking unconnected concepts"}, {"Head": "Domain-specific KG", "Relation": "facilitates", "Tail": "domain-specific superintelligence"}, {"Head": "Dedhia et al. (2025)", "Relation": "show", "Tail": "multi-hop KG paths boost small language model reasoning"}, {"Head": "High-quality domain-specific KG", "Relation": "enables", "Tail": "deeper semantic representations and fine-tuning benefits"}, {"Head": "Conventional text datasets", "Relation": "provide", "Tail": "mostly one-hop knowledge"}, {"Head": "Scalable automatic KG extraction", "Relation": "opens", "Tail": "path to scalable superintelligence"}], "entity_relation_output": "[{\"Head\": \"GraphMERT pipeline\", \"Relation\": \"relies on\", \"Tail\": \"domain-agnostic principles\"}, {\"Head\": \"GraphMERT pipeline\", \"Relation\": \"connects\", \"Tail\": \"global concepts across the dataset\"}, {\"Head\": \"Knowledge Graph\", \"Relation\": \"was coined by\", \"Tail\": \"Google\"}, {\"Head\": \"Knowledge Graph\", \"Relation\": \"is represented as\", \"Tail\": \"directed graph (V, E)\"}, {\"Head\": \"KG node\", \"Relation\": \"represents\", \"Tail\": \"real-world entities\"}, {\"Head\": \"KG directed edge\", \"Relation\": \"encodes\", \"Tail\": \"relationships between entities\"}, {\"Head\": \"KG triple\", \"Relation\": \"captures\", \"Tail\": \"head relation tail\"}, {\"Head\": \"Metformin\", \"Relation\": \"treats\", \"Tail\": \"Type 2 Diabetes\"}, {\"Head\": \"Neurosymbolic AI\", \"Relation\": \"faces\", \"Tail\": \"reasoning challenge\"}, {\"Head\": \"Symbolic methods\", \"Relation\": \"encode\", \"Tail\": \"explicit rules over discrete concepts\"}, {\"Head\": \"Symbolic methods\", \"Relation\": \"offer\", \"Tail\": \"interpretability and verifiability\"}, {\"Head\": \"Symbolic methods\", \"Relation\": \"suffer from\", \"Tail\": \"scalability and brittleness issues\"}, {\"Head\": \"Neural approaches\", \"Relation\": \"use\", \"Tail\": \"multidimensional embeddings and gradient-based learning\"}, {\"Head\": \"Neural approaches\", \"Relation\": \"provide\", \"Tail\": \"scalability and robustness to noise\"}, {\"Head\": \"Neural approaches\", \"Relation\": \"lack\", \"Tail\": \"transparency and verifiable interpretability\"}, {\"Head\": \"Neurosymbolic integration\", \"Relation\": \"combines\", \"Tail\": \"neural networks and symbolic layers\"}, {\"Head\": \"Knowledge Graphs\", \"Relation\": \"serve as\", \"Tail\": \"symbolic memory and rule repositories\"}, {\"Head\": \"KG distilled from a neural network\", \"Relation\": \"provides\", \"Tail\": \"transparent view of learned representations\"}, {\"Head\": \"KGs\", \"Relation\": \"enable\", \"Tail\": \"explicit reasoning and knowledge transfer\"}, {\"Head\": \"KGs\", \"Relation\": \"support\", \"Tail\": \"auditable and editable persistent knowledge bases\"}, {\"Head\": \"LLMs\", \"Relation\": \"embed knowledge\", \"Tail\": \"implicitly in parameters\"}, {\"Head\": \"LLMs\", \"Relation\": \"are prone to\", \"Tail\": \"hallucinations\"}, {\"Head\": \"Updating LLMs\", \"Relation\": \"requires\", \"Tail\": \"resource-intensive fine-tuning or RAG\"}, {\"Head\": \"GraphRAG\", \"Relation\": \"outperforms\", \"Tail\": \"vector RAG and HybridRAG on arXiv datasets\"}, {\"Head\": \"KGs\", \"Relation\": \"anchor\", \"Tail\": \"LLM context and evidence for retrieval\"}, {\"Head\": \"KGs\", \"Relation\": \"improve\", \"Tail\": \"scalability and factuality of retrieval\"}, {\"Head\": \"KGs\", \"Relation\": \"enable\", \"Tail\": \"policy-guided walks in reinforcement learning\"}, {\"Head\": \"KG extraction from models\", \"Relation\": \"enables\", \"Tail\": \"interpretability and auditing of neural decisions\"}, {\"Head\": \"KGs\", \"Relation\": \"support\", \"Tail\": \"discoveries via linking unconnected concepts\"}, {\"Head\": \"Domain-specific KG\", \"Relation\": \"facilitates\", \"Tail\": \"domain-specific superintelligence\"}, {\"Head\": \"Dedhia et al. (2025)\", \"Relation\": \"show\", \"Tail\": \"multi-hop KG paths boost small language model reasoning\"}, {\"Head\": \"High-quality domain-specific KG\", \"Relation\": \"enables\", \"Tail\": \"deeper semantic representations and fine-tuning benefits\"}, {\"Head\": \"Conventional text datasets\", \"Relation\": \"provide\", \"Tail\": \"mostly one-hop knowledge\"}, {\"Head\": \"Scalable automatic KG extraction\", \"Relation\": \"opens\", \"Tail\": \"path to scalable superintelligence\"}]", "event_entity_dict": [{"Event": "It relies on domain-agnostic principles.", "Entity": ["GraphMERT pipeline", "domain-agnostic principles"]}, {"Event": "We do not hard-code any domain-specific parameters to the proposed GraphMERT pipeline.", "Entity": ["we", "GraphMERT pipeline", "domain-specific parameters"]}, {"Event": "It can connect global concepts across the whole dataset throughout training", "Entity": ["GraphMERT", "global concepts", "whole dataset", "training"]}, {"Event": "The rest of the article is organized as follows.", "Entity": ["article", "rest of the article"]}, {"Event": "In Sec. 2, we review different KG extraction techniques and motivate the need for a reliable KG.", "Entity": ["we", "Sec. 2", "KG extraction techniques", "reliable KG"]}, {"Event": "In Sec. 3, we provide a brief motivational example.", "Entity": ["we", "Sec. 3", "motivational example"]}, {"Event": "In Sec. 4, we give a detailed overview of our proposed GraphMERT framework and its architecture.", "Entity": ["we", "Sec. 4", "GraphMERT framework", "architecture"]}, {"Event": "In Sec. 5, we describe the experimental setup.", "Entity": ["we", "Sec. 5", "experimental setup"]}, {"Event": "In Sec. 6, we provide experimental results.", "Entity": ["we", "Sec. 6", "experimental results"]}, {"Event": "In Sec. 7, we discuss the limitations of our methodology and discuss future work.", "Entity": ["we", "Sec. 7", "limitations of our methodology", "future work"]}, {"Event": "We conclude in Sec. 8.", "Entity": ["we", "Sec. 8", "article conclusion"]}, {"Event": "In this section, we review prior research that is relevant to our work, including applications of neurosymbolic AI and KGs.", "Entity": ["we", "prior research", "neurosymbolic AI", "KGs", "this section"]}, {"Event": "We then examine existing KG extraction methods, their limitations, and how our framework addresses these gaps.", "Entity": ["we", "existing KG extraction methods", "their limitations", "our framework"]}, {"Event": "Finally, we provide the technical background on graph transformer architectures that is necessary to understand the remainder of this work.", "Entity": ["we", "technical background", "graph transformer architectures", "remainder of this work"]}, {"Event": "The term 'Knowledge Graph' was coined by Google in a blog in 2012.", "Entity": ["Knowledge Graph", "Google", "blog", "2012"]}, {"Event": "Google anticipated a great potential of graph representation in web search for discerning semantic connections in vast web data to respond to user queries.", "Entity": ["Google", "graph representation", "web search", "semantic connections", "vast web data", "user queries"]}, {"Event": "Since then, KGs have sparked a great deal of research on knowledge-aware applications.", "Entity": ["KGs", "research", "knowledge-aware applications"]}, {"Event": "A KG G = (V, E) can be viewed as a directed graph where nodes V represent real-world entities and directed edges E represent relationships between them.", "Entity": ["KG", "G", "V", "E", "nodes V", "real-world entities", "directed edges E", "relationships"]}, {"Event": "Each directed edge e = (u, v) ∈ E connects two nodes u, v ∈ V and encodes a relationship r between the corresponding entities.", "Entity": ["directed edge e", "u", "v", "E", "relationship r", "corresponding entities"]}, {"Event": "Semantically, a KG can be thought of as a set of triples G = 〈h, r, t〉 = 〈head, relation, tail〉.", "Entity": ["KG", "triples", "G", "h", "r", "t", "head", "relation", "tail"]}, {"Event": "For example, 〈Metformin, TREATS, Type 2 Diabetes〉 is one of the triples in the toy KG.", "Entity": ["Metformin", "TREATS", "Type 2 Diabetes", "toy KG"]}, {"Event": "Reasoning is the defining challenge in neurosymbolic AI.", "Entity": ["Reasoning", "neurosymbolic AI"]}, {"Event": "Researchers have long struggled to combine the efficiency of neural learning with the rigor and interpretability of symbolic inference.", "Entity": ["Researchers", "neural learning", "symbolic inference", "efficiency", "rigor", "interpretability"]}, {"Event": "Traditional AI research overwhelmingly associates reasoning with purely symbolic systems, such as expert systems or logic-based AI.", "Entity": ["Traditional AI research", "reasoning", "symbolic systems", "expert systems", "logic-based AI"]}, {"Event": "For decades, this paradigm shaped AI practice under the premise that human intelligence could be reduced to formal logic operating on symbols.", "Entity": ["this paradigm", "AI practice", "human intelligence", "formal logic", "symbols"]}, {"Event": "Symbolic methods offer clarity and structure by explicitly encoding rules over discrete concepts and are reliable, given suitable abstractions.", "Entity": ["Symbolic methods", "clarity", "structure", "rules", "discrete concepts", "suitable abstractions"]}, {"Event": "The symbolic approach governed the AI field till the 90s, when its drawbacks became evident.", "Entity": ["symbolic approach", "AI field", "90s", "drawbacks"]}, {"Event": "Symbolic systems struggle with ambiguity, contextualization, and the fluidity of real-world knowledge.", "Entity": ["Symbolic systems", "ambiguity", "contextualization", "fluidity of real-world knowledge"]}, {"Event": "Computational complexity limits scalability of systems that are already prone to brittleness.", "Entity": ["Computational complexity", "scalability", "systems", "brittleness"]}, {"Event": "Complete symbolic grounding of a knowledge base leads to a worst-case combinatorial explosion.", "Entity": ["Complete symbolic grounding", "knowledge base", "worst-case combinatorial explosion"]}, {"Event": "Neural approaches rely on multidimensional embeddings and approximate knowledge grounding through gradient-based learning over a continuous parameter space.", "Entity": ["Neural approaches", "multidimensional embeddings", "gradient-based learning", "continuous parameter space"]}, {"Event": "They are robust against outliers and inaccuracies in data, and scale learning and inference well.", "Entity": ["Neural approaches", "outliers", "inaccuracies in data", "learning", "inference"]}, {"Event": "Modern deep learning excels in domains such as image classification and machine translation.", "Entity": ["Modern deep learning", "image classification", "machine translation"]}, {"Event": "Neural systems are efficient learners but forfeit transparency.", "Entity": ["Neural systems", "efficiency", "transparency"]}, {"Event": "Their decision pathways remain opaque and lack the verifiable interpretability of symbolic inference.", "Entity": ["Neural systems", "decision pathways", "opaque", "verifiable interpretability", "symbolic inference"]}, {"Event": "They tend to memorize, thus undermining reliable generalization beyond observed facts, especially in out-of-distribution domains.", "Entity": ["Neural systems", "memorization", "reliable generalization", "observed facts", "out-of-distribution domains"]}, {"Event": "Probabilistic and approximate inference accommodates ambiguities but yields imprecise logical inference.", "Entity": ["probabilistic inference", "approximate inference", "ambiguities", "imprecise logical inference"]}], "event_entity_output": "[{\"Event\": \"It relies on domain-agnostic principles.\", \"Entity\": [\"GraphMERT pipeline\", \"domain-agnostic principles\"]}, {\"Event\": \"We do not hard-code any domain-specific parameters to the proposed GraphMERT pipeline.\", \"Entity\": [\"we\", \"GraphMERT pipeline\", \"domain-specific parameters\"]}, {\"Event\": \"It can connect global concepts across the whole dataset throughout training\", \"Entity\": [\"GraphMERT\", \"global concepts\", \"whole dataset\", \"training\"]}, {\"Event\": \"The rest of the article is organized as follows.\", \"Entity\": [\"article\", \"rest of the article\"]}, {\"Event\": \"In Sec. 2, we review different KG extraction techniques and motivate the need for a reliable KG.\", \"Entity\": [\"we\", \"Sec. 2\", \"KG extraction techniques\", \"reliable KG\"]}, {\"Event\": \"In Sec. 3, we provide a brief motivational example.\", \"Entity\": [\"we\", \"Sec. 3\", \"motivational example\"]}, {\"Event\": \"In Sec. 4, we give a detailed overview of our proposed GraphMERT framework and its architecture.\", \"Entity\": [\"we\", \"Sec. 4\", \"GraphMERT framework\", \"architecture\"]}, {\"Event\": \"In Sec. 5, we describe the experimental setup.\", \"Entity\": [\"we\", \"Sec. 5\", \"experimental setup\"]}, {\"Event\": \"In Sec. 6, we provide experimental results.\", \"Entity\": [\"we\", \"Sec. 6\", \"experimental results\"]}, {\"Event\": \"In Sec. 7, we discuss the limitations of our methodology and discuss future work.\", \"Entity\": [\"we\", \"Sec. 7\", \"limitations of our methodology\", \"future work\"]}, {\"Event\": \"We conclude in Sec. 8.\", \"Entity\": [\"we\", \"Sec. 8\", \"article conclusion\"]}, {\"Event\": \"In this section, we review prior research that is relevant to our work, including applications of neurosymbolic AI and KGs.\", \"Entity\": [\"we\", \"prior research\", \"neurosymbolic AI\", \"KGs\", \"this section\"]}, {\"Event\": \"We then examine existing KG extraction methods, their limitations, and how our framework addresses these gaps.\", \"Entity\": [\"we\", \"existing KG extraction methods\", \"their limitations\", \"our framework\"]}, {\"Event\": \"Finally, we provide the technical background on graph transformer architectures that is necessary to understand the remainder of this work.\", \"Entity\": [\"we\", \"technical background\", \"graph transformer architectures\", \"remainder of this work\"]}, {\"Event\": \"The term 'Knowledge Graph' was coined by Google in a blog in 2012.\", \"Entity\": [\"Knowledge Graph\", \"Google\", \"blog\", \"2012\"]}, {\"Event\": \"Google anticipated a great potential of graph representation in web search for discerning semantic connections in vast web data to respond to user queries.\", \"Entity\": [\"Google\", \"graph representation\", \"web search\", \"semantic connections\", \"vast web data\", \"user queries\"]}, {\"Event\": \"Since then, KGs have sparked a great deal of research on knowledge-aware applications.\", \"Entity\": [\"KGs\", \"research\", \"knowledge-aware applications\"]}, {\"Event\": \"A KG G = (V, E) can be viewed as a directed graph where nodes V represent real-world entities and directed edges E represent relationships between them.\", \"Entity\": [\"KG\", \"G\", \"V\", \"E\", \"nodes V\", \"real-world entities\", \"directed edges E\", \"relationships\"]}, {\"Event\": \"Each directed edge e = (u, v) ∈ E connects two nodes u, v ∈ V and encodes a relationship r between the corresponding entities.\", \"Entity\": [\"directed edge e\", \"u\", \"v\", \"E\", \"relationship r\", \"corresponding entities\"]}, {\"Event\": \"Semantically, a KG can be thought of as a set of triples G = 〈h, r, t〉 = 〈head, relation, tail〉.\", \"Entity\": [\"KG\", \"triples\", \"G\", \"h\", \"r\", \"t\", \"head\", \"relation\", \"tail\"]}, {\"Event\": \"For example, 〈Metformin, TREATS, Type 2 Diabetes〉 is one of the triples in the toy KG.\", \"Entity\": [\"Metformin\", \"TREATS\", \"Type 2 Diabetes\", \"toy KG\"]}, {\"Event\": \"Reasoning is the defining challenge in neurosymbolic AI.\", \"Entity\": [\"Reasoning\", \"neurosymbolic AI\"]}, {\"Event\": \"Researchers have long struggled to combine the efficiency of neural learning with the rigor and interpretability of symbolic inference.\", \"Entity\": [\"Researchers\", \"neural learning\", \"symbolic inference\", \"efficiency\", \"rigor\", \"interpretability\"]}, {\"Event\": \"Traditional AI research overwhelmingly associates reasoning with purely symbolic systems, such as expert systems or logic-based AI.\", \"Entity\": [\"Traditional AI research\", \"reasoning\", \"symbolic systems\", \"expert systems\", \"logic-based AI\"]}, {\"Event\": \"For decades, this paradigm shaped AI practice under the premise that human intelligence could be reduced to formal logic operating on symbols.\", \"Entity\": [\"this paradigm\", \"AI practice\", \"human intelligence\", \"formal logic\", \"symbols\"]}, {\"Event\": \"Symbolic methods offer clarity and structure by explicitly encoding rules over discrete concepts and are reliable, given suitable abstractions.\", \"Entity\": [\"Symbolic methods\", \"clarity\", \"structure\", \"rules\", \"discrete concepts\", \"suitable abstractions\"]}, {\"Event\": \"The symbolic approach governed the AI field till the 90s, when its drawbacks became evident.\", \"Entity\": [\"symbolic approach\", \"AI field\", \"90s\", \"drawbacks\"]}, {\"Event\": \"Symbolic systems struggle with ambiguity, contextualization, and the fluidity of real-world knowledge.\", \"Entity\": [\"Symbolic systems\", \"ambiguity\", \"contextualization\", \"fluidity of real-world knowledge\"]}, {\"Event\": \"Computational complexity limits scalability of systems that are already prone to brittleness.\", \"Entity\": [\"Computational complexity\", \"scalability\", \"systems\", \"brittleness\"]}, {\"Event\": \"Complete symbolic grounding of a knowledge base leads to a worst-case combinatorial explosion.\", \"Entity\": [\"Complete symbolic grounding\", \"knowledge base\", \"worst-case combinatorial explosion\"]}, {\"Event\": \"Neural approaches rely on multidimensional embeddings and approximate knowledge grounding through gradient-based learning over a continuous parameter space.\", \"Entity\": [\"Neural approaches\", \"multidimensional embeddings\", \"gradient-based learning\", \"continuous parameter space\"]}, {\"Event\": \"They are robust against outliers and inaccuracies in data, and scale learning and inference well.\", \"Entity\": [\"Neural approaches\", \"outliers\", \"inaccuracies in data\", \"learning\", \"inference\"]}, {\"Event\": \"Modern deep learning excels in domains such as image classification and machine translation.\", \"Entity\": [\"Modern deep learning\", \"image classification\", \"machine translation\"]}, {\"Event\": \"Neural systems are efficient learners but forfeit transparency.\", \"Entity\": [\"Neural systems\", \"efficiency\", \"transparency\"]}, {\"Event\": \"Their decision pathways remain opaque and lack the verifiable interpretability of symbolic inference.\", \"Entity\": [\"Neural systems\", \"decision pathways\", \"opaque\", \"verifiable interpretability\", \"symbolic inference\"]}, {\"Event\": \"They tend to memorize, thus undermining reliable generalization beyond observed facts, especially in out-of-distribution domains.\", \"Entity\": [\"Neural systems\", \"memorization\", \"reliable generalization\", \"observed facts\", \"out-of-distribution domains\"]}, {\"Event\": \"Probabilistic and approximate inference accommodates ambiguities but yields imprecise logical inference.\", \"Entity\": [\"probabilistic inference\", \"approximate inference\", \"ambiguities\", \"imprecise logical inference\"]}]", "event_relation_dict": [{"Head": "The rest of the article is organized as follows", "Relation": "before", "Tail": "In Sec. 2, we review different KG extraction techniques and motivate the need for a reliable KG"}, {"Head": "The rest of the article is organized as follows", "Relation": "before", "Tail": "In Sec. 3, we provide a brief motivational example"}, {"Head": "The rest of the article is organized as follows", "Relation": "before", "Tail": "In Sec. 4, we give a detailed overview of our proposed GraphMERT framework and its architecture"}, {"Head": "The symbolic approach governed the AI field till the 90s", "Relation": "before", "Tail": "Its drawbacks became evident in the 90s"}, {"Head": "Its drawbacks became evident in the 90s", "Relation": "because", "Tail": "Symbolic systems struggle with ambiguity, contextualization, and the fluidity of real-world knowledge"}, {"Head": "Neural approaches rely on multidimensional embeddings and approximate knowledge grounding", "Relation": "as a result", "Tail": "They are robust against outliers and inaccuracies in data and scale learning and inference well"}, {"Head": "Due to complementary advantages and limitations of symbolic and neural methods", "Relation": "because", "Tail": "Researchers are increasingly focused on neurosymbolic integration"}, {"Head": "KGs can be distilled directly from a neural network", "Relation": "as a result", "Tail": "They provide a transparent view of the learned representations of the model, fostering trust and enabling cross-domain transfer"}, {"Head": "KGs provide an anchoring structure for LLMs to maintain context and make evidence clear", "Relation": "as a result", "Tail": "This improves scalability and lowers generation costs"}, {"Head": "Replacing standard RAG with GraphRAG", "Relation": "as a result", "Tail": "Recent work shows GraphRAG outperforms vector RAG and HybridRAG on arXiv datasets with superior factual accuracy and reasoning"}, {"Head": "By decoupling learning from reasoning", "Relation": "as a result", "Tail": "KGs address interpretability, verifiability, and factuality gaps in modern AI systems"}, {"Head": "Auditable and editable KGs can serve as a persistent knowledge base in sensitive domains", "Relation": "as a result", "Tail": "Facts can be inspected, verified, and updated directly"}, {"Head": "Removing knowledge from LLMs requires complex interventions and sophisticated strategies", "Relation": "as a result", "Tail": "This risks catastrophic unlearning and raises concerns about access to harmful content, user privacy, and copyright violations"}], "event_relation_output": "[{\"Head\": \"The rest of the article is organized as follows\", \"Relation\": \"before\", \"Tail\": \"In Sec. 2, we review different KG extraction techniques and motivate the need for a reliable KG\"}, {\"Head\": \"The rest of the article is organized as follows\", \"Relation\": \"before\", \"Tail\": \"In Sec. 3, we provide a brief motivational example\"}, {\"Head\": \"The rest of the article is organized as follows\", \"Relation\": \"before\", \"Tail\": \"In Sec. 4, we give a detailed overview of our proposed GraphMERT framework and its architecture\"}, {\"Head\": \"The symbolic approach governed the AI field till the 90s\", \"Relation\": \"before\", \"Tail\": \"Its drawbacks became evident in the 90s\"}, {\"Head\": \"Its drawbacks became evident in the 90s\", \"Relation\": \"because\", \"Tail\": \"Symbolic systems struggle with ambiguity, contextualization, and the fluidity of real-world knowledge\"}, {\"Head\": \"Neural approaches rely on multidimensional embeddings and approximate knowledge grounding\", \"Relation\": \"as a result\", \"Tail\": \"They are robust against outliers and inaccuracies in data and scale learning and inference well\"}, {\"Head\": \"Due to complementary advantages and limitations of symbolic and neural methods\", \"Relation\": \"because\", \"Tail\": \"Researchers are increasingly focused on neurosymbolic integration\"}, {\"Head\": \"KGs can be distilled directly from a neural network\", \"Relation\": \"as a result\", \"Tail\": \"They provide a transparent view of the learned representations of the model, fostering trust and enabling cross-domain transfer\"}, {\"Head\": \"KGs provide an anchoring structure for LLMs to maintain context and make evidence clear\", \"Relation\": \"as a result\", \"Tail\": \"This improves scalability and lowers generation costs\"}, {\"Head\": \"Replacing standard RAG with GraphRAG\", \"Relation\": \"as a result\", \"Tail\": \"Recent work shows GraphRAG outperforms vector RAG and HybridRAG on arXiv datasets with superior factual accuracy and reasoning\"}, {\"Head\": \"By decoupling learning from reasoning\", \"Relation\": \"as a result\", \"Tail\": \"KGs address interpretability, verifiability, and factuality gaps in modern AI systems\"}, {\"Head\": \"Auditable and editable KGs can serve as a persistent knowledge base in sensitive domains\", \"Relation\": \"as a result\", \"Tail\": \"Facts can be inspected, verified, and updated directly\"}, {\"Head\": \"Removing knowledge from LLMs requires complex interventions and sophisticated strategies\", \"Relation\": \"as a result\", \"Tail\": \"This risks catastrophic unlearning and raises concerns about access to harmful content, user privacy, and copyright violations\"}]"}
{"id": "1", "original_text": ", or LLM-based, which we discuss in greater detail, given its current prominence. Given the growing attention to LLM-driven KG construction (Zhu et al., 2024), we further differentiate KG extraction from KG generation , to clarify their respective advantages, limitations, and application scopes. We classify methods where an LLM plays a pivotal role in the KG construction pipeline, either generating triples conditioned on input texts or distilling knowledge from model weights, under the category of KG generation. We refer to all other approaches as KG extraction. ## 2.4.1 Task-specific NLP Methods Scale Badly Early rule-based information extraction systems demanded heavy feature engineering and domain expertise. Modern pipelines sequentially chain machine learning components-named entity recognition, coreference resolution, and relation extraction (Jaradeh et al., 2023)-often relying on structured or semi-structured data (Hofer et al., 2024). These systems require sophisticated text preprocessing heuristics (Rao et al., 2024), e.g., as in the case of conditional random fields. Long short-term memories and convolutional neural networks introduce locality bias. Another drawback is that errors propagate over the pipeline. Overall, these methods can be accurate, but are very labor-intensive, not fully automatic, and hard to scale. ## 2.4.2 Triple Embeddings are Local, Closed-domain, and Miss Long-range Dependencies An embedding-based approach seeks to train ML methods on KGs to capture semantic and structural patterns of the graph into embeddings by optimizing a scoring function. Embeddings enable the model to predict missing links (triple completion) and estimate the likelihood of new relations (link prediction; Cheng et al. 2024). However, this approach suffers from several limitations, including selection bias, lack of scalability, brittleness to KG errors, and limited external/world knowledge (Xia et al., 2025). Because most KG embedding models operate on local triple patterns, they struggle to compose long multi-hop chains, handle negation, or respect ontological constraints - particularly when relations are n-ary, qualified (e.g., temporal, provenance), or context-dependent. They also assume a largely closed-world, static graph: Cold-start entities/relations and evolving KGs typically require expensive retraining or ad-hoc heuristics, and performance degrades under distribution shift. More concretely, embedding-based approaches face the following limitations. Sparsity, limited information, and vocabulary: The scale of the largest publicly available KGs, e.g., Wikidata (118M+ entities), PubGraph (385M+ entities; Ahrabian et al. 2023), is of the order of 10 8 entities. The scale is incompatible with text corpora sizes: In 2024, top-tier LLMs reported up to 10 13 -token training datasets (Villalobos et al., 2024), and the pretraining corpora of leading projects can collectively surpass 700TB (Liu et al., 2024b). Insufficient utilization of semantic information: Learning an embedding representation that incorporates equally good graph structural and semantic information remains challenging. This is an active research frontier itself. Multiple efforts are targeted at developing architectures and approaches that produce embeddings that are not overly localized (Rao &amp; Wang, 2023), incorporate multiple relation types (Lu et al., 2023), and better integrate contextual (including semantic) information for improved reasoning (Shi et al., 2025). This suggests that embedding methods are useful in task-specific applications based on KGs, but on their own, fall short in extending KGs. Generalizability: Embedding methods do not generalize well across different KGs. Each KG is characterized by its own set of relations, attributes, and ontology, making it impossible or impractical to unite many KGs for training. In practice, embeddings entangle schema-specific signals (relation vocabularies, type hierarchies, qualifier formats). Hence, representations learned on one KG transfer poorly to another with different ontologies or naming conventions. Cross-KG use then requires costly alignment steps - entity linking, relation mapping, and negative-sampling redesign - and even after alignment, out-of-vocabulary entities/relations and schema drift often degrade performance (Chen et al., 2023b). ## 2.4.3 LLM-based KG Generation is Not Reliable With the tremendous success of LLMs on all kinds of NLP tasks, modern research on KG extraction is skewed towards extracting relational knowledge from LLM weights using prompts (Zhu et al., 2024; Carta et al., 2023; Li et al., 2025; Gupta et al., 2025). The widespread adoption of LLMs can be attributed to their versatility across tasks, adaptability to diverse domains, and ease of use, which together make them attractive as general-purpose AI systems. LLMs capture relational knowledge unevenly: They are more accurate for some types (e.g., commonsense or hierarchical 'is-a' links) and less accurate for others (e.g., detailed encyclopedic facts or multi-hop traversal relations; Pan et al. 2023a). In addition, a range of inherent drawbacks raises concerns about the use of LLMs for reliable domain-specific KG generation. The drawbacks we discuss next appear to be intrinsic to generative methods of KG construction. LLMs are brittle with respect to prompts: Instruction fine-tuning does not fully address this problem (Zhou et al., 2024). KG extraction with prompts is biased towards prompt structure (Cao et al., 2021). LLMs are sensitive to task-framing: answer consistency can shift with small syntactic changes (Hagström et al., 2023), with slight prompt variations (Mousavi et al., 2024; Wang et al., 2024a), and even with respect to basic logical constraints (Ghosh et al., 2025). Retrieval augmentation can mitigate inconsistency and knowledge-cutoff issues (Shuster et al., 2021), but introduces new failure modes: conflicts between retrieved evidence and LLM's parametric knowledge (Zhang et al., 2025; Zeng et al., 2025), imperfections in retrieval and ranking (Jin et al., 2024), and weak relevance estimation, resulting in incorrect utilization of the retrieved knowledge (Wang et al., 2024e). LLMs hallucinate: Beyond reproducibility, LLMs hallucinate outputs that are nonsensical or unfaithful to the provided source content (Ji et al., 2023; Zhang et al., 2024b; Li et al., 2024). Hallucinations persist regardless of model size or training data scale (Shuster et al., 2021). The current consensus is that hallucinations are an inherent, unavoidable property of LLMs. Some scholars formally show that, from the theoretical viewpoint, hallucinations may be innate to probabilistic generative methods (Xu et al., 2025). All methods to strengthen LLM reasoning, such as chain-of-thoughts with self-consistency, fine-tuning, augmented generation, and greedy decoding, improve accuracy, but are unable to eliminate nontrivial hallucinations (Kim et al., 2025). In the context of KG generation, LLMs struggle with inverse inference (the 'reversal curse'): They may learn 〈 A , is-a , B 〉 yet fail to infer the inverse relation (Berglund et al., 2024), undermining triple extraction in domains where inverse relations are common and semantically critical. LLMs are not factually accurate: Factuality and hallucination are distinct: Factuality errors occur when a model fails to learn or apply factual knowledge accurately, whereas hallucinations are ungrounded or unfaithful content relative to the provided source (Wang et al., 2024f). As demonstrated in our motivating example (Sec. 3), even state-of-the-art models can return factually divergent answers to equivalent queries. Because models acquire factual knowledge during pretraining and can add more via continued pretraining (Chang et al., 2025), rigorous dataset cleaning is essential. Yet, verifying or synthesizing high-quality data at the LLM scale is infeasible in practice, creating a fundamental size-quality trade-off (see Sec. 2.5). No current LLM offers the factuality needed for trust. Even the most advanced commercial systems make significant factual errors, which spike on rare entities and remain less factual than humans (Min et al., 2023), with mistakes persisting even in search-augmented tools (Mehrotra &amp; Marchman, 2024). Consequently, any method that relies on LLMs needs robust verification. In high-stakes domains (e.g., medicine (Thirunavukarasu et al., 2023), autonomous driving, aeronautics, and cybersecurity), verification alone is insufficient: Outputs must also be interpretable and explainable for decision-makers. However, today's LLMs provide little insight into their decision rationale (Madsen et al., 2024; Ye &amp; Durrett, 2022; Bowman, 2023), falling short of the guarantees these applications demand. ## 2.5 Impact of Data Quality and Dataset Size Prior work shows that state-of-the-art LLM capabilities emerge only when model size, dataset scale, and compute reach sufficient magnitude (Brown et al., 2020; Kaplan et al., 2020; Wei et al., 2022). As a result, modern pretraining corpora often favor scale over domain fidelity. Given LLM propensity to memorization, flawed data sources with misinformation and biases are a primary driver of hallucinations (Huang et al., 2025b). Domain adaptation with fine-tuning (Hu et al., 2022) can improve factuality and coherence, but risk catastrophic forgetting and cross-domain interference (Wang et al., 2024d); continued pretraining adapts knowledge more smoothly to a target domain, but demands substantial additional data. In medicine, researchers warn that scarcity of diverse, high-quality data at the scale required by LLMs leads to a 'garbage in, garbage out' dynamic and remains a key barrier to clinical LLM deployment (Thirunavukarasu et al., 2023). Compounding this, large-scale public text corpora lack established cross-verification mechanisms. Privacy and copyright concerns restrict access to private datasets for training purposes (Pereira et al., 2022; Wang et al., 2024b). In cases where models are trained on closed-source training data that are not accessible for scrutiny, the lack of transparency blocks the public's ability to conduct a thorough investigation (Nguyen et al., 2024). As a response to the limited availability of verified sources (Gandhi et al., 2024; Wang et al., 2024c) and unaffordable training costs, a growing line of work seeks to maximize LLM performance with less data, emphasizing the quality-quantity trade-off. The NLP field's post-GPT-3 trajectory (Brown et al., 2020), prioritized ever-larger unlabeled web corpora, arguably underweighting data quality. Recent efforts formalize data-quality criteria (Zheng et al., 2025) and show that small, high-quality datasets can outperform substantially larger but unvalidated corpora (Iskander et al., 2024); likewise, compact models trained on carefully curated, domain-specific text sometimes surpass frontier general-purpose models on in-domain tasks (Kadosh et al., 2024; Chen et al., 2023a). Our approach also advocates for 'data quality first': We contend that high-quality data - not the sheer volume of data - is crucial to creating a reliable KG. ## 2.6 GraphRAG Retrieval-augmented generation: RAG enhances the capabilities of LLMs by connecting them to external data sources. In a typical RAG system, a user's query is used to retrieve relevant documents or text chunks from a large corpus. This retrieved information is then combined with the original query into a prompt for the LLM, which generates a response grounded in the provided context (Ram et al., 2023). This approach is particularly effective when the knowledge base is too large to fit within the LLM context window. The most common retrieval method, vector RAG, involves embedding the text corpus into a vector space and retrieving chunks that are semantically closest to the query vector (Gao et al., 2024). However, this approach struggles with queries that require a holistic understanding of the entire dataset. GraphRAG: To strengthen standard retrieval, many systems incorporate KGs. GraphRAG (Edge et al., 2024) leverages the inherent modularity of KGs to support global sense-making in two stages: indexing and querying. In the indexing stage, an LLM builds an entity-level KG from source documents, then partitions the graph into a hierarchy of nested communities based on the density of connections between entities. The LLM then produces bottom-up summaries for each community, yielding a hierarchical summary tree that aggregates local insights into global ones. In the querying stage, GraphRAG extracts a subgraph based on the pre-generated community summaries and the query, and uses that subgraph as context to generate answers. With its hierarchical design, GraphRAG reports improvements over conventional vector-based RAG (Edge et al., 2024). Using GraphRAG for KG evaluation: The global sense-making capability of GraphRAG also enables a unique method for evaluating the quality of the KG and benchmarking it across various tasks. The accuracy of the answers to user queries is directly dependent on the coverage, validity, and factuality of the KG. A poorly constructed KG (e.g., one with incomplete entities or incorrect relationships) results in fragmented, inaccurate, or nonsensical responses. Therefore, by assessing the quality of GraphRAG's output to queries, one can indirectly measure the quality of the KG itself. ## 2.7 Graph Attention Networks The transformer architecture (Vaswani et al., 2017) has established itself as the de facto standard for NLP tasks. Self-attention", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "KG generation", "Relation": "is differentiated from", "Tail": "KG extraction"}, {"Head": "LLM", "Relation": "plays a pivotal role in", "Tail": "KG generation"}, {"Head": "KG generation", "Relation": "produces", "Tail": "triples conditioned on input texts"}, {"Head": "KG generation", "Relation": "distills knowledge from", "Tail": "model weights"}, {"Head": "Rule-based information extraction systems", "Relation": "demanded", "Tail": "heavy feature engineering and domain expertise"}, {"Head": "Modern pipelines", "Relation": "chain", "Tail": "named entity recognition, coreference resolution, and relation extraction"}, {"Head": "Conditional random fields", "Relation": "are used in", "Tail": "text preprocessing heuristics"}, {"Head": "LSTM and CNN", "Relation": "introduce", "Tail": "locality bias"}, {"Head": "Errors", "Relation": "propagate over", "Tail": "the pipeline"}, {"Head": "Embedding-based approach", "Relation": "trains ML methods on", "Tail": "knowledge graphs"}, {"Head": "Embeddings", "Relation": "enable", "Tail": "triple completion and link prediction"}, {"Head": "KG embedding models", "Relation": "struggle to compose", "Tail": "long multi-hop chains and handle n-ary/qualified relations"}, {"Head": "Embedding methods", "Relation": "assume", "Tail": "a largely closed-world, static graph"}, {"Head": "Cold-start entities and evolving KGs", "Relation": "require", "Tail": "expensive retraining or ad-hoc heuristics"}, {"Head": "Largest publicly available KGs", "Relation": "include", "Tail": "Wikidata and PubGraph"}, {"Head": "LLMs", "Relation": "capture relational knowledge", "Tail": "unevenly across relation types"}, {"Head": "LLM-based KG generation", "Relation": "is affected by", "Tail": "prompt brittleness and task-framing sensitivity"}, {"Head": "Retrieval augmentation", "Relation": "mitigates", "Tail": "inconsistency and knowledge-cutoff issues"}, {"Head": "Retrieval augmentation", "Relation": "introduces", "Tail": "conflicts between retrieved evidence and LLM parametric knowledge"}, {"Head": "LLMs", "Relation": "hallucinate", "Tail": "nonsensical or unfaithful outputs"}, {"Head": "Hallucinations", "Relation": "persist regardless of", "Tail": "model size or training data scale"}, {"Head": "LLMs", "Relation": "fail at", "Tail": "inverse inference (reversal curse)"}, {"Head": "Factuality errors", "Relation": "are distinct from", "Tail": "hallucinations"}, {"Head": "High-stakes domains", "Relation": "require", "Tail": "verification, interpretability, and explainability"}, {"Head": "State-of-the-art LLM capabilities", "Relation": "emerge only when", "Tail": "model size, dataset scale, and compute are large"}, {"Head": "Flawed data sources with misinformation and biases", "Relation": "drive", "Tail": "hallucinations"}, {"Head": "Domain adaptation with fine-tuning", "Relation": "improves", "Tail": "factuality and coherence but risks catastrophic forgetting"}, {"Head": "Continued pretraining", "Relation": "adapts knowledge", "Tail": "more smoothly to a target domain but requires substantial data"}, {"Head": "Research efforts", "Relation": "prioritize", "Tail": "maximizing LLM performance with less data (quality-quantity trade-off)"}, {"Head": "GraphRAG", "Relation": "leverages", "Tail": "knowledge graphs for global sense-making"}, {"Head": "GraphRAG indexing stage", "Relation": "has an LLM build", "Tail": "an entity-level KG and partition it into nested communities"}, {"Head": "GraphRAG querying stage", "Relation": "extracts", "Tail": "a subgraph based on community summaries and the query"}, {"Head": "GraphRAG hierarchical design", "Relation": "reports improvements over", "Tail": "vector-based RAG"}, {"Head": "GraphRAG output accuracy", "Relation": "depends on", "Tail": "coverage, validity, and factuality of the KG"}], "entity_relation_output": "[{\"Head\": \"KG generation\", \"Relation\": \"is differentiated from\", \"Tail\": \"KG extraction\"}, {\"Head\": \"LLM\", \"Relation\": \"plays a pivotal role in\", \"Tail\": \"KG generation\"}, {\"Head\": \"KG generation\", \"Relation\": \"produces\", \"Tail\": \"triples conditioned on input texts\"}, {\"Head\": \"KG generation\", \"Relation\": \"distills knowledge from\", \"Tail\": \"model weights\"}, {\"Head\": \"Rule-based information extraction systems\", \"Relation\": \"demanded\", \"Tail\": \"heavy feature engineering and domain expertise\"}, {\"Head\": \"Modern pipelines\", \"Relation\": \"chain\", \"Tail\": \"named entity recognition, coreference resolution, and relation extraction\"}, {\"Head\": \"Conditional random fields\", \"Relation\": \"are used in\", \"Tail\": \"text preprocessing heuristics\"}, {\"Head\": \"LSTM and CNN\", \"Relation\": \"introduce\", \"Tail\": \"locality bias\"}, {\"Head\": \"Errors\", \"Relation\": \"propagate over\", \"Tail\": \"the pipeline\"}, {\"Head\": \"Embedding-based approach\", \"Relation\": \"trains ML methods on\", \"Tail\": \"knowledge graphs\"}, {\"Head\": \"Embeddings\", \"Relation\": \"enable\", \"Tail\": \"triple completion and link prediction\"}, {\"Head\": \"KG embedding models\", \"Relation\": \"struggle to compose\", \"Tail\": \"long multi-hop chains and handle n-ary/qualified relations\"}, {\"Head\": \"Embedding methods\", \"Relation\": \"assume\", \"Tail\": \"a largely closed-world, static graph\"}, {\"Head\": \"Cold-start entities and evolving KGs\", \"Relation\": \"require\", \"Tail\": \"expensive retraining or ad-hoc heuristics\"}, {\"Head\": \"Largest publicly available KGs\", \"Relation\": \"include\", \"Tail\": \"Wikidata and PubGraph\"}, {\"Head\": \"LLMs\", \"Relation\": \"capture relational knowledge\", \"Tail\": \"unevenly across relation types\"}, {\"Head\": \"LLM-based KG generation\", \"Relation\": \"is affected by\", \"Tail\": \"prompt brittleness and task-framing sensitivity\"}, {\"Head\": \"Retrieval augmentation\", \"Relation\": \"mitigates\", \"Tail\": \"inconsistency and knowledge-cutoff issues\"}, {\"Head\": \"Retrieval augmentation\", \"Relation\": \"introduces\", \"Tail\": \"conflicts between retrieved evidence and LLM parametric knowledge\"}, {\"Head\": \"LLMs\", \"Relation\": \"hallucinate\", \"Tail\": \"nonsensical or unfaithful outputs\"}, {\"Head\": \"Hallucinations\", \"Relation\": \"persist regardless of\", \"Tail\": \"model size or training data scale\"}, {\"Head\": \"LLMs\", \"Relation\": \"fail at\", \"Tail\": \"inverse inference (reversal curse)\"}, {\"Head\": \"Factuality errors\", \"Relation\": \"are distinct from\", \"Tail\": \"hallucinations\"}, {\"Head\": \"High-stakes domains\", \"Relation\": \"require\", \"Tail\": \"verification, interpretability, and explainability\"}, {\"Head\": \"State-of-the-art LLM capabilities\", \"Relation\": \"emerge only when\", \"Tail\": \"model size, dataset scale, and compute are large\"}, {\"Head\": \"Flawed data sources with misinformation and biases\", \"Relation\": \"drive\", \"Tail\": \"hallucinations\"}, {\"Head\": \"Domain adaptation with fine-tuning\", \"Relation\": \"improves\", \"Tail\": \"factuality and coherence but risks catastrophic forgetting\"}, {\"Head\": \"Continued pretraining\", \"Relation\": \"adapts knowledge\", \"Tail\": \"more smoothly to a target domain but requires substantial data\"}, {\"Head\": \"Research efforts\", \"Relation\": \"prioritize\", \"Tail\": \"maximizing LLM performance with less data (quality-quantity trade-off)\"}, {\"Head\": \"GraphRAG\", \"Relation\": \"leverages\", \"Tail\": \"knowledge graphs for global sense-making\"}, {\"Head\": \"GraphRAG indexing stage\", \"Relation\": \"has an LLM build\", \"Tail\": \"an entity-level KG and partition it into nested communities\"}, {\"Head\": \"GraphRAG querying stage\", \"Relation\": \"extracts\", \"Tail\": \"a subgraph based on community summaries and the query\"}, {\"Head\": \"GraphRAG hierarchical design\", \"Relation\": \"reports improvements over\", \"Tail\": \"vector-based RAG\"}, {\"Head\": \"GraphRAG output accuracy\", \"Relation\": \"depends on\", \"Tail\": \"coverage, validity, and factuality of the KG\"}]", "event_entity_dict": [{"Event": "We differentiate KG extraction from KG generation to clarify their advantages limitations and application scopes", "Entity": ["We", "KG extraction", "KG generation"]}, {"Event": "We classify methods where an LLM plays a pivotal role in the KG construction pipeline under the category of KG generation", "Entity": ["We", "LLM", "KG construction pipeline", "KG generation"]}, {"Event": "We refer to all other approaches as KG extraction", "Entity": ["We", "other approaches", "KG extraction"]}, {"Event": "Early rule-based information extraction systems demanded heavy feature engineering and domain expertise", "Entity": ["Early rule-based information extraction systems", "feature engineering", "domain expertise"]}, {"Event": "Modern pipelines sequentially chain machine learning components often relying on structured or semi-structured data", "Entity": ["Modern pipelines", "machine learning components", "structured data", "semi-structured data"]}, {"Event": "These systems require sophisticated text preprocessing heuristics", "Entity": ["These systems", "text preprocessing heuristics"]}, {"Event": "Long short-term memories and convolutional neural networks introduce locality bias", "Entity": ["Long short-term memories", "convolutional neural networks", "locality bias"]}, {"Event": "Errors propagate over the pipeline", "Entity": ["Errors", "pipeline"]}, {"Event": "An embedding-based approach seeks to train ML methods on KGs to capture semantic and structural patterns into embeddings", "Entity": ["embedding-based approach", "ML methods", "KGs", "embeddings"]}, {"Event": "Embeddings enable the model to predict missing links and estimate the likelihood of new relations", "Entity": ["Embeddings", "model", "missing links", "new relations"]}, {"Event": "This approach suffers from selection bias lack of scalability brittleness to KG errors and limited external world knowledge", "Entity": ["This approach", "selection bias", "scalability", "KG errors", "external/world knowledge"]}, {"Event": "Most KG embedding models operate on local triple patterns and struggle to compose long multi-hop chains handle negation or respect ontological constraints", "Entity": ["KG embedding models", "local triple patterns", "multi-hop chains", "negation", "ontological constraints"]}, {"Event": "They also assume a largely closed-world static graph which requires expensive retraining for cold-start entities and evolving KGs", "Entity": ["They", "closed-world static graph", "expensive retraining", "cold-start entities", "evolving KGs"]}, {"Event": "Embedding-based approaches face limitations due to sparsity limited information and vocabulary scale mismatches", "Entity": ["Embedding-based approaches", "sparsity", "limited information", "vocabulary", "scale mismatches"]}, {"Event": "Embedding methods are useful in task-specific applications but fall short in extending KGs on their own", "Entity": ["Embedding methods", "task-specific applications", "KGs"]}, {"Event": "Embedding methods do not generalize well across different KGs", "Entity": ["Embedding methods", "different KGs"]}, {"Event": "Cross-KG use requires costly alignment steps and may still suffer from out-of-vocabulary entities relations and schema drift", "Entity": ["Cross-KG use", "alignment steps", "out-of-vocabulary entities", "out-of-vocabulary relations", "schema drift"]}, {"Event": "Modern research on KG extraction is skewed towards extracting relational knowledge from LLM weights using prompts", "Entity": ["Modern research on KG extraction", "LLM weights", "prompts"]}, {"Event": "The widespread adoption of LLMs can be attributed to their versatility adaptability and ease of use", "Entity": ["LLMs", "versatility", "adaptability", "ease of use"]}, {"Event": "LLMs capture relational knowledge unevenly being more accurate for some types and less accurate for others", "Entity": ["LLMs", "relational knowledge", "some types", "other types"]}, {"Event": "LLMs are brittle with respect to prompts and instruction fine-tuning does not fully address this problem", "Entity": ["LLMs", "prompts", "instruction fine-tuning"]}, {"Event": "KG extraction with prompts is biased towards prompt structure", "Entity": ["KG extraction with prompts", "prompt structure"]}, {"Event": "LLMs are sensitive to task-framing and answer consistency can shift with small syntactic changes and slight prompt variations", "Entity": ["LLMs", "task-framing", "answer consistency", "syntactic changes", "prompt variations"]}, {"Event": "Retrieval augmentation can mitigate inconsistency and knowledge-cutoff issues but introduces conflicts between retrieved evidence and LLM's parametric knowledge", "Entity": ["Retrieval augmentation", "inconsistency", "knowledge-cutoff issues", "retrieved evidence", "LLM's parametric knowledge"]}, {"Event": "LLMs hallucinate producing nonsensical or unfaithful outputs regardless of model size or training data scale", "Entity": ["LLMs", "hallucinations", "model size", "training data scale"]}, {"Event": "Some scholars show that hallucinations may be innate to probabilistic generative methods", "Entity": ["Some scholars", "hallucinations", "probabilistic generative methods"]}, {"Event": "Methods to strengthen LLM reasoning improve accuracy but cannot eliminate nontrivial hallucinations", "Entity": ["Methods to strengthen LLM reasoning", "LLM reasoning", "accuracy", "hallucinations"]}, {"Event": "In KG generation LLMs struggle with inverse inference and may fail to infer inverse relations", "Entity": ["KG generation", "LLMs", "inverse inference", "inverse relations"]}, {"Event": "LLMs are not factually accurate and factuality errors differ from hallucinations", "Entity": ["LLMs", "factuality errors", "hallucinations"]}, {"Event": "Verifying or synthesizing high-quality data at the LLM scale is infeasible creating a size-quality trade-off", "Entity": ["Verifying or synthesizing high-quality data", "LLM scale", "size-quality trade-off"]}, {"Event": "No current LLM offers the factuality needed for trust and even advanced commercial systems make significant factual errors", "Entity": ["current LLMs", "factuality", "advanced commercial systems", "factual errors"]}, {"Event": "In high-stakes domains verification alone is insufficient since outputs must be interpretable and explainable", "Entity": ["high-stakes domains", "verification", "outputs", "interpretability", "explainability"]}, {"Event": "State-of-the-art LLM capabilities emerge only when model size dataset scale and compute reach sufficient magnitude", "Entity": ["state-of-the-art LLM capabilities", "model size", "dataset scale", "compute"]}, {"Event": "Modern pretraining corpora often favor scale over domain fidelity", "Entity": ["Modern pretraining corpora", "scale", "domain fidelity"]}, {"Event": "Flawed data sources with misinformation and biases are a primary driver of hallucinations", "Entity": ["Flawed data sources", "misinformation", "biases", "hallucinations"]}, {"Event": "Domain adaptation with fine-tuning can improve factuality and coherence but risks catastrophic forgetting and cross-domain interference", "Entity": ["Domain adaptation", "fine-tuning", "factuality", "coherence", "catastrophic forgetting", "cross-domain interference"]}, {"Event": "Continued pretraining adapts knowledge more smoothly to a target domain but demands substantial additional data", "Entity": ["Continued pretraining", "target domain", "additional data"]}, {"Event": "Scarcity of diverse high-quality data at the scale required by LLMs is a key barrier to clinical LLM deployment", "Entity": ["Scarcity of diverse high-quality data", "LLMs", "clinical LLM deployment"]}], "event_entity_output": "[{\"Event\": \"We differentiate KG extraction from KG generation to clarify their advantages limitations and application scopes\", \"Entity\": [\"We\", \"KG extraction\", \"KG generation\"]}, {\"Event\": \"We classify methods where an LLM plays a pivotal role in the KG construction pipeline under the category of KG generation\", \"Entity\": [\"We\", \"LLM\", \"KG construction pipeline\", \"KG generation\"]}, {\"Event\": \"We refer to all other approaches as KG extraction\", \"Entity\": [\"We\", \"other approaches\", \"KG extraction\"]}, {\"Event\": \"Early rule-based information extraction systems demanded heavy feature engineering and domain expertise\", \"Entity\": [\"Early rule-based information extraction systems\", \"feature engineering\", \"domain expertise\"]}, {\"Event\": \"Modern pipelines sequentially chain machine learning components often relying on structured or semi-structured data\", \"Entity\": [\"Modern pipelines\", \"machine learning components\", \"structured data\", \"semi-structured data\"]}, {\"Event\": \"These systems require sophisticated text preprocessing heuristics\", \"Entity\": [\"These systems\", \"text preprocessing heuristics\"]}, {\"Event\": \"Long short-term memories and convolutional neural networks introduce locality bias\", \"Entity\": [\"Long short-term memories\", \"convolutional neural networks\", \"locality bias\"]}, {\"Event\": \"Errors propagate over the pipeline\", \"Entity\": [\"Errors\", \"pipeline\"]}, {\"Event\": \"An embedding-based approach seeks to train ML methods on KGs to capture semantic and structural patterns into embeddings\", \"Entity\": [\"embedding-based approach\", \"ML methods\", \"KGs\", \"embeddings\"]}, {\"Event\": \"Embeddings enable the model to predict missing links and estimate the likelihood of new relations\", \"Entity\": [\"Embeddings\", \"model\", \"missing links\", \"new relations\"]}, {\"Event\": \"This approach suffers from selection bias lack of scalability brittleness to KG errors and limited external world knowledge\", \"Entity\": [\"This approach\", \"selection bias\", \"scalability\", \"KG errors\", \"external/world knowledge\"]}, {\"Event\": \"Most KG embedding models operate on local triple patterns and struggle to compose long multi-hop chains handle negation or respect ontological constraints\", \"Entity\": [\"KG embedding models\", \"local triple patterns\", \"multi-hop chains\", \"negation\", \"ontological constraints\"]}, {\"Event\": \"They also assume a largely closed-world static graph which requires expensive retraining for cold-start entities and evolving KGs\", \"Entity\": [\"They\", \"closed-world static graph\", \"expensive retraining\", \"cold-start entities\", \"evolving KGs\"]}, {\"Event\": \"Embedding-based approaches face limitations due to sparsity limited information and vocabulary scale mismatches\", \"Entity\": [\"Embedding-based approaches\", \"sparsity\", \"limited information\", \"vocabulary\", \"scale mismatches\"]}, {\"Event\": \"Embedding methods are useful in task-specific applications but fall short in extending KGs on their own\", \"Entity\": [\"Embedding methods\", \"task-specific applications\", \"KGs\"]}, {\"Event\": \"Embedding methods do not generalize well across different KGs\", \"Entity\": [\"Embedding methods\", \"different KGs\"]}, {\"Event\": \"Cross-KG use requires costly alignment steps and may still suffer from out-of-vocabulary entities relations and schema drift\", \"Entity\": [\"Cross-KG use\", \"alignment steps\", \"out-of-vocabulary entities\", \"out-of-vocabulary relations\", \"schema drift\"]}, {\"Event\": \"Modern research on KG extraction is skewed towards extracting relational knowledge from LLM weights using prompts\", \"Entity\": [\"Modern research on KG extraction\", \"LLM weights\", \"prompts\"]}, {\"Event\": \"The widespread adoption of LLMs can be attributed to their versatility adaptability and ease of use\", \"Entity\": [\"LLMs\", \"versatility\", \"adaptability\", \"ease of use\"]}, {\"Event\": \"LLMs capture relational knowledge unevenly being more accurate for some types and less accurate for others\", \"Entity\": [\"LLMs\", \"relational knowledge\", \"some types\", \"other types\"]}, {\"Event\": \"LLMs are brittle with respect to prompts and instruction fine-tuning does not fully address this problem\", \"Entity\": [\"LLMs\", \"prompts\", \"instruction fine-tuning\"]}, {\"Event\": \"KG extraction with prompts is biased towards prompt structure\", \"Entity\": [\"KG extraction with prompts\", \"prompt structure\"]}, {\"Event\": \"LLMs are sensitive to task-framing and answer consistency can shift with small syntactic changes and slight prompt variations\", \"Entity\": [\"LLMs\", \"task-framing\", \"answer consistency\", \"syntactic changes\", \"prompt variations\"]}, {\"Event\": \"Retrieval augmentation can mitigate inconsistency and knowledge-cutoff issues but introduces conflicts between retrieved evidence and LLM's parametric knowledge\", \"Entity\": [\"Retrieval augmentation\", \"inconsistency\", \"knowledge-cutoff issues\", \"retrieved evidence\", \"LLM's parametric knowledge\"]}, {\"Event\": \"LLMs hallucinate producing nonsensical or unfaithful outputs regardless of model size or training data scale\", \"Entity\": [\"LLMs\", \"hallucinations\", \"model size\", \"training data scale\"]}, {\"Event\": \"Some scholars show that hallucinations may be innate to probabilistic generative methods\", \"Entity\": [\"Some scholars\", \"hallucinations\", \"probabilistic generative methods\"]}, {\"Event\": \"Methods to strengthen LLM reasoning improve accuracy but cannot eliminate nontrivial hallucinations\", \"Entity\": [\"Methods to strengthen LLM reasoning\", \"LLM reasoning\", \"accuracy\", \"hallucinations\"]}, {\"Event\": \"In KG generation LLMs struggle with inverse inference and may fail to infer inverse relations\", \"Entity\": [\"KG generation\", \"LLMs\", \"inverse inference\", \"inverse relations\"]}, {\"Event\": \"LLMs are not factually accurate and factuality errors differ from hallucinations\", \"Entity\": [\"LLMs\", \"factuality errors\", \"hallucinations\"]}, {\"Event\": \"Verifying or synthesizing high-quality data at the LLM scale is infeasible creating a size-quality trade-off\", \"Entity\": [\"Verifying or synthesizing high-quality data\", \"LLM scale\", \"size-quality trade-off\"]}, {\"Event\": \"No current LLM offers the factuality needed for trust and even advanced commercial systems make significant factual errors\", \"Entity\": [\"current LLMs\", \"factuality\", \"advanced commercial systems\", \"factual errors\"]}, {\"Event\": \"In high-stakes domains verification alone is insufficient since outputs must be interpretable and explainable\", \"Entity\": [\"high-stakes domains\", \"verification\", \"outputs\", \"interpretability\", \"explainability\"]}, {\"Event\": \"State-of-the-art LLM capabilities emerge only when model size dataset scale and compute reach sufficient magnitude\", \"Entity\": [\"state-of-the-art LLM capabilities\", \"model size\", \"dataset scale\", \"compute\"]}, {\"Event\": \"Modern pretraining corpora often favor scale over domain fidelity\", \"Entity\": [\"Modern pretraining corpora\", \"scale\", \"domain fidelity\"]}, {\"Event\": \"Flawed data sources with misinformation and biases are a primary driver of hallucinations\", \"Entity\": [\"Flawed data sources\", \"misinformation\", \"biases\", \"hallucinations\"]}, {\"Event\": \"Domain adaptation with fine-tuning can improve factuality and coherence but risks catastrophic forgetting and cross-domain interference\", \"Entity\": [\"Domain adaptation\", \"fine-tuning\", \"factuality\", \"coherence\", \"catastrophic forgetting\", \"cross-domain interference\"]}, {\"Event\": \"Continued pretraining adapts knowledge more smoothly to a target domain but demands substantial additional data\", \"Entity\": [\"Continued pretraining\", \"target domain\", \"additional data\"]}, {\"Event\": \"Scarcity of diverse high-quality data at the scale required by LLMs is a key barrier to clinical LLM deployment\", \"Entity\": [\"Scarcity of diverse high-quality data\", \"LLMs\", \"clinical LLM deployment\"]}]", "event_relation_dict": [{"Head": "Early rule-based information extraction systems demanded heavy feature engineering and domain expertise", "Relation": "before", "Tail": "Modern pipelines sequentially chain machine learning components such as named entity recognition, coreference resolution, and relation extraction"}, {"Head": "Modern pipelines sequentially chain machine learning components such as named entity recognition, coreference resolution, and relation extraction", "Relation": "because", "Tail": "These systems require sophisticated text preprocessing heuristics"}, {"Head": "Errors propagate over the pipeline", "Relation": "as a result", "Tail": "Overall, these methods are very labor-intensive, not fully automatic, and hard to scale"}, {"Head": "An embedding-based approach seeks to train ML methods on KGs to capture semantic and structural patterns", "Relation": "at the same time", "Tail": "Embeddings enable the model to predict missing links and estimate the likelihood of new relations"}, {"Head": "Most KG embedding models operate on local triple patterns", "Relation": "because", "Tail": "They struggle to compose long multi-hop chains, handle negation, or respect ontological constraints"}, {"Head": "Embedding-based approaches assume a largely closed-world, static graph", "Relation": "as a result", "Tail": "Cold-start entities and evolving KGs typically require expensive retraining or ad-hoc heuristics"}, {"Head": "With the tremendous success of LLMs on many NLP tasks, modern research on KG extraction is skewed towards extracting relational knowledge from LLM weights using prompts", "Relation": "because", "Tail": "The widespread adoption of LLMs can be attributed to their versatility across tasks, adaptability to diverse domains, and ease of use"}, {"Head": "LLMs are brittle with respect to prompts", "Relation": "because", "Tail": "KG extraction with prompts is biased towards prompt structure and sensitive to task framing"}, {"Head": "Retrieval augmentation can mitigate inconsistency and knowledge-cutoff issues", "Relation": "after", "Tail": "It introduces new failure modes such as conflicts between retrieved evidence and LLM parametric knowledge and imperfections in retrieval and ranking"}, {"Head": "LLMs hallucinate outputs that are nonsensical or unfaithful to the provided source content", "Relation": "at the same time", "Tail": "Hallucinations persist regardless of model size or training data scale"}, {"Head": "Verifying or synthesizing high-quality data at the LLM scale is infeasible", "Relation": "because", "Tail": "There is a fundamental size-quality trade-off in acquiring reliable training data"}, {"Head": "In the GraphRAG indexing stage an LLM builds an entity-level KG and then partitions the graph into a hierarchy of nested communities", "Relation": "before", "Tail": "In the querying stage GraphRAG extracts a subgraph based on the pre-generated community summaries and the query and uses that subgraph as context to generate answers"}, {"Head": "A poorly constructed KG has incomplete entities or incorrect relationships", "Relation": "as a result", "Tail": "GraphRAG produces fragmented, inaccurate, or nonsensical responses"}], "event_relation_output": "[{\"Head\": \"Early rule-based information extraction systems demanded heavy feature engineering and domain expertise\", \"Relation\": \"before\", \"Tail\": \"Modern pipelines sequentially chain machine learning components such as named entity recognition, coreference resolution, and relation extraction\"}, {\"Head\": \"Modern pipelines sequentially chain machine learning components such as named entity recognition, coreference resolution, and relation extraction\", \"Relation\": \"because\", \"Tail\": \"These systems require sophisticated text preprocessing heuristics\"}, {\"Head\": \"Errors propagate over the pipeline\", \"Relation\": \"as a result\", \"Tail\": \"Overall, these methods are very labor-intensive, not fully automatic, and hard to scale\"}, {\"Head\": \"An embedding-based approach seeks to train ML methods on KGs to capture semantic and structural patterns\", \"Relation\": \"at the same time\", \"Tail\": \"Embeddings enable the model to predict missing links and estimate the likelihood of new relations\"}, {\"Head\": \"Most KG embedding models operate on local triple patterns\", \"Relation\": \"because\", \"Tail\": \"They struggle to compose long multi-hop chains, handle negation, or respect ontological constraints\"}, {\"Head\": \"Embedding-based approaches assume a largely closed-world, static graph\", \"Relation\": \"as a result\", \"Tail\": \"Cold-start entities and evolving KGs typically require expensive retraining or ad-hoc heuristics\"}, {\"Head\": \"With the tremendous success of LLMs on many NLP tasks, modern research on KG extraction is skewed towards extracting relational knowledge from LLM weights using prompts\", \"Relation\": \"because\", \"Tail\": \"The widespread adoption of LLMs can be attributed to their versatility across tasks, adaptability to diverse domains, and ease of use\"}, {\"Head\": \"LLMs are brittle with respect to prompts\", \"Relation\": \"because\", \"Tail\": \"KG extraction with prompts is biased towards prompt structure and sensitive to task framing\"}, {\"Head\": \"Retrieval augmentation can mitigate inconsistency and knowledge-cutoff issues\", \"Relation\": \"after\", \"Tail\": \"It introduces new failure modes such as conflicts between retrieved evidence and LLM parametric knowledge and imperfections in retrieval and ranking\"}, {\"Head\": \"LLMs hallucinate outputs that are nonsensical or unfaithful to the provided source content\", \"Relation\": \"at the same time\", \"Tail\": \"Hallucinations persist regardless of model size or training data scale\"}, {\"Head\": \"Verifying or synthesizing high-quality data at the LLM scale is infeasible\", \"Relation\": \"because\", \"Tail\": \"There is a fundamental size-quality trade-off in acquiring reliable training data\"}, {\"Head\": \"In the GraphRAG indexing stage an LLM builds an entity-level KG and then partitions the graph into a hierarchy of nested communities\", \"Relation\": \"before\", \"Tail\": \"In the querying stage GraphRAG extracts a subgraph based on the pre-generated community summaries and the query and uses that subgraph as context to generate answers\"}, {\"Head\": \"A poorly constructed KG has incomplete entities or incorrect relationships\", \"Relation\": \"as a result\", \"Tail\": \"GraphRAG produces fragmented, inaccurate, or nonsensical responses\"}]"}
{"id": "1", "original_text": " lets a transformer model long-range dependencies in parallel, dramatically speeding up training compared to their predecessors. Their stackable blocks enable scaling to billions of parameters. Due to their scalability and unprecedented versatility on language tasks, transformers currently dominate the NLP field. Yet, the native transformer self-attention module handles only sequential input. ## 2.7.1 Graph Transformer Architecture To enable training of a transformer on graphical input, the graph structure must either be encoded into the input or the attention module must be modified. We do both: (1) encode relation embedding into input graph sequences (see Sec. 2.7.2) and (2) modify attention weights to reflect spatial distance in input graphs (see Sec. 4.2). To implement our model, we take inspiration from Graphormer (Ying et al., 2021) but design alternative graph encodings tailored to language tasks as well. ## 2.7.2 Hierarchical Graph Attention Networks To incorporate semantic relations into GraphMERT , we combine a generic transformer architecture with a hierarchical graph attention network (H-GAT; Xu et al. 2021; Nathani et al. 2019). H-GAT fuses relation embeddings into semantic graph nodes before passing the graph sequences to the transformer layers. The original H-GAT architecture hierarchically combines intra-relation and inter-relation attention to derive node embeddings by aggregating the embeddings of the neighbors of the graph node. To tailor H-GAT to our input (i.e., chain vocabulary graphs that we describe later), we discard the unnecessary inter-relation representations and use the simplified architecture with token embeddings instead of graph node embeddings. In the GraphMERT implementation, given a triple &lt; h, r, t &gt; - head, relation, tail, where head and tail are represented by { h 1 , .., h m } and { t 1 , .., t n } at the token level, for any given tail token t i we have: <!-- formula-not-decoded --> where W r is a learnable relation embedding matrix, a r is a learnable relation embedding, and LeakyReLU is an activation function. <!-- formula-not-decoded --> Then the final node embedding for the tail token is given by: <!-- formula-not-decoded --> Thus, the new tail token t ′ i fuses the relation embedding via W r and a r with its initial tail token embedding t i and all head token embeddings { h 1 , ..., h m } . ## 3 Motivational Example What follows is a motivating example to demonstrate the importance of reliability in our proposed pipeline. To do this, we design a simple 'reverse test' using Unified Medical Language System (UMLS; Bodenreider 2004) triples. First, we sample a ground-truth triple from UMLS: 〈 chronic kidney disease , has\\_finding\\_site , kidney structure 〉 [SNOMED CT United States Edition vocabulary in UMLS lists kidney structure as the only finding site for chronic kidney disease (CKD)]. Next, we manually create a sequence that implies a weak connection between CKD and cerebellar gray matter abnormalities (so that it is appropriate for the associated\\_with relation, i.e., 〈 chronic kidney disease , associated\\_with , cerebellar gray matter 〉 would be an ontologically appropriate triple). We craft this sequence so that it reflects recent medical studies on brain imaging in patients with CKD (Xiao et al., 2024), which show indirect abnormalities in the cerebellar gray matter. Even with this indirect correlation, the logical triple should remain 〈 chronic kidney disease , has\\_finding\\_site , kidney structure 〉 , as found in UMLS. Next, we prompt strong general-purpose LLMs (Gemini 2.5 Pro, Claude Sonnet 4.5, GPT-5, and Grok 4) to infer the triple from the sentence. Despite fluent rationales, these models frequently hallucinate relations or return ontologically invalid outputs, yielding triples that are non-factual or misaligned with UMLS constraints. Their outputs seem to show spurious correlations instead of semantic connections. In contrast, our GraphMERT model, trained as detailed in the following sections, recovers the correct UMLS triple from the same sentence. This example underscores that adhering to biomedical ontologies matters: Terms like 'gray matter' should be used with an associated\\_with relation rather than being miscast with finding\\_site ; structure-aware training is essential for preventing such errors. This is only possible with the proposed GraphMERT pipeline. Prompt. Please complete the following medical KG triple (head, relation, tail): (chronic kidney disease, has\\_finding\\_site, ...) based on the sequence: Chronic kidney disease (CKD) is a renal disorder. However, neuroimaging cohorts of people with CKD have reported subtle, group-level abnormalities within the cerebellar gray matter. Studies note modest reductions or regional alterations in cerebellar gray-matter volume, cortical thickness, and diffusion metrics. These observations are heterogeneous and not diagnostic, yet they place observable findings at the cerebellar gray matter in CKD. Thus, CKD may be associated with cerebellar gray-matter changes. Different LLMs produced mostly wrong answers to this triple-generation query: Gemini 2.5 Pro: (chronic kidney disease, has\\_finding\\_site, cerebellar gray matter) The provided text explicitly states that neuroimaging studies 'place observable findings at the cerebellar gray matter in CKD.' Claude Sonnet 4.5: Based on the provided sequence, the medical KG triple should be completed as: (pediatric chronic kidney disease (pckd), has\\_finding\\_site, kidney) ## Reasoning: The primary and defining finding site for chronic kidney disease is the kidney itself, as explicitly stated in the passage: 'Chronic kidney disease (CKD) is a renal disorder.' While the passage does discuss secondary neuroimaging findings in the cerebellar gray matter, these are described as: - Subtle and group-level abnormalities - Heterogeneous observations - Not diagnostic - Modest and regional alterations In contrast, the kidney is the primary pathological site where CKD occurs by definition. The cerebellar changes represent associated findings or potential complications, but they are not the primary finding site of the disease entity itself. For medical knowledge graphs, the has\\_finding\\_site relation typically indicates the primary anatomical location where the disease process occurs, which for CKD is definitively the kidney. If you needed to represent the cerebellar findings, that would be better captured with a different relation such as has\\_associated\\_finding or may\\_affect, rather than has\\_finding\\_site. GPT-5: Based on the medical knowledge graph triple format and the provided sequence, the completed triple would be: (chronic kidney disease, has\\_finding\\_site, cerebellar gray matter) This is based on the text where chronic kidney disease (CKD) is associated with observable findings in the cerebellar gray matter, specifically mentioning reductions in cerebellar gray-matter volume, cortical thickness, and diffusion metrics. Grok 4: Based on the medical knowledge graph triple format and the provided sequence, the completed triple would be: (chronic kidney disease, has\\_finding\\_site, cerebellar gray matter) The triple (chronic kidney disease, has\\_finding\\_site, cerebellar gray matter) is completed based on the provided sequence, which states that neuroimaging studies of chronic kidney disease (CKD) patients have identified subtle abnormalities in the cerebellar gray matter, such as reductions in volume, cortical thickness, and diffusion metrics. The relation 'has\\_finding\\_site' indicates the anatomical location where these abnormalities are observed, making 'cerebellar gray matter' the appropriate tail entity. Next, based on the top 20 predicted tokens from our model with top-5 softmax probabilities of 0.789, 0.173, 0.01, 0.003, 0.003, our pipeline yields 'kidneys' (with Gemini 2.5 Pro as a helper LLM), which corresponds to the UMLS gold answer: ## GraphMERT: structure, kidney, system, function, renal, disease, heart, kidneys, of, physiology, arterial, underlying, pancreas, organ, impaired, health, cerebrovascular, pathophysiology, injury, morphology ## Gemini 2.5 Pro reasons over GraphMERT triple candidates: ## 1. Analyze the Input: Sequence: The text describes Chronic Kidney Disease (CKD) as a 'renal disorder,' indicating its primary location is the kidneys. It also explicitly mentions that in people with CKD, neuroimaging has found 'abnormalities within the cerebellar gray matter.' . . . ## 2. Generate Potential Tails: The most obvious and primary finding site for a 'renal disorder' is the kidneys. The token list contains kidneys. This is a very strong candidate. I can also form renal system from the tokens renal and system. This is also correct but is more general than kidneys. Specificity is preferred. ## 3. Verify and Filter Tails: Candidate 1: kidneys - Factual: Yes, CKD is a disease of the kidneys. - Supported by sequence: Yes, the text calls CKD a 'renal disorder.' - Valuable &amp; Specific: Yes, it pinpoints the primary organ affected. It is specific and not vague. - Uses only candidate tokens: Yes, 'kidneys' is in the list. - Conclusion: This is a high-quality, factual tail. . . . The text also mentions findings in the 'cerebellar gray matter.' I can look for tokens to construct this. Cerebrovascular is available, and structure is available. I could potentially form cerebrovascular structure. However, the cerebellum is not primarily a vascular structure, and this tail is very general and not as precise as the information in the text ('cerebellar gray matter'). More importantly, the key tokens cerebellar and gray matter are missing. Therefore, I cannot accurately represent this secondary finding site. . . . 4. Final Decision: The best and most directly supported tail I can construct from the given tokens is kidneys. While the text mentions other sites, the provided tokens do not allow for their accurate creation. As we noted above, there is an indirect correlation between CKD and cerebellar gray matter in the source sentence; however, it does not imply the triple suggested by most of the LLMs in their responses. This illustrative case reinforces recent evidence that LLMs regrettably answer based on word correlations in language rather than honing in on the semantic meaning of text and vernacular syntax, making them surprisingly brittle (Li et al., 2020). Recent works also show that, despite the high accuracy on various language tasks, when examined more closely, LLMs are only learning surface-level information, such as word overlap, perplexity, sentence lengths, etc., and not the underlying task at hand (Durmus et al., 2022). Taken together, the example above and the additional results we present later make us skeptical about deploying these models in high-stakes use cases for constructing reliable, domain-specific KGs. ## 4 GraphMERT KG-extraction Framework This section introduces the KG extraction pipeline and the GraphMERT architecture. It also introduces an LLM-based KG generation method that is used to obtain the baseline KG. Figure 2: Overview of the GraphMERT framework. It is trained on the fusion of syntactic and semantic examples (II) and augments syntactic data with semantic tails (I) ; an LLM helps determine the linguistic structure of tails proposed by GraphMERT (III) . (I) : Chain graph (Ic) combines syntactic knowledge from text corpora (Ib) with semantic examples and relations from a seed KG (Ia) : Roots hold syntactic knowledge (in orange), sparse leaves hold semantic examples (in blue), and edges encode semantic relations (purple arrows). (II) : GraphMERT is trained on chain graphs to align semantic examples with their syntactic context (IIa) . It then predicts novel semantic token completions for chain graphs without injections, using their syntactic information as context (IIb) . (III) : An LLM combines raw semantic token completions from GraphMERT into grammatically well-formed triple tails, producing complete triples. After filtering them by similarity to the source syntactic context and dropping duplicate triples, we obtain the final KG. <!-- image --> One of the earliest studies on relational factual knowledge extraction from pre-trained encoder-only models used cloze-style prompts, as discussed by Petroni et al. (2019). E.g., ' John Lennon plays [MASK]' to complete 〈 John Lennon, PersonInstrument, ? 〉 . Later work showed that such a prompt-based retrieval is heavily biased toward prompt syntax rather than factual content (Cao et al., 2021). For instance, GarcíaSilva et al. (2023) report that BERT (Devlin et al., 2019) completes the above example with ' guitar, piano, drums, himself, harmonica ,' where syntactically plausible but non-factual predictions like ' drums ' rank high and, surprisingly, more specific prompts, such as ' John Lennon plays instrument [MASK] ,' produce irrelevant outputs like ' here, there, too, himself, onstage . ' These shortcomings stem from the syntactic form of the prompt overshadowing the factual knowledge of the model, which is mostly semantic . Our key innovation overcomes this obstacle by implanting relations into an encoder via graph attention and training relation embeddings in a dedicated semantic space under the unified MLM + MNM objectives. Our approach directly teaches the model relational knowledge abstracted away from prompt syntax. In parallel, GraphMERT learns the syntactic structure too and leverages syntactic information as a context for semantic knowledge. A high-level overview of the pipeline is shown in Fig. 2. GraphMERT is a multi-directional enc", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "Transformer model", "Relation": "learns", "Tail": "long-range dependencies in parallel"}, {"Head": "Stackable blocks", "Relation": "enable", "Tail": "scaling to billions of parameters"}, {"Head": "Transformers", "Relation": "dominate", "Tail": "NLP field"}, {"Head": "Native transformer self-attention module", "Relation": "handles", "Tail": "sequential input only"}, {"Head": "Graph Transformer Architecture", "Relation": "requires", "Tail": "graph structure encoded into input or modified attention module"}, {"Head": "GraphMERT", "Relation": "encodes", "Tail": "relation embedding into input graph sequences"}, {"Head": "GraphMERT", "Relation": "modifies", "Tail": "attention weights to reflect spatial distance in input graphs"}, {"Head": "GraphMERT", "Relation": "takes inspiration from", "Tail": "Graphormer (Ying et al., 2021)"}, {"Head": "Hierarchical Graph Attention Network (H-GAT)", "Relation": "fuses", "Tail": "relation embeddings into semantic graph nodes"}, {"Head": "Original H-GAT architecture", "Relation": "combines", "Tail": "intra-relation and inter-relation attention"}, {"Head": "GraphMERT implementation", "Relation": "discards", "Tail": "inter-relation representations"}, {"Head": "GraphMERT implementation", "Relation": "uses", "Tail": "token embeddings instead of graph node embeddings"}, {"Head": "W_r", "Relation": "is", "Tail": "learnable relation embedding matrix"}, {"Head": "a_r", "Relation": "is", "Tail": "learnable relation embedding"}, {"Head": "LeakyReLU", "Relation": "functions as", "Tail": "activation function"}, {"Head": "UMLS triples", "Relation": "are used in", "Tail": "reverse test"}, {"Head": "UMLS gold triple", "Relation": "asserts", "Tail": "〈chronic kidney disease, has_finding_site, kidney structure〉"}, {"Head": "Medical studies (Xiao et al., 2024)", "Relation": "report", "Tail": "indirect abnormalities in cerebellar gray matter in CKD patients"}, {"Head": "LLMs (Gemini 2.5 Pro, Claude Sonnet 4.5, GPT-5, Grok 4)", "Relation": "frequently produce", "Tail": "hallucinated or ontologically invalid KG triples"}, {"Head": "GraphMERT model", "Relation": "recovers", "Tail": "correct UMLS triple from the same sentence"}, {"Head": "Terms like 'gray matter'", "Relation": "should use", "Tail": "associated_with relation rather than has_finding_site"}, {"Head": "GraphMERT pipeline", "Relation": "yields", "Tail": "'kidneys' as top predicted tail"}, {"Head": "Gemini 2.5 Pro", "Relation": "reasons over", "Tail": "GraphMERT triple candidates"}, {"Head": "GraphMERT KG-extraction Framework", "Relation": "trains on", "Tail": "fusion of syntactic and semantic examples"}, {"Head": "Chain graph (Ic)", "Relation": "combines", "Tail": "syntactic knowledge from text corpora with semantic examples and relations from seed KG"}, {"Head": "LLM helper", "Relation": "combines", "Tail": "raw semantic token completions into grammatically well-formed triple tails"}, {"Head": "Cloze-style prompts (Petroni et al., 2019)", "Relation": "were used to", "Tail": "extract relational factual knowledge from pre-trained encoder-only models"}, {"Head": "BERT", "Relation": "completes", "Tail": "cloze examples with syntactically plausible but non-factual tokens"}, {"Head": "Our approach", "Relation": "implants", "Tail": "relations into an encoder via graph attention and trains relation embeddings in semantic space"}, {"Head": "GraphMERT", "Relation": "learns", "Tail": "syntactic structure and leverages syntactic information as context for semantic knowledge"}], "entity_relation_output": "[{\"Head\": \"Transformer model\", \"Relation\": \"learns\", \"Tail\": \"long-range dependencies in parallel\"}, {\"Head\": \"Stackable blocks\", \"Relation\": \"enable\", \"Tail\": \"scaling to billions of parameters\"}, {\"Head\": \"Transformers\", \"Relation\": \"dominate\", \"Tail\": \"NLP field\"}, {\"Head\": \"Native transformer self-attention module\", \"Relation\": \"handles\", \"Tail\": \"sequential input only\"}, {\"Head\": \"Graph Transformer Architecture\", \"Relation\": \"requires\", \"Tail\": \"graph structure encoded into input or modified attention module\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"encodes\", \"Tail\": \"relation embedding into input graph sequences\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"modifies\", \"Tail\": \"attention weights to reflect spatial distance in input graphs\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"takes inspiration from\", \"Tail\": \"Graphormer (Ying et al., 2021)\"}, {\"Head\": \"Hierarchical Graph Attention Network (H-GAT)\", \"Relation\": \"fuses\", \"Tail\": \"relation embeddings into semantic graph nodes\"}, {\"Head\": \"Original H-GAT architecture\", \"Relation\": \"combines\", \"Tail\": \"intra-relation and inter-relation attention\"}, {\"Head\": \"GraphMERT implementation\", \"Relation\": \"discards\", \"Tail\": \"inter-relation representations\"}, {\"Head\": \"GraphMERT implementation\", \"Relation\": \"uses\", \"Tail\": \"token embeddings instead of graph node embeddings\"}, {\"Head\": \"W_r\", \"Relation\": \"is\", \"Tail\": \"learnable relation embedding matrix\"}, {\"Head\": \"a_r\", \"Relation\": \"is\", \"Tail\": \"learnable relation embedding\"}, {\"Head\": \"LeakyReLU\", \"Relation\": \"functions as\", \"Tail\": \"activation function\"}, {\"Head\": \"UMLS triples\", \"Relation\": \"are used in\", \"Tail\": \"reverse test\"}, {\"Head\": \"UMLS gold triple\", \"Relation\": \"asserts\", \"Tail\": \"〈chronic kidney disease, has_finding_site, kidney structure〉\"}, {\"Head\": \"Medical studies (Xiao et al., 2024)\", \"Relation\": \"report\", \"Tail\": \"indirect abnormalities in cerebellar gray matter in CKD patients\"}, {\"Head\": \"LLMs (Gemini 2.5 Pro, Claude Sonnet 4.5, GPT-5, Grok 4)\", \"Relation\": \"frequently produce\", \"Tail\": \"hallucinated or ontologically invalid KG triples\"}, {\"Head\": \"GraphMERT model\", \"Relation\": \"recovers\", \"Tail\": \"correct UMLS triple from the same sentence\"}, {\"Head\": \"Terms like 'gray matter'\", \"Relation\": \"should use\", \"Tail\": \"associated_with relation rather than has_finding_site\"}, {\"Head\": \"GraphMERT pipeline\", \"Relation\": \"yields\", \"Tail\": \"'kidneys' as top predicted tail\"}, {\"Head\": \"Gemini 2.5 Pro\", \"Relation\": \"reasons over\", \"Tail\": \"GraphMERT triple candidates\"}, {\"Head\": \"GraphMERT KG-extraction Framework\", \"Relation\": \"trains on\", \"Tail\": \"fusion of syntactic and semantic examples\"}, {\"Head\": \"Chain graph (Ic)\", \"Relation\": \"combines\", \"Tail\": \"syntactic knowledge from text corpora with semantic examples and relations from seed KG\"}, {\"Head\": \"LLM helper\", \"Relation\": \"combines\", \"Tail\": \"raw semantic token completions into grammatically well-formed triple tails\"}, {\"Head\": \"Cloze-style prompts (Petroni et al., 2019)\", \"Relation\": \"were used to\", \"Tail\": \"extract relational factual knowledge from pre-trained encoder-only models\"}, {\"Head\": \"BERT\", \"Relation\": \"completes\", \"Tail\": \"cloze examples with syntactically plausible but non-factual tokens\"}, {\"Head\": \"Our approach\", \"Relation\": \"implants\", \"Tail\": \"relations into an encoder via graph attention and trains relation embeddings in semantic space\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"learns\", \"Tail\": \"syntactic structure and leverages syntactic information as context for semantic knowledge\"}]", "event_entity_dict": [{"Event": "lets a transformer model long-range dependencies in parallel, dramatically speeding up training compared to their predecessors.", "Entity": ["transformer model", "long-range dependencies", "training", "predecessors"]}, {"Event": "Their stackable blocks enable scaling to billions of parameters.", "Entity": ["stackable blocks", "billions of parameters"]}, {"Event": "Due to their scalability and unprecedented versatility on language tasks, transformers currently dominate the NLP field.", "Entity": ["scalability", "versatility", "language tasks", "transformers", "NLP field"]}, {"Event": "Yet, the native transformer self-attention module handles only sequential input.", "Entity": ["native transformer self-attention module", "sequential input"]}, {"Event": "To enable training of a transformer on graphical input, the graph structure must either be encoded into the input or the attention module must be modified.", "Entity": ["training of a transformer", "graphical input", "graph structure", "input", "attention module"]}, {"Event": "We do both: (1) encode relation embedding into input graph sequences and (2) modify attention weights to reflect spatial distance in input graphs.", "Entity": ["we", "relation embedding", "input graph sequences", "attention weights", "spatial distance", "input graphs"]}, {"Event": "To implement our model, we take inspiration from Graphormer (Ying et al., 2021) but design alternative graph encodings tailored to language tasks as well.", "Entity": ["our model", "Graphormer", "alternative graph encodings", "language tasks"]}, {"Event": "To incorporate semantic relations into GraphMERT, we combine a generic transformer architecture with a hierarchical graph attention network (H-GAT).", "Entity": ["semantic relations", "GraphMERT", "generic transformer architecture", "hierarchical graph attention network", "H-GAT"]}, {"Event": "H-GAT fuses relation embeddings into semantic graph nodes before passing the graph sequences to the transformer layers.", "Entity": ["H-GAT", "relation embeddings", "semantic graph nodes", "graph sequences", "transformer layers"]}, {"Event": "The original H-GAT architecture hierarchically combines intra-relation and inter-relation attention to derive node embeddings by aggregating the embeddings of the neighbors of the graph node.", "Entity": ["original H-GAT architecture", "intra-relation attention", "inter-relation attention", "node embeddings", "embeddings of the neighbors", "graph node"]}, {"Event": "To tailor H-GAT to our input, we discard the unnecessary inter-relation representations and use the simplified architecture with token embeddings instead of graph node embeddings.", "Entity": ["H-GAT", "input", "inter-relation representations", "simplified architecture", "token embeddings", "graph node embeddings"]}, {"Event": "In the GraphMERT implementation, given a triple < h, r, t > - head, relation, tail, where head and tail are represented by { h1, .., hm } and { t1, .., tn } at the token level, for any given tail token ti we have: where Wr is a learnable relation embedding matrix, ar is a learnable relation embedding, and LeakyReLU is an activation function.", "Entity": ["GraphMERT implementation", "triple", "h", "r", "t", "head", "relation", "tail", "head tokens {h1..hm}", "tail tokens {t1..tn}", "tail token ti", "Wr", "relation embedding matrix", "ar", "relation embedding", "LeakyReLU", "activation function"]}, {"Event": "Then the final node embedding for the tail token is given by:", "Entity": ["final node embedding", "tail token"]}, {"Event": "Thus, the new tail token t'i fuses the relation embedding via Wr and ar with its initial tail token embedding ti and all head token embeddings { h1, ..., hm }.", "Entity": ["new tail token t'i", "relation embedding", "Wr", "ar", "initial tail token embedding ti", "head token embeddings {h1..hm}"]}, {"Event": "What follows is a motivating example to demonstrate the importance of reliability in our proposed pipeline.", "Entity": ["motivating example", "importance of reliability", "proposed pipeline"]}, {"Event": "To do this, we design a simple 'reverse test' using Unified Medical Language System (UMLS) triples.", "Entity": ["we", "simple 'reverse test'", "Unified Medical Language System", "UMLS triples"]}, {"Event": "First, we sample a ground-truth triple from UMLS: 〈 chronic kidney disease, has_finding_site, kidney structure 〉.", "Entity": ["we", "ground-truth triple", "UMLS", "chronic kidney disease", "has_finding_site", "kidney structure"]}, {"Event": "Next, we manually create a sequence that implies a weak connection between CKD and cerebellar gray matter abnormalities.", "Entity": ["we", "manually created sequence", "CKD", "cerebellar gray matter abnormalities"]}, {"Event": "We craft this sequence so that it reflects recent medical studies on brain imaging in patients with CKD, which show indirect abnormalities in the cerebellar gray matter.", "Entity": ["we", "sequence", "recent medical studies", "brain imaging", "patients with CKD", "indirect abnormalities", "cerebellar gray matter"]}, {"Event": "Even with this indirect correlation, the logical triple should remain 〈 chronic kidney disease, has_finding_site, kidney structure 〉, as found in UMLS.", "Entity": ["indirect correlation", "logical triple", "chronic kidney disease", "has_finding_site", "kidney structure", "UMLS"]}, {"Event": "Next, we prompt strong general-purpose LLMs (Gemini 2.5 Pro, Claude Sonnet 4.5, GPT-5, and Grok 4) to infer the triple from the sentence.", "Entity": ["we", "general-purpose LLMs", "Gemini 2.5 Pro", "Claude Sonnet 4.5", "GPT-5", "Grok 4", "triple", "sentence"]}, {"Event": "Despite fluent rationales, these models frequently hallucinate relations or return ontologically invalid outputs, yielding triples that are non-factual or misaligned with UMLS constraints.", "Entity": ["models", "fluent rationales", "hallucinated relations", "ontologically invalid outputs", "triples", "UMLS constraints"]}, {"Event": "Their outputs seem to show spurious correlations instead of semantic connections.", "Entity": ["their outputs", "spurious correlations", "semantic connections"]}, {"Event": "In contrast, our GraphMERT model, trained as detailed in the following sections, recovers the correct UMLS triple from the same sentence.", "Entity": ["GraphMERT model", "training", "following sections", "correct UMLS triple", "sentence"]}, {"Event": "This example underscores that adhering to biomedical ontologies matters.", "Entity": ["example", "adhering to biomedical ontologies"]}, {"Event": "Terms like 'gray matter' should be used with an associated_with relation rather than being miscast with finding_site.", "Entity": ["terms 'gray matter'", "associated_with relation", "finding_site"]}, {"Event": "Structure-aware training is essential for preventing such errors.", "Entity": ["structure-aware training", "errors"]}, {"Event": "This is only possible with the proposed GraphMERT pipeline.", "Entity": ["proposed GraphMERT pipeline"]}, {"Event": "Please complete the following medical KG triple (head, relation, tail): (chronic kidney disease, has_finding_site, ...) based on the sequence: Chronic kidney disease (CKD) is a renal disorder.", "Entity": ["medical KG triple", "chronic kidney disease", "has_finding_site", "sequence", "Chronic kidney disease (CKD)", "renal disorder"]}], "event_entity_output": "[{\"Event\": \"lets a transformer model long-range dependencies in parallel, dramatically speeding up training compared to their predecessors.\", \"Entity\": [\"transformer model\", \"long-range dependencies\", \"training\", \"predecessors\"]}, {\"Event\": \"Their stackable blocks enable scaling to billions of parameters.\", \"Entity\": [\"stackable blocks\", \"billions of parameters\"]}, {\"Event\": \"Due to their scalability and unprecedented versatility on language tasks, transformers currently dominate the NLP field.\", \"Entity\": [\"scalability\", \"versatility\", \"language tasks\", \"transformers\", \"NLP field\"]}, {\"Event\": \"Yet, the native transformer self-attention module handles only sequential input.\", \"Entity\": [\"native transformer self-attention module\", \"sequential input\"]}, {\"Event\": \"To enable training of a transformer on graphical input, the graph structure must either be encoded into the input or the attention module must be modified.\", \"Entity\": [\"training of a transformer\", \"graphical input\", \"graph structure\", \"input\", \"attention module\"]}, {\"Event\": \"We do both: (1) encode relation embedding into input graph sequences and (2) modify attention weights to reflect spatial distance in input graphs.\", \"Entity\": [\"we\", \"relation embedding\", \"input graph sequences\", \"attention weights\", \"spatial distance\", \"input graphs\"]}, {\"Event\": \"To implement our model, we take inspiration from Graphormer (Ying et al., 2021) but design alternative graph encodings tailored to language tasks as well.\", \"Entity\": [\"our model\", \"Graphormer\", \"alternative graph encodings\", \"language tasks\"]}, {\"Event\": \"To incorporate semantic relations into GraphMERT, we combine a generic transformer architecture with a hierarchical graph attention network (H-GAT).\", \"Entity\": [\"semantic relations\", \"GraphMERT\", \"generic transformer architecture\", \"hierarchical graph attention network\", \"H-GAT\"]}, {\"Event\": \"H-GAT fuses relation embeddings into semantic graph nodes before passing the graph sequences to the transformer layers.\", \"Entity\": [\"H-GAT\", \"relation embeddings\", \"semantic graph nodes\", \"graph sequences\", \"transformer layers\"]}, {\"Event\": \"The original H-GAT architecture hierarchically combines intra-relation and inter-relation attention to derive node embeddings by aggregating the embeddings of the neighbors of the graph node.\", \"Entity\": [\"original H-GAT architecture\", \"intra-relation attention\", \"inter-relation attention\", \"node embeddings\", \"embeddings of the neighbors\", \"graph node\"]}, {\"Event\": \"To tailor H-GAT to our input, we discard the unnecessary inter-relation representations and use the simplified architecture with token embeddings instead of graph node embeddings.\", \"Entity\": [\"H-GAT\", \"input\", \"inter-relation representations\", \"simplified architecture\", \"token embeddings\", \"graph node embeddings\"]}, {\"Event\": \"In the GraphMERT implementation, given a triple < h, r, t > - head, relation, tail, where head and tail are represented by { h1, .., hm } and { t1, .., tn } at the token level, for any given tail token ti we have: where Wr is a learnable relation embedding matrix, ar is a learnable relation embedding, and LeakyReLU is an activation function.\", \"Entity\": [\"GraphMERT implementation\", \"triple\", \"h\", \"r\", \"t\", \"head\", \"relation\", \"tail\", \"head tokens {h1..hm}\", \"tail tokens {t1..tn}\", \"tail token ti\", \"Wr\", \"relation embedding matrix\", \"ar\", \"relation embedding\", \"LeakyReLU\", \"activation function\"]}, {\"Event\": \"Then the final node embedding for the tail token is given by:\", \"Entity\": [\"final node embedding\", \"tail token\"]}, {\"Event\": \"Thus, the new tail token t'i fuses the relation embedding via Wr and ar with its initial tail token embedding ti and all head token embeddings { h1, ..., hm }.\", \"Entity\": [\"new tail token t'i\", \"relation embedding\", \"Wr\", \"ar\", \"initial tail token embedding ti\", \"head token embeddings {h1..hm}\"]}, {\"Event\": \"What follows is a motivating example to demonstrate the importance of reliability in our proposed pipeline.\", \"Entity\": [\"motivating example\", \"importance of reliability\", \"proposed pipeline\"]}, {\"Event\": \"To do this, we design a simple 'reverse test' using Unified Medical Language System (UMLS) triples.\", \"Entity\": [\"we\", \"simple 'reverse test'\", \"Unified Medical Language System\", \"UMLS triples\"]}, {\"Event\": \"First, we sample a ground-truth triple from UMLS: 〈 chronic kidney disease, has_finding_site, kidney structure 〉.\", \"Entity\": [\"we\", \"ground-truth triple\", \"UMLS\", \"chronic kidney disease\", \"has_finding_site\", \"kidney structure\"]}, {\"Event\": \"Next, we manually create a sequence that implies a weak connection between CKD and cerebellar gray matter abnormalities.\", \"Entity\": [\"we\", \"manually created sequence\", \"CKD\", \"cerebellar gray matter abnormalities\"]}, {\"Event\": \"We craft this sequence so that it reflects recent medical studies on brain imaging in patients with CKD, which show indirect abnormalities in the cerebellar gray matter.\", \"Entity\": [\"we\", \"sequence\", \"recent medical studies\", \"brain imaging\", \"patients with CKD\", \"indirect abnormalities\", \"cerebellar gray matter\"]}, {\"Event\": \"Even with this indirect correlation, the logical triple should remain 〈 chronic kidney disease, has_finding_site, kidney structure 〉, as found in UMLS.\", \"Entity\": [\"indirect correlation\", \"logical triple\", \"chronic kidney disease\", \"has_finding_site\", \"kidney structure\", \"UMLS\"]}, {\"Event\": \"Next, we prompt strong general-purpose LLMs (Gemini 2.5 Pro, Claude Sonnet 4.5, GPT-5, and Grok 4) to infer the triple from the sentence.\", \"Entity\": [\"we\", \"general-purpose LLMs\", \"Gemini 2.5 Pro\", \"Claude Sonnet 4.5\", \"GPT-5\", \"Grok 4\", \"triple\", \"sentence\"]}, {\"Event\": \"Despite fluent rationales, these models frequently hallucinate relations or return ontologically invalid outputs, yielding triples that are non-factual or misaligned with UMLS constraints.\", \"Entity\": [\"models\", \"fluent rationales\", \"hallucinated relations\", \"ontologically invalid outputs\", \"triples\", \"UMLS constraints\"]}, {\"Event\": \"Their outputs seem to show spurious correlations instead of semantic connections.\", \"Entity\": [\"their outputs\", \"spurious correlations\", \"semantic connections\"]}, {\"Event\": \"In contrast, our GraphMERT model, trained as detailed in the following sections, recovers the correct UMLS triple from the same sentence.\", \"Entity\": [\"GraphMERT model\", \"training\", \"following sections\", \"correct UMLS triple\", \"sentence\"]}, {\"Event\": \"This example underscores that adhering to biomedical ontologies matters.\", \"Entity\": [\"example\", \"adhering to biomedical ontologies\"]}, {\"Event\": \"Terms like 'gray matter' should be used with an associated_with relation rather than being miscast with finding_site.\", \"Entity\": [\"terms 'gray matter'\", \"associated_with relation\", \"finding_site\"]}, {\"Event\": \"Structure-aware training is essential for preventing such errors.\", \"Entity\": [\"structure-aware training\", \"errors\"]}, {\"Event\": \"This is only possible with the proposed GraphMERT pipeline.\", \"Entity\": [\"proposed GraphMERT pipeline\"]}, {\"Event\": \"Please complete the following medical KG triple (head, relation, tail): (chronic kidney disease, has_finding_site, ...) based on the sequence: Chronic kidney disease (CKD) is a renal disorder.\", \"Entity\": [\"medical KG triple\", \"chronic kidney disease\", \"has_finding_site\", \"sequence\", \"Chronic kidney disease (CKD)\", \"renal disorder\"]}]", "event_relation_dict": [{"Head": "Transformers let a model learn long-range dependencies in parallel", "Relation": "as a result", "Tail": "training is dramatically sped up compared to their predecessors"}, {"Head": "Their stackable blocks enable scaling to billions of parameters", "Relation": "because", "Tail": "transformers currently dominate the NLP field"}, {"Head": "The native transformer self-attention module handles only sequential input", "Relation": "therefore", "Tail": "to enable training of a transformer on graphical input the graph structure must either be encoded into the input or the attention module must be modified"}, {"Head": "We encode relation embedding into input graph sequences", "Relation": "at the same time", "Tail": "we modify attention weights to reflect spatial distance in input graphs"}, {"Head": "We take inspiration from Graphormer", "Relation": "because", "Tail": "we implement our model with alternative graph encodings tailored to language tasks"}, {"Head": "H-GAT fuses relation embeddings into semantic graph nodes", "Relation": "before", "Tail": "the graph sequences are passed to the transformer layers"}, {"Head": "We discard unnecessary inter-relation representations and use a simplified architecture with token embeddings", "Relation": "because", "Tail": "we tailor H-GAT to chain vocabulary graphs"}, {"Head": "The new tail token fuses the relation embedding with its initial tail token embedding and all head token embeddings", "Relation": "as a result", "Tail": "the tail token embedding integrates relation and head token information"}, {"Head": "We design a simple reverse test using UMLS triples", "Relation": "before", "Tail": "we sample a ground-truth triple from UMLS"}, {"Head": "We manually create a sequence that implies a weak connection between CKD and cerebellar gray matter", "Relation": "because", "Tail": "we want an example appropriate for the associated_with relation"}, {"Head": "We prompt strong general-purpose LLMs to infer the triple from the sentence", "Relation": "after", "Tail": "these models frequently hallucinate relations or return ontologically invalid outputs"}, {"Head": "These models frequently hallucinate relations or return ontologically invalid outputs", "Relation": "as a result", "Tail": "their outputs show spurious correlations instead of semantic connections"}, {"Head": "Our GraphMERT model recovers the correct UMLS triple from the same sentence", "Relation": "in contrast to", "Tail": "strong general-purpose LLMs that produced non-factual or misaligned triples"}, {"Head": "This example underscores that adhering to biomedical ontologies matters", "Relation": "because", "Tail": "structure-aware training is essential for preventing errors like miscasting gray matter with finding_site"}, {"Head": "GraphMERT is trained on the fusion of syntactic and semantic examples and augments syntactic data with semantic tails", "Relation": "therefore", "Tail": "GraphMERT can predict novel semantic token completions using syntactic information as context"}], "event_relation_output": "[{\"Head\": \"Transformers let a model learn long-range dependencies in parallel\", \"Relation\": \"as a result\", \"Tail\": \"training is dramatically sped up compared to their predecessors\"}, {\"Head\": \"Their stackable blocks enable scaling to billions of parameters\", \"Relation\": \"because\", \"Tail\": \"transformers currently dominate the NLP field\"}, {\"Head\": \"The native transformer self-attention module handles only sequential input\", \"Relation\": \"therefore\", \"Tail\": \"to enable training of a transformer on graphical input the graph structure must either be encoded into the input or the attention module must be modified\"}, {\"Head\": \"We encode relation embedding into input graph sequences\", \"Relation\": \"at the same time\", \"Tail\": \"we modify attention weights to reflect spatial distance in input graphs\"}, {\"Head\": \"We take inspiration from Graphormer\", \"Relation\": \"because\", \"Tail\": \"we implement our model with alternative graph encodings tailored to language tasks\"}, {\"Head\": \"H-GAT fuses relation embeddings into semantic graph nodes\", \"Relation\": \"before\", \"Tail\": \"the graph sequences are passed to the transformer layers\"}, {\"Head\": \"We discard unnecessary inter-relation representations and use a simplified architecture with token embeddings\", \"Relation\": \"because\", \"Tail\": \"we tailor H-GAT to chain vocabulary graphs\"}, {\"Head\": \"The new tail token fuses the relation embedding with its initial tail token embedding and all head token embeddings\", \"Relation\": \"as a result\", \"Tail\": \"the tail token embedding integrates relation and head token information\"}, {\"Head\": \"We design a simple reverse test using UMLS triples\", \"Relation\": \"before\", \"Tail\": \"we sample a ground-truth triple from UMLS\"}, {\"Head\": \"We manually create a sequence that implies a weak connection between CKD and cerebellar gray matter\", \"Relation\": \"because\", \"Tail\": \"we want an example appropriate for the associated_with relation\"}, {\"Head\": \"We prompt strong general-purpose LLMs to infer the triple from the sentence\", \"Relation\": \"after\", \"Tail\": \"these models frequently hallucinate relations or return ontologically invalid outputs\"}, {\"Head\": \"These models frequently hallucinate relations or return ontologically invalid outputs\", \"Relation\": \"as a result\", \"Tail\": \"their outputs show spurious correlations instead of semantic connections\"}, {\"Head\": \"Our GraphMERT model recovers the correct UMLS triple from the same sentence\", \"Relation\": \"in contrast to\", \"Tail\": \"strong general-purpose LLMs that produced non-factual or misaligned triples\"}, {\"Head\": \"This example underscores that adhering to biomedical ontologies matters\", \"Relation\": \"because\", \"Tail\": \"structure-aware training is essential for preventing errors like miscasting gray matter with finding_site\"}, {\"Head\": \"GraphMERT is trained on the fusion of syntactic and semantic examples and augments syntactic data with semantic tails\", \"Relation\": \"therefore\", \"Tail\": \"GraphMERT can predict novel semantic token completions using syntactic information as context\"}]"}
{"id": "1", "original_text": "oderonly transformer. To complete a triple, it predicts a masked tail (a node in the KG, hence MNM). Just like typically text-based encoder-only models, GraphMERT also learns syntactic representations from text corpora via the MLM learning objective (Devlin et al., 2019). To enable an encoder-only extraction, we create a new textual data format that encapsulates semantic triples and engineer GraphMERT to work in this space. ## 4.1 Syntactic and Semantic Spaces: Merging Semantic Triples and Syntactic Text into a Unified Graphical Format In essence, GraphMERT performs syntactic-to-semantic knowledge conversion during prediction. The sentences in the dataset represent the syntactic space . The KG triples represent the semantic space that Figure 3: Chain graph. Roots are in orange, leaves are in blue. Conceptual representation (A, B): term level, each circle is a term. Actual representation in training (C): token level, each square is a token. Each term can be multi-token. (A) No injections, all leaves are empty. (B) One root node has a leaf term. (C) Token-level representation for the 3-leaf case. Here, the leaf in (B) is encoded with a maximum of three tokens and padded to the maximum length if needed. Root term comprises two tokens, and tail term also comprises two tokens that are connected to the first root token. <!-- image --> includes semantic relations . To enable knowledge form conversion, we propose leafy chain graph encoding that unifies the semantic and syntactic representations into a joint representation (see Fig. 3) in which chain graph roots lie in the syntactic space and leaves, along with their relations, lie in the semantic space. As we demonstrate later, leaves play a crucial role in training semantic relation embeddings. Leafy chain graphs follow a regular structure, which enables sequential encoding of the graphical information. All chain graphs have a fixed number of root nodes; the number of leaves per root node is also fixed. Leaves of the same root are connected, introducing a shortest-path linkage between them. All edges are undirected (the directionality of relations is implied in the architecture). To create a unified representation for the training data, we parse the dataset into chain graphs with &lt;pad&gt; tokens in all leaf positions, keeping only root nodes non-empty. Next, we populate the empty leaves with semantic nodes and their relations from the seed KG in a separate pipeline step, as detailed in Sec. 4.3. Thereafter, the dataset consists of leafy chain graphs with a regular structure . Most leaf nodes are pads, while some contain semantic tail tokens from the seed KG. This regularity in graphical input informs and simplifies the choice of graph encodings in GraphMERT , as discussed further in Sec. 4.2.1. ## 4.2 GraphMERT Architecture and Training The core architectural challenge in graph transformer design lies in encoding graphs into a sequential input for attention-based learning, in order to enable robust graphical representations. We discuss this in the next two subsections. ## 4.2.1 GraphMERT Architecture with Graph Encodings The proposed GraphMERT F ( x, θ ), x : chain graph input, θ : trainable parameters, is a RoBERTa-style (Liu et al., 2019) encoder-only transformer integrated with H-GAT, trained with the MLM + MNM objective. Fig. 4 illustrates the GraphMERT architecture. Our choice of graph encodings is informed by the regularity of the input graph: The input consists of chain graphs with a fixed number of root and leaf nodes. Therefore, to describe the input graph class, node encoding, semantic leaf relation encodings, and spatial distances between node pairs are sufficient. Though common in graph transformers, degree and sparsity encodings offer little value in our setup. The two core components of GraphMERT that encapsulate graph encoding are the input embedding layer and the attention decay mask. Figure 4: Main GraphMERT architectural components. GraphMERT is a RoBERTa transformer with two modifications. (I) In the embedding layer, H-GAT encodes semantic triples. (IA) There are leaves connected to a root node; hence, the node feature is equal to the token embedding. (IB) There are leaves connected to a root node; H-GAT fuses leaves, relations, and head embeddings resulting in fused node feature. (II) In the attention layers, attention weights are multiplied by a function that exponentially decreases with pairwise distance. They encode graph relations and graph distance, respectively. The input is either a node feature or a fused node feature. <!-- image --> The embedding layer processes input nodes, concretely, root nodes along with their leaves, and semantic relations for each injected leaf node. For every injected triple, its head (multi-token) lies in the root space and its tail (also multi-token) lies in the leaf space. The embedding block fuses every leaf token embedding with its relation and all its head tokens via H-GAT (see Sec. 2.7.2): <!-- formula-not-decoded --> where t i is the tail token embedding, h j is the head token embedding, and dim is the embedding dimension. The derived embedding replaces the initial leaf embedding, effectively encoding the whole semantic triple into the leaf embedding space, as shown in Fig 5. During training, masking leaf nodes enables the training of relation embeddings with backpropagation, as shown in Fig. 6. The attention decay mask encodes the spatial distance between graph nodes. The core idea is that attention between two nodes should decrease with respect to their distance. Following Gradformer (Liu et al., 2024a), we use an exponential function with base 0 &lt; λ &lt; 1 and the shortest path in the exponent. To adjust Gradformer's exponential mask for vocabulary sequence graphs that experimentally need a smoother attention decay with respect to the shortest path, we introduce a square root in the exponent. Figure 5: Semantic embedding derivation on leaves (only three leaves are shown). h i : head token, l i : leaf token, t : syntactic context token. For every injected triple, H-GAT fuses each leaf token with the relation and all the head tokens, yielding an embedding of the same dimension as the initial leaf token embedding. The derived embedding replaces the initial leaf embedding. <!-- image --> Backpropagation path: loss → transformer layers → H-GAT → input token embeddings. <!-- image --> Figure 6: Relation embedding training. The sequence with updated leaf embeddings is passed to the transformer layers. The masked nodes (both roots and leaves) contribute to the loss calculation. For masked leaves, the gradient flows back to them through H-GAT, updating the relation embeddings. The shortest path for every node pair is calculated using the Floyd-Warshall algorithm: <!-- formula-not-decoded --> The exponential decay mask is an N × N matrix defined as: <!-- formula-not-decoded --> where p is a learnable parameter and λ is a hyperparameter. For sp ( i, j ) ≤ p , the activation function, GELU (Hendrycks &amp; Gimpel, 2023), zeroes the exponent, making the mask close to zero for nodes with the shortest path less than or equal to the learned p . Finally, we multiply the attention weights A ∈ R N × N by the mask elementwise, effectively incorporating spatial distance in the attention mechanism. <!-- formula-not-decoded --> The exponential mask is shared across all attention layers. ## 4.2.2 GraphMERT Training As explained earlier, we represent each sentence as a leafy chain graph G whose root nodes are text tokens, and graft semantic leaf nodes from a seed KG onto entity/mention spans via relation edges. GraphMERT jointly pretrains using MLM over syntactic tokens and MNM over semantic leaves: We randomly select spans in either space and train the model to reconstruct the missing words and/or KG leaves. This setup couples the transformer's token encoder with the H-GAT relation encoder so that the surface form and KG semantics align during pretraining. <!-- formula-not-decoded --> <!-- formula-not-decoded --> <!-- formula-not-decoded --> where x denotes the input token sequence; G is the text chain graph augmented with KG leaf nodes; M x and M g are the masked text and leaf spans, respectively; x t is a masked token target; g /lscript is a masked semantic leaf target (as a leaf-span explained below); L SBO ( x t ) is span boundary loss on M x (explained below); θ denotes all model parameters (transformer + H-GAT); and µ &gt; 0 balances the two losses (we use µ = 1). Both objectives use span-wise masking. In GraphMERT , H-GAT is responsible for training semantic relation embeddings. Dropout on relation embeddings prevents overfitting on scarce semantic examples. In parallel, transformer attention trains the remaining network parameters, attending jointly to tokens from both the syntactic and semantic spaces. GraphMERT is trained with a span-masking schema. Empirically, span masking tightens alignment among the topk tokens predicted within a single leaf. Later, better-aligned tokens result in more nuanced combinations when constructing complete tails. We discuss the topk predicted token combination stage in Sec. 4.4. From the syntactic stream, we exactly follow the span masking implementation, which sums regular masked objective with span boundary loss of SpanBERT (Joshi et al., 2020). In the semantic space, however, we introduce a modification: Whenever a leaf span is selected (with a standard MLM/MNM probability of 0.15), we mask all the leaf tokens rather than sampling span length from the geometric distribution, which could mask a leaf subset for a given root. In other words, M g and M x follow different masking schemas. The rationale for this stems from backpropagation. Relation embeddings must receive gradients from the entire tail so that they can capture its full meaning, not just fragments from individual tokens. Since the semantic meaning of a relation manifests only across the complete tail expression, masking the whole leaf ensures that gradients reflect the whole semantic unit. ## 4.3 High-quality Text Sources and Dataset Preprocessing for GraphMERT Training Our framework focuses on domains with stringent factuality requirements. The compact GraphMERT model makes it feasible to train exclusively on limited expert-verified open-source texts. This approach takes an essential step toward reliable KG extraction: Data cleaning reduces hallucinations and training on scientific corpora can substantially limit domain-specific errors (Li et al., 2024). Reliance on expert-verified data prevents importing spurious facts from vast, tainted corpora. Data quality requirements apply equally to the seed KG. The seed KG is a set of domain-specific triples that serve as initial relation examples for the model. As the full training set in the semantic space, the seed KG defines the relation set for the extracted KG. Its quality, therefore, is of utmost significance in training of robust semantic relation embeddings in GraphMERT . A seed KG can be obtained from an external source, provided that it satisfies the following two conditions: 1. It contains clean, domain-specific data. ## 2. It has a sufficiently diverse vocabulary. Condition (1) provides the foundation for learning accurate relation embeddings and Condition (2) prevents relation embedding overfitting on a small set of tokens. To obtain a domain-specific seed KG that meets these requirements, we suggest either selecting a relevant, well-curated external KG or generating one (see Sec. 4.5), followed by thorough cleaning. After obtaining a KG, we apply a similarity filter to it against the training data (see Sec. 4.3.1), which ensures alignment with the target domain [Condition (1)] and identification of the triples most relevant to the context (see Sec. 4.3.2). The algorithm for selecting the best matches, described in Sec. 4.3.3, addresses vocabulary diversity [Condition (2)]. This algorithm selects triples from the external KG to position them within the semantic space in the chain graphs, given the potential spots for triple heads within the syntactic space. For domain-specific head discovery in the dataset, we use a helper LLM. ## 4.3.1 Entity Linking Although GraphMERT is applicable to any domain-specific text corpora, we leverage biomedical knowledge in the UMLS to develop a multi-stage process to link entities discovered in the text to concepts in UMLS. This process ensures that identified entities are mapped to standardized Concept Unique Identifiers (CUIs), facilitating the subsequent retrieval of structured information from the UMLS KG. We combine both embedding similarity and string similarity. Stage 1: Embedding-based candidate retrieval: The initial stage aims to rapidly identify a set of potential candidate concepts from the vast UMLS ontology. This is achieved by representing both the discovered source entities (queries) and the target UMLS entities in a shared high-dimensional vector space. We use SapBERT (Lim &amp; Kim, 2022), an encoder-only language model specifically pre-trained on biomedical knowledge from UMLS, which is able to capture the nuanced difference between biomedical terms. Each discovered head entity and every UMLS entity is processed through SapBERT to produce a unique vector embedding. To efficiently search through millions of UMLS entity embeddings, we employ an Approximate Nearest Neighbor (ANN) algorithm. ANN constructs a pre-computed index of the UMLS embeddings, enabling highly efficient retrieval of the topk most similar vectors for a given query vector. For each discovered entity, we use t", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "GraphMERT", "Relation": "integrates", "Tail": "H-GAT"}, {"Head": "GraphMERT", "Relation": "is based on", "Tail": "RoBERTa-style encoder-only transformer"}, {"Head": "GraphMERT", "Relation": "is trained with", "Tail": "MLM + MNM objectives"}, {"Head": "Leafy chain graph", "Relation": "unifies", "Tail": "syntactic space and semantic space"}, {"Head": "Chain graph roots", "Relation": "reside in", "Tail": "syntactic space"}, {"Head": "Chain graph leaves", "Relation": "represent", "Tail": "semantic tail nodes from seed KG"}, {"Head": "H-GAT", "Relation": "fuses", "Tail": "leaf token embeddings, relation embeddings, and head token embeddings"}, {"Head": "Embedding layer", "Relation": "replaces", "Tail": "initial leaf embeddings with derived semantic embeddings"}, {"Head": "Attention decay mask", "Relation": "encodes", "Tail": "spatial distances between graph nodes"}, {"Head": "Exponential decay mask", "Relation": "uses", "Tail": "shortest-path distances with square-rooted exponent"}, {"Head": "Floyd-Warshall algorithm", "Relation": "computes", "Tail": "shortest path for every node pair"}, {"Head": "Masking schema for leaves", "Relation": "masks", "Tail": "entire leaf spans rather than subsets"}, {"Head": "Relation embeddings", "Relation": "are trained via", "Tail": "backpropagation through H-GAT from masked leaves"}, {"Head": "Seed KG", "Relation": "supplies", "Tail": "semantic triples for leaf injection"}, {"Head": "Seed KG", "Relation": "must contain", "Tail": "clean domain-specific data and diverse vocabulary"}, {"Head": "Data cleaning", "Relation": "reduces", "Tail": "hallucinations during KG extraction"}, {"Head": "Similarity filter", "Relation": "aligns", "Tail": "external KG triples with target training data"}, {"Head": "Helper LLM", "Relation": "assists in", "Tail": "domain-specific head discovery"}, {"Head": "Entity linking pipeline", "Relation": "maps", "Tail": "text entities to UMLS Concept Unique Identifiers"}, {"Head": "SapBERT", "Relation": "produces", "Tail": "vector embeddings for biomedical terms"}, {"Head": "ANN algorithm", "Relation": "retrieves", "Tail": "top-k similar UMLS entity embeddings"}, {"Head": "Span-masking schema", "Relation": "tightens", "Tail": "alignment among top-k tokens predicted within a leaf"}, {"Head": "Attention weights", "Relation": "are multiplied by", "Tail": "exponential decay mask"}, {"Head": "Dropout on relation embeddings", "Relation": "prevents", "Tail": "overfitting on scarce semantic examples"}], "entity_relation_output": "[{\"Head\": \"GraphMERT\", \"Relation\": \"integrates\", \"Tail\": \"H-GAT\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"is based on\", \"Tail\": \"RoBERTa-style encoder-only transformer\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"is trained with\", \"Tail\": \"MLM + MNM objectives\"}, {\"Head\": \"Leafy chain graph\", \"Relation\": \"unifies\", \"Tail\": \"syntactic space and semantic space\"}, {\"Head\": \"Chain graph roots\", \"Relation\": \"reside in\", \"Tail\": \"syntactic space\"}, {\"Head\": \"Chain graph leaves\", \"Relation\": \"represent\", \"Tail\": \"semantic tail nodes from seed KG\"}, {\"Head\": \"H-GAT\", \"Relation\": \"fuses\", \"Tail\": \"leaf token embeddings, relation embeddings, and head token embeddings\"}, {\"Head\": \"Embedding layer\", \"Relation\": \"replaces\", \"Tail\": \"initial leaf embeddings with derived semantic embeddings\"}, {\"Head\": \"Attention decay mask\", \"Relation\": \"encodes\", \"Tail\": \"spatial distances between graph nodes\"}, {\"Head\": \"Exponential decay mask\", \"Relation\": \"uses\", \"Tail\": \"shortest-path distances with square-rooted exponent\"}, {\"Head\": \"Floyd-Warshall algorithm\", \"Relation\": \"computes\", \"Tail\": \"shortest path for every node pair\"}, {\"Head\": \"Masking schema for leaves\", \"Relation\": \"masks\", \"Tail\": \"entire leaf spans rather than subsets\"}, {\"Head\": \"Relation embeddings\", \"Relation\": \"are trained via\", \"Tail\": \"backpropagation through H-GAT from masked leaves\"}, {\"Head\": \"Seed KG\", \"Relation\": \"supplies\", \"Tail\": \"semantic triples for leaf injection\"}, {\"Head\": \"Seed KG\", \"Relation\": \"must contain\", \"Tail\": \"clean domain-specific data and diverse vocabulary\"}, {\"Head\": \"Data cleaning\", \"Relation\": \"reduces\", \"Tail\": \"hallucinations during KG extraction\"}, {\"Head\": \"Similarity filter\", \"Relation\": \"aligns\", \"Tail\": \"external KG triples with target training data\"}, {\"Head\": \"Helper LLM\", \"Relation\": \"assists in\", \"Tail\": \"domain-specific head discovery\"}, {\"Head\": \"Entity linking pipeline\", \"Relation\": \"maps\", \"Tail\": \"text entities to UMLS Concept Unique Identifiers\"}, {\"Head\": \"SapBERT\", \"Relation\": \"produces\", \"Tail\": \"vector embeddings for biomedical terms\"}, {\"Head\": \"ANN algorithm\", \"Relation\": \"retrieves\", \"Tail\": \"top-k similar UMLS entity embeddings\"}, {\"Head\": \"Span-masking schema\", \"Relation\": \"tightens\", \"Tail\": \"alignment among top-k tokens predicted within a leaf\"}, {\"Head\": \"Attention weights\", \"Relation\": \"are multiplied by\", \"Tail\": \"exponential decay mask\"}, {\"Head\": \"Dropout on relation embeddings\", \"Relation\": \"prevents\", \"Tail\": \"overfitting on scarce semantic examples\"}]", "event_entity_dict": [{"Event": "To complete a triple, it predicts a masked tail", "Entity": ["GraphMERT", "triple", "masked tail", "KG"]}, {"Event": "GraphMERT also learns syntactic representations from text corpora via the MLM learning objective", "Entity": ["GraphMERT", "syntactic representations", "text corpora", "MLM learning objective"]}, {"Event": "We create a new textual data format that encapsulates semantic triples and engineer GraphMERT to work in this space", "Entity": ["we", "new textual data format", "semantic triples", "GraphMERT"]}, {"Event": "GraphMERT performs syntactic-to-semantic knowledge conversion during prediction", "Entity": ["GraphMERT", "syntactic space", "semantic space"]}, {"Event": "The sentences in the dataset represent the syntactic space", "Entity": ["sentences", "dataset", "syntactic space"]}, {"Event": "The KG triples represent the semantic space", "Entity": ["KG triples", "semantic space"]}, {"Event": "We propose leafy chain graph encoding that unifies the semantic and syntactic representations into a joint representation", "Entity": ["we", "leafy chain graph encoding", "semantic representations", "syntactic representations"]}, {"Event": "Chain graph roots lie in the syntactic space and leaves, along with their relations, lie in the semantic space", "Entity": ["chain graph roots", "syntactic space", "leaves", "relations", "semantic space"]}, {"Event": "Leaves play a crucial role in training semantic relation embeddings", "Entity": ["leaves", "semantic relation embeddings", "training"]}, {"Event": "All chain graphs have a fixed number of root nodes and the number of leaves per root node is also fixed", "Entity": ["chain graphs", "root nodes", "leaves"]}, {"Event": "Leaves of the same root are connected, introducing a shortest-path linkage between them", "Entity": ["leaves", "root", "shortest-path linkage"]}, {"Event": "All edges are undirected", "Entity": ["edges"]}, {"Event": "We parse the dataset into chain graphs with <pad> tokens in all leaf positions, keeping only root nodes non-empty", "Entity": ["we", "dataset", "chain graphs", "<pad> tokens", "leaf positions", "root nodes"]}, {"Event": "We populate the empty leaves with semantic nodes and their relations from the seed KG in a separate pipeline step", "Entity": ["we", "empty leaves", "semantic nodes", "relations", "seed KG", "pipeline"]}, {"Event": "Most leaf nodes are pads while some contain semantic tail tokens from the seed KG", "Entity": ["leaf nodes", "pads", "semantic tail tokens", "seed KG"]}, {"Event": "The core architectural challenge in graph transformer design lies in encoding graphs into a sequential input for attention-based learning", "Entity": ["core architectural challenge", "graph transformer design", "encoding graphs", "sequential input", "attention-based learning"]}, {"Event": "The proposed GraphMERT is a RoBERTa-style encoder-only transformer integrated with H-GAT trained with the MLM + MNM objective", "Entity": ["GraphMERT", "RoBERTa-style encoder-only transformer", "H-GAT", "MLM", "MNM"]}, {"Event": "The input consists of chain graphs with a fixed number of root and leaf nodes", "Entity": ["input", "chain graphs", "root nodes", "leaf nodes"]}, {"Event": "Node encoding, semantic leaf relation encodings, and spatial distances between node pairs are sufficient to describe the input graph class", "Entity": ["node encoding", "semantic leaf relation encodings", "spatial distances", "node pairs", "input graph class"]}, {"Event": "The two core components of GraphMERT that encapsulate graph encoding are the input embedding layer and the attention decay mask", "Entity": ["GraphMERT", "input embedding layer", "attention decay mask"]}, {"Event": "H-GAT encodes semantic triples in the embedding layer", "Entity": ["H-GAT", "semantic triples", "embedding layer"]}, {"Event": "H-GAT fuses leaves, relations, and head embeddings resulting in fused node feature", "Entity": ["H-GAT", "leaves", "relations", "head embeddings", "fused node feature"]}, {"Event": "Attention weights are multiplied by a function that exponentially decreases with pairwise distance", "Entity": ["attention weights", "function", "pairwise distance"]}, {"Event": "The embedding layer processes root nodes along with their leaves and semantic relations for each injected leaf node", "Entity": ["embedding layer", "root nodes", "leaves", "semantic relations", "injected leaf node"]}, {"Event": "For every injected triple, its head lies in the root space and its tail lies in the leaf space", "Entity": ["injected triple", "head", "root space", "tail", "leaf space"]}, {"Event": "The embedding block fuses every leaf token embedding with its relation and all its head tokens via H-GAT", "Entity": ["embedding block", "leaf token embedding", "relation", "head tokens", "H-GAT"]}, {"Event": "The derived embedding replaces the initial leaf embedding, effectively encoding the whole semantic triple into the leaf embedding space", "Entity": ["derived embedding", "initial leaf embedding", "semantic triple", "leaf embedding space"]}, {"Event": "Masking leaf nodes during training enables the training of relation embeddings with backpropagation", "Entity": ["masking leaf nodes", "training", "relation embeddings", "backpropagation"]}, {"Event": "The attention decay mask encodes the spatial distance between graph nodes", "Entity": ["attention decay mask", "spatial distance", "graph nodes"]}, {"Event": "We use an exponential function with base 0 < λ < 1 and the shortest path in the exponent", "Entity": ["exponential function", "λ", "shortest path"]}, {"Event": "We introduce a square root in the exponent to obtain a smoother attention decay", "Entity": ["we", "square root", "exponent", "attention decay"]}, {"Event": "For every injected triple, H-GAT fuses each leaf token with the relation and all the head tokens, yielding an embedding of the same dimension as the initial leaf token embedding", "Entity": ["injected triple", "H-GAT", "leaf token", "relation", "head tokens", "embedding"]}, {"Event": "The masked nodes (both roots and leaves) contribute to the loss calculation", "Entity": ["masked nodes", "roots", "leaves", "loss calculation"]}, {"Event": "For masked leaves, the gradient flows back to them through H-GAT, updating the relation embeddings", "Entity": ["masked leaves", "gradient", "H-GAT", "relation embeddings"]}, {"Event": "The shortest path for every node pair is calculated using the Floyd-Warshall algorithm", "Entity": ["shortest path", "node pair", "Floyd-Warshall algorithm"]}, {"Event": "The exponential decay mask is an N × N matrix defined with p as a learnable parameter and λ as a hyperparameter", "Entity": ["exponential decay mask", "N × N matrix", "p", "λ"]}, {"Event": "For sp(i, j) ≤ p the activation function GELU zeroes the exponent making the mask close to zero", "Entity": ["sp(i, j)", "p", "GELU", "exponent", "mask"]}], "event_entity_output": "[{\"Event\": \"To complete a triple, it predicts a masked tail\", \"Entity\": [\"GraphMERT\", \"triple\", \"masked tail\", \"KG\"]}, {\"Event\": \"GraphMERT also learns syntactic representations from text corpora via the MLM learning objective\", \"Entity\": [\"GraphMERT\", \"syntactic representations\", \"text corpora\", \"MLM learning objective\"]}, {\"Event\": \"We create a new textual data format that encapsulates semantic triples and engineer GraphMERT to work in this space\", \"Entity\": [\"we\", \"new textual data format\", \"semantic triples\", \"GraphMERT\"]}, {\"Event\": \"GraphMERT performs syntactic-to-semantic knowledge conversion during prediction\", \"Entity\": [\"GraphMERT\", \"syntactic space\", \"semantic space\"]}, {\"Event\": \"The sentences in the dataset represent the syntactic space\", \"Entity\": [\"sentences\", \"dataset\", \"syntactic space\"]}, {\"Event\": \"The KG triples represent the semantic space\", \"Entity\": [\"KG triples\", \"semantic space\"]}, {\"Event\": \"We propose leafy chain graph encoding that unifies the semantic and syntactic representations into a joint representation\", \"Entity\": [\"we\", \"leafy chain graph encoding\", \"semantic representations\", \"syntactic representations\"]}, {\"Event\": \"Chain graph roots lie in the syntactic space and leaves, along with their relations, lie in the semantic space\", \"Entity\": [\"chain graph roots\", \"syntactic space\", \"leaves\", \"relations\", \"semantic space\"]}, {\"Event\": \"Leaves play a crucial role in training semantic relation embeddings\", \"Entity\": [\"leaves\", \"semantic relation embeddings\", \"training\"]}, {\"Event\": \"All chain graphs have a fixed number of root nodes and the number of leaves per root node is also fixed\", \"Entity\": [\"chain graphs\", \"root nodes\", \"leaves\"]}, {\"Event\": \"Leaves of the same root are connected, introducing a shortest-path linkage between them\", \"Entity\": [\"leaves\", \"root\", \"shortest-path linkage\"]}, {\"Event\": \"All edges are undirected\", \"Entity\": [\"edges\"]}, {\"Event\": \"We parse the dataset into chain graphs with <pad> tokens in all leaf positions, keeping only root nodes non-empty\", \"Entity\": [\"we\", \"dataset\", \"chain graphs\", \"<pad> tokens\", \"leaf positions\", \"root nodes\"]}, {\"Event\": \"We populate the empty leaves with semantic nodes and their relations from the seed KG in a separate pipeline step\", \"Entity\": [\"we\", \"empty leaves\", \"semantic nodes\", \"relations\", \"seed KG\", \"pipeline\"]}, {\"Event\": \"Most leaf nodes are pads while some contain semantic tail tokens from the seed KG\", \"Entity\": [\"leaf nodes\", \"pads\", \"semantic tail tokens\", \"seed KG\"]}, {\"Event\": \"The core architectural challenge in graph transformer design lies in encoding graphs into a sequential input for attention-based learning\", \"Entity\": [\"core architectural challenge\", \"graph transformer design\", \"encoding graphs\", \"sequential input\", \"attention-based learning\"]}, {\"Event\": \"The proposed GraphMERT is a RoBERTa-style encoder-only transformer integrated with H-GAT trained with the MLM + MNM objective\", \"Entity\": [\"GraphMERT\", \"RoBERTa-style encoder-only transformer\", \"H-GAT\", \"MLM\", \"MNM\"]}, {\"Event\": \"The input consists of chain graphs with a fixed number of root and leaf nodes\", \"Entity\": [\"input\", \"chain graphs\", \"root nodes\", \"leaf nodes\"]}, {\"Event\": \"Node encoding, semantic leaf relation encodings, and spatial distances between node pairs are sufficient to describe the input graph class\", \"Entity\": [\"node encoding\", \"semantic leaf relation encodings\", \"spatial distances\", \"node pairs\", \"input graph class\"]}, {\"Event\": \"The two core components of GraphMERT that encapsulate graph encoding are the input embedding layer and the attention decay mask\", \"Entity\": [\"GraphMERT\", \"input embedding layer\", \"attention decay mask\"]}, {\"Event\": \"H-GAT encodes semantic triples in the embedding layer\", \"Entity\": [\"H-GAT\", \"semantic triples\", \"embedding layer\"]}, {\"Event\": \"H-GAT fuses leaves, relations, and head embeddings resulting in fused node feature\", \"Entity\": [\"H-GAT\", \"leaves\", \"relations\", \"head embeddings\", \"fused node feature\"]}, {\"Event\": \"Attention weights are multiplied by a function that exponentially decreases with pairwise distance\", \"Entity\": [\"attention weights\", \"function\", \"pairwise distance\"]}, {\"Event\": \"The embedding layer processes root nodes along with their leaves and semantic relations for each injected leaf node\", \"Entity\": [\"embedding layer\", \"root nodes\", \"leaves\", \"semantic relations\", \"injected leaf node\"]}, {\"Event\": \"For every injected triple, its head lies in the root space and its tail lies in the leaf space\", \"Entity\": [\"injected triple\", \"head\", \"root space\", \"tail\", \"leaf space\"]}, {\"Event\": \"The embedding block fuses every leaf token embedding with its relation and all its head tokens via H-GAT\", \"Entity\": [\"embedding block\", \"leaf token embedding\", \"relation\", \"head tokens\", \"H-GAT\"]}, {\"Event\": \"The derived embedding replaces the initial leaf embedding, effectively encoding the whole semantic triple into the leaf embedding space\", \"Entity\": [\"derived embedding\", \"initial leaf embedding\", \"semantic triple\", \"leaf embedding space\"]}, {\"Event\": \"Masking leaf nodes during training enables the training of relation embeddings with backpropagation\", \"Entity\": [\"masking leaf nodes\", \"training\", \"relation embeddings\", \"backpropagation\"]}, {\"Event\": \"The attention decay mask encodes the spatial distance between graph nodes\", \"Entity\": [\"attention decay mask\", \"spatial distance\", \"graph nodes\"]}, {\"Event\": \"We use an exponential function with base 0 < λ < 1 and the shortest path in the exponent\", \"Entity\": [\"exponential function\", \"λ\", \"shortest path\"]}, {\"Event\": \"We introduce a square root in the exponent to obtain a smoother attention decay\", \"Entity\": [\"we\", \"square root\", \"exponent\", \"attention decay\"]}, {\"Event\": \"For every injected triple, H-GAT fuses each leaf token with the relation and all the head tokens, yielding an embedding of the same dimension as the initial leaf token embedding\", \"Entity\": [\"injected triple\", \"H-GAT\", \"leaf token\", \"relation\", \"head tokens\", \"embedding\"]}, {\"Event\": \"The masked nodes (both roots and leaves) contribute to the loss calculation\", \"Entity\": [\"masked nodes\", \"roots\", \"leaves\", \"loss calculation\"]}, {\"Event\": \"For masked leaves, the gradient flows back to them through H-GAT, updating the relation embeddings\", \"Entity\": [\"masked leaves\", \"gradient\", \"H-GAT\", \"relation embeddings\"]}, {\"Event\": \"The shortest path for every node pair is calculated using the Floyd-Warshall algorithm\", \"Entity\": [\"shortest path\", \"node pair\", \"Floyd-Warshall algorithm\"]}, {\"Event\": \"The exponential decay mask is an N × N matrix defined with p as a learnable parameter and λ as a hyperparameter\", \"Entity\": [\"exponential decay mask\", \"N × N matrix\", \"p\", \"λ\"]}, {\"Event\": \"For sp(i, j) ≤ p the activation function GELU zeroes the exponent making the mask close to zero\", \"Entity\": [\"sp(i, j)\", \"p\", \"GELU\", \"exponent\", \"mask\"]}]", "event_relation_dict": [{"Head": "GraphMERT predicts a masked tail to complete a triple", "Relation": "because", "Tail": "it is designed as a masked node modeling (MNM) task"}, {"Head": "GraphMERT learns syntactic representations from text corpora via the MLM learning objective", "Relation": "at the same time", "Tail": "GraphMERT predicts masked tails with MNM"}, {"Head": "We create a new textual data format that encapsulates semantic triples", "Relation": "so that", "Tail": "GraphMERT can perform encoder-only extraction"}, {"Head": "GraphMERT performs syntactic-to-semantic knowledge conversion during prediction", "Relation": "because", "Tail": "the sentences in the dataset represent the syntactic space and the KG triples represent the semantic space"}, {"Head": "We propose leafy chain graph encoding that unifies the semantic and syntactic representations", "Relation": "as a result", "Tail": "chain graph roots lie in the syntactic space and leaves lie in the semantic space"}, {"Head": "Leaves play a crucial role in training semantic relation embeddings", "Relation": "because", "Tail": "they carry injected semantic tail tokens from the seed KG"}, {"Head": "All chain graphs have a fixed number of root nodes and a fixed number of leaves per root node", "Relation": "as a result", "Tail": "the input graph class can be described using node encoding, semantic leaf relation encodings, and spatial distances"}, {"Head": "We parse the dataset into chain graphs with <pad> tokens in all leaf positions keeping only root nodes non-empty", "Relation": "before", "Tail": "we populate the empty leaves with semantic nodes and their relations from the seed KG"}, {"Head": "Most leaf nodes are pads while some contain semantic tail tokens from the seed KG", "Relation": "as a result", "Tail": "the graphical input has regularity that simplifies the choice of graph encodings"}, {"Head": "GraphMERT is a RoBERTa-style encoder-only transformer integrated with H-GAT", "Relation": "and", "Tail": "it is trained with the MLM + MNM objective"}, {"Head": "H-GAT fuses leaves, relations, and head embeddings resulting in fused node features", "Relation": "so that", "Tail": "the derived embedding replaces the initial leaf embedding encoding the whole semantic triple"}, {"Head": "Masking leaf nodes enables the training of relation embeddings with backpropagation", "Relation": "because", "Tail": "gradients flow back to relation embeddings through H-GAT during training"}, {"Head": "The attention decay mask encodes the spatial distance between graph nodes", "Relation": "so that", "Tail": "attention between two nodes decreases with respect to their distance"}, {"Head": "We introduce a square root in the exponent of the exponential mask", "Relation": "because", "Tail": "vocabulary sequence graphs experimentally need a smoother attention decay with respect to the shortest path"}, {"Head": "GraphMERT jointly pretrains using MLM over syntactic tokens and MNM over semantic leaves", "Relation": "as a result", "Tail": "the transformer token encoder is coupled with the H-GAT relation encoder aligning surface form and KG semantics"}, {"Head": "In the semantic space we mask all the leaf tokens whenever a leaf span is selected", "Relation": "because", "Tail": "relation embeddings must receive gradients from the entire tail to capture its full meaning"}, {"Head": "The seed KG is a set of domain-specific triples that serve as initial relation examples", "Relation": "as a result", "Tail": "the seed KG defines the relation set for the extracted KG"}, {"Head": "We apply a similarity filter to the seed KG against the training data", "Relation": "so that", "Tail": "the selected triples align with the target domain and identify triples most relevant to the context"}, {"Head": "For domain-specific head discovery in the dataset we use a helper LLM", "Relation": "and", "Tail": "we obtain candidate mappings to position triples within the semantic space"}, {"Head": "Entity linking uses SapBERT to produce vector embeddings for discovered entities and UMLS entities", "Relation": "so that", "Tail": "we can efficiently retrieve similar UMLS concepts using an ANN algorithm"}], "event_relation_output": "[{\"Head\": \"GraphMERT predicts a masked tail to complete a triple\", \"Relation\": \"because\", \"Tail\": \"it is designed as a masked node modeling (MNM) task\"}, {\"Head\": \"GraphMERT learns syntactic representations from text corpora via the MLM learning objective\", \"Relation\": \"at the same time\", \"Tail\": \"GraphMERT predicts masked tails with MNM\"}, {\"Head\": \"We create a new textual data format that encapsulates semantic triples\", \"Relation\": \"so that\", \"Tail\": \"GraphMERT can perform encoder-only extraction\"}, {\"Head\": \"GraphMERT performs syntactic-to-semantic knowledge conversion during prediction\", \"Relation\": \"because\", \"Tail\": \"the sentences in the dataset represent the syntactic space and the KG triples represent the semantic space\"}, {\"Head\": \"We propose leafy chain graph encoding that unifies the semantic and syntactic representations\", \"Relation\": \"as a result\", \"Tail\": \"chain graph roots lie in the syntactic space and leaves lie in the semantic space\"}, {\"Head\": \"Leaves play a crucial role in training semantic relation embeddings\", \"Relation\": \"because\", \"Tail\": \"they carry injected semantic tail tokens from the seed KG\"}, {\"Head\": \"All chain graphs have a fixed number of root nodes and a fixed number of leaves per root node\", \"Relation\": \"as a result\", \"Tail\": \"the input graph class can be described using node encoding, semantic leaf relation encodings, and spatial distances\"}, {\"Head\": \"We parse the dataset into chain graphs with <pad> tokens in all leaf positions keeping only root nodes non-empty\", \"Relation\": \"before\", \"Tail\": \"we populate the empty leaves with semantic nodes and their relations from the seed KG\"}, {\"Head\": \"Most leaf nodes are pads while some contain semantic tail tokens from the seed KG\", \"Relation\": \"as a result\", \"Tail\": \"the graphical input has regularity that simplifies the choice of graph encodings\"}, {\"Head\": \"GraphMERT is a RoBERTa-style encoder-only transformer integrated with H-GAT\", \"Relation\": \"and\", \"Tail\": \"it is trained with the MLM + MNM objective\"}, {\"Head\": \"H-GAT fuses leaves, relations, and head embeddings resulting in fused node features\", \"Relation\": \"so that\", \"Tail\": \"the derived embedding replaces the initial leaf embedding encoding the whole semantic triple\"}, {\"Head\": \"Masking leaf nodes enables the training of relation embeddings with backpropagation\", \"Relation\": \"because\", \"Tail\": \"gradients flow back to relation embeddings through H-GAT during training\"}, {\"Head\": \"The attention decay mask encodes the spatial distance between graph nodes\", \"Relation\": \"so that\", \"Tail\": \"attention between two nodes decreases with respect to their distance\"}, {\"Head\": \"We introduce a square root in the exponent of the exponential mask\", \"Relation\": \"because\", \"Tail\": \"vocabulary sequence graphs experimentally need a smoother attention decay with respect to the shortest path\"}, {\"Head\": \"GraphMERT jointly pretrains using MLM over syntactic tokens and MNM over semantic leaves\", \"Relation\": \"as a result\", \"Tail\": \"the transformer token encoder is coupled with the H-GAT relation encoder aligning surface form and KG semantics\"}, {\"Head\": \"In the semantic space we mask all the leaf tokens whenever a leaf span is selected\", \"Relation\": \"because\", \"Tail\": \"relation embeddings must receive gradients from the entire tail to capture its full meaning\"}, {\"Head\": \"The seed KG is a set of domain-specific triples that serve as initial relation examples\", \"Relation\": \"as a result\", \"Tail\": \"the seed KG defines the relation set for the extracted KG\"}, {\"Head\": \"We apply a similarity filter to the seed KG against the training data\", \"Relation\": \"so that\", \"Tail\": \"the selected triples align with the target domain and identify triples most relevant to the context\"}, {\"Head\": \"For domain-specific head discovery in the dataset we use a helper LLM\", \"Relation\": \"and\", \"Tail\": \"we obtain candidate mappings to position triples within the semantic space\"}, {\"Head\": \"Entity linking uses SapBERT to produce vector embeddings for discovered entities and UMLS entities\", \"Relation\": \"so that\", \"Tail\": \"we can efficiently retrieve similar UMLS concepts using an ANN algorithm\"}]"}
{"id": "1", "original_text": "his method to retrieve the top 10 UMLS candidates based on the cosine similarity of their embeddings. Stage 2: Fine-grained filtering with string matching: The top candidates from embedding-based retrieval are then subjected to a more rigorous filtering process based on string similarity. We use characterlevel 3-grams (char-3grams) as a robust string comparison. Each entity name is represented as a set of char-3grams, which can be easily compared with others using standard set-based similarity metrics. We compute Jaccard similarity between the 3-gram sets of the source entity and each of the 10 candidate entities: <!-- formula-not-decoded --> A candidate entity is confirmed as a valid link only if its Jaccard similarity score is greater than the threshold. The threshold is set to 0.5 based on manual inspection. The entities that successfully pass both stages are considered the final Linked UMLS Entities and are used for the following task. ## 4.3.2 Contextual Triple Selection Following the entity linking stage, each input sequence is associated with a set of UMLS concepts. While these links grant access to the structured knowledge within UMLS, a single concept can be involved in hundreds of triples, many of which may be irrelevant to the specific context of the source text. Therefore, a crucial subsequent step is to identify and select only the most contextually relevant triples for each sequence. Figure 7: Data preparation for GraphMERT . To find the most relevant triples, we perform semantic similarity matching of triples to dataset sequences. The triple head should almost literally match one of the entities discovered in Step (I); from them, we pick the top triples whose tails are semantically close to the sequence. All matched triples are subject to the injection algorithm (III), which selects the top-scoring triples and limits the number of equivalent triples. The injected triples together comprise a seed KG . <!-- image --> We perform this selection using an embedding-based relevance-ranking procedure. For each sequence, we begin by retrieving the complete set of triples from the UMLS KG where any of the linked entities from that sequence appear as the head entity. We compute a semantic relevance score for each triple with respect to the original input sequence. We exclude triples with undesired relations from the search: relations that are not useful to have in the KG (see Table A1 in Appendix A). Specifically, each retrieved triple, consisting of a head, relation, and tail, is transformed into a linearized sentence by concatenating its components with spaces. We encode both the original input sequence and the sentence formed by each triple into high-dimensional vectors using the Gemini embedding model, textembedding-004, and use cosine similarity as the semantic relevance score. For each linked entity, we rank its associated triples by their semantic relevance scores and retain the top 40 triples. The resulting contextually filtered set of triples is then used in the subsequent injection process. ## 4.3.3 Seed KG Injection The KG injection algorithm prepares a GraphMERT -compatible dataset of leafy chain graphs by selecting relevant triples from an external KG source (potentially, limited in size) based on their similarity score to the input sequence, thresholded with a hyperparameter α . At the same time, the algorithm maintains diversity in the injected relations and semantic vocabulary. All triples selected by the algorithm comprise the seed KG. In this process (see Fig. 7), triples are mapped to the chain graph semantic space: The head is placed at a root node and the tail at the root's leaf node. Critically, the injected triples must be contextually relevant to the sequence. This aligns transformer attention with H-GAT during training on the chain graphs, as both attend to the semantic and syntactic spaces simultaneously; otherwise, the attention layers would get a noisy signal from extraneous tokens. Furthermore, because both H-GAT and transformer attention jointly train GraphMERT relation embeddings, alignment between leaf and root tokens enables vocabulary transfer from the syntactic root space into the semantic leaf space. This process forms integrated representations that support the retrieval of novel tails from a shared embedding space during prediction. Why do we need an injection algorithm? A naive strategy would be to inject the top-scoring triple for each head out of all the matched ones. We now demonstrate why a triple with the best similarity to a sequence may be suboptimal for both (a) populating the semantic space and (b) GraphMERT training. (a) Limitations for the semantic space: Similarity matching favors frequent terms in the dataset (Zhou et al., 2022). Hence, triples with common domain-specific keywords in tails score highly across many sequences. As a result, a small set of triples achieves high similarity scores across a large number of sequences. If only top matches were to be chosen, these ubiquitous tails would dominate the semantic space, suppressing rarer but semantically valuable tails that introduce novel terms into the semantic space. The scoring is also biased towards classificatory relations like isa or inverse\\_isa , since they often restate the head (e.g., 〈 fibrosing interstitial lung diseases, isa, fibrosis of lung 〉 in a biomedical KG). Such close textual matches contribute little new information. (b) Limitations for GraphMERT training: Over-injecting frequent tokens leads to a skewed training distribution. If the semantic space vocabulary is dominated by a few tokens, relation embeddings overfit on them, causing GraphMERT to predict a narrow token subset. Likewise, certain relations, e.g., 'isa' and 'inverse\\_isa,' would dominate the limited spots for injected triples, suppressing all other relations. Thus, GraphMERT will be undertrained on the other relations. Design goals: To address these limitations, we design the injection algorithm around three goals: 1. Eliminate low-relevance matched triples. 2. Select one triple ('inject') per head out of all matched with the sequence. 3. Diversify injected relations by balancing examples across all relations. Goal (1) can be satisfied by thresholding similarity scores. However, Goals (2) and (3) cannot be enforced independently: Selecting only the top match achieves (2) but undermines (3), amplifying certain top-scored relations, such as 'isa' . The algorithm must enforce (2) and (3) jointly, balancing contextual relevance with relation diversity. The proposed KG injection algorithm iteratively drops undesired triples from all matched triples in two interleaving phases: first, by maximizing the score; second, by maximizing the diversity of relations. The surviving triples are 'injected' into the semantic space and comprise the seed KG. We defer the description and implementation details to Appendix B. ## 4.4 GraphMERT Pipeline for Knowledge Graph Extraction We distill internal GraphMERT representations from the trained GraphMERT into explicit graph triples by adding leaf nodes. Using purely-MNM prediction, we distill semantic knowledge directly from GraphMERT weights, conditioned on a sequence from which we want to extract a triple. The role of a sequence in our framework is analogous to the role of a prompt in LLM-based KG generation, but our prediction is unambiguous and deterministic. Fig. 8 shows the execution order of the framework components. Fig. 9 illustrates the first pipeline step. Starting with the syntactic corpus (no KG injections), we sample head ( h ) spans from the syntactic space (root nodes) and assign an outgoing relation ( r ). We then create the corresponding tail slot ( t , leaf) for the chosen relation and initialize it with masks. We then ask the model to predict the masked tail (leaf) conditioned on the head, relation, and the rest of the sequence. The topk predictions for each masked leaf yield k candidate tokens, which serve as building blocks for tails of each head-relation pair 〈 h, r 〉 . Next, a helper LLM combines predicted tail tokens into coherent phrases, followed by a cleaning step. We further filter the generated triples by computing semantic similarity between each triple and its source sequence, discarding those with a score below the user-defined similarity check threshold β . GraphMERT may predict a tail that connects a head with a semantically related concept across the training corpus, and hyperparameter β regulates the fraction of such triples in the output. A higher β yields fewer but more sequence-specific triples, often explicitly included in the text. A lower β allows for broader, more general (yet semantically <!-- image --> Figure 8: GraphMERT Pipeline flowchart with temporal execution ordering of the main components. <!-- image --> 1. Choose a head for triple to be predicted ## PubMed papers (training dataset) <!-- image --> 3. Predict the masked leaf tokens (top k ) with the trained GraphMERT 2. Mask its leaf and set the target relation 4. Extract raw triples: head + relation + k tail token candidates 5. Form final triples for this head (with multi-token tails) <!-- image --> <!-- image --> <!-- image --> Figure 9: Prediction of triple tails. The trained GraphMERT predicts the top k tokens for a masked leaf and the chosen relation, resulting in a set of raw triples with the same head. related) triples that may not be explicitly mentioned in the sequence. However, if β is set too low, the output becomes flooded with triples that merely restate general truths, reflecting statistically dominant statements in the training dataset. The surviving 〈 h, r, t 〉 triples expand the KG with novel facts. Importantly, each prediction is traceable to its source sequence, while at the same time accumulating knowledge distilled from the entire training corpus. This global knowledge accumulation contrasts with RAG methods, which remain local to retrieved documents. Further, RAG is a post-hoc data attribution mechanism, unlike ours. Role of the helper LLM: The laborious (grammatical) part of the work is carried out with help from an LLM and the essential (triple extraction) part done with GraphMERT . In this pipeline, the helper LLM performs three auxiliary tasks: discovering head entities, selecting relations for subsequent GraphMERT prediction, and combining single-token predictions into meaningful, relation-aware tail phrases. Critically, the LLM is constrained: It cannot invent new entities or relations, as heads must be present in the dataset, relations are restricted to the seed KG, and only GraphMERT -predicted tokens are allowed to be in tails. Why do we need a helper LLM for combining tokens? An encoder-only model does not address span decoding. Masked span prediction would still be challenging for a small model, given the very limited number of semantic examples. Here, two factors come into play: 1. For a coherent span prediction, each token should be conditioned on other tokens. However, in an encoder-only model prediction, each masked token in the span is conditioned on the sequence independently of other span tokens. 2. In our experiments, training with span masking results in a prediction where tokens in the syntactic space are better aligned with each other within a span; however, the semantic space has orders of magnitude fewer examples (10 4 in our experiments). Given the limited scale of the semantic space, how to achieve the same effect on leaves remains an open question. Thus, training on small corpora to some extent trades English proficiency for data quality. Exploring methods to augment GraphMERT and thereby remove the LLM-based combining-tokens step is an avenue for future work. ## 4.5 LLM-generated KG To provide a fair and robust comparison for our framework, we construct a baseline LLM KG using a standard LLM-based pipeline that follows the GraphRAG indexing methodology, with a filtering step to align its schema with the GraphMERT KG. The process begins by segmenting the source documents into smaller, manageable text chunks. An LLM is then prompted to perform open information extraction on each chunk, which involves identifying entities, extracting the relationships between them, and generating short, descriptive summaries for each entity. We retain only the relationships that are part of our pre-defined relation set, discarding all others. This ensures that the resulting LLM KG shares exactly the same relational schema as our framework, enabling a direct and equitable comparison of performance. After filtering, the extracted elements are subsequently aggregated and consolidated into a final graph structure. To handle multiple mentions of the same concept, exact string matching is used to resolve entities into unique nodes. Relationships that are generated multiple times between the same two entities are aggregated into a single edge. ## 4.6 KG Verification We can subdivide KG verification methods into two categories: graph-level and triple-level . ## 4.6.1 Graph-level Verification This method evaluates the KG as a whole. It focuses on its logical coherence, internal consistency, comprehensiveness, coverage, important aspects of domain-relevant knowledge, and depth (considering whether it contains rich, insightful connections beyond surface-level facts). Graph-level approaches typically operate by retrieving relevant subgraphs and evaluating their quality with respect to these criteria. GraphRAG: We employ GraphRAG to evaluate the KGs and benchmark them across various tasks. The KGs are used as the primary source of informa", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "embedding-based retrieval", "Relation": "retrieves", "Tail": "top 10 UMLS candidates"}, {"Head": "character-level 3-grams", "Relation": "represent", "Tail": "entity names"}, {"Head": "Jaccard similarity", "Relation": "compares", "Tail": "3-gram sets"}, {"Head": "Jaccard similarity score", "Relation": "is thresholded by", "Tail": "0.5"}, {"Head": "entities that pass both stages", "Relation": "become", "Tail": "Linked UMLS Entities"}, {"Head": "Contextual triple selection", "Relation": "identifies", "Tail": "contextually relevant triples"}, {"Head": "triple head", "Relation": "must match", "Tail": "linked entity"}, {"Head": "Gemini embedding model textembedding-004", "Relation": "encodes", "Tail": "input sequences and linearized triples"}, {"Head": "cosine similarity", "Relation": "computes", "Tail": "semantic relevance scores"}, {"Head": "retrieved triples", "Relation": "are ranked and truncated to", "Tail": "top 40 triples per linked entity"}, {"Head": "KG injection algorithm", "Relation": "selects", "Tail": "seed KG triples"}, {"Head": "injection algorithm", "Relation": "maps", "Tail": "triples to chain graph semantic space"}, {"Head": "H-GAT and transformer attention", "Relation": "align with", "Tail": "injected chain graphs"}, {"Head": "injection algorithm", "Relation": "balances", "Tail": "contextual relevance and relation diversity"}, {"Head": "design goals", "Relation": "require", "Tail": "elimination of low-relevance triples"}, {"Head": "design goals", "Relation": "require", "Tail": "one triple injected per head"}, {"Head": "design goals", "Relation": "require", "Tail": "diversified injected relations"}, {"Head": "GraphMERT", "Relation": "distills", "Tail": "explicit graph triples from internal representations"}, {"Head": "helper LLM", "Relation": "combines", "Tail": "predicted tail tokens into coherent phrases"}, {"Head": "helper LLM", "Relation": "discovers and selects", "Tail": "head entities and relations for prediction"}, {"Head": "user-defined threshold β", "Relation": "filters", "Tail": "GraphMERT-predicted triples by semantic similarity"}, {"Head": "LLM-generated KG pipeline", "Relation": "uses", "Tail": "open information extraction on text chunks"}, {"Head": "LLM-generated KG pipeline", "Relation": "restricts", "Tail": "relationships to a predefined relation set"}, {"Head": "exact string matching", "Relation": "resolves", "Tail": "multiple mentions into unique entity nodes"}, {"Head": "GraphRAG", "Relation": "evaluates", "Tail": "knowledge graphs"}], "entity_relation_output": "[{\"Head\": \"embedding-based retrieval\", \"Relation\": \"retrieves\", \"Tail\": \"top 10 UMLS candidates\"}, {\"Head\": \"character-level 3-grams\", \"Relation\": \"represent\", \"Tail\": \"entity names\"}, {\"Head\": \"Jaccard similarity\", \"Relation\": \"compares\", \"Tail\": \"3-gram sets\"}, {\"Head\": \"Jaccard similarity score\", \"Relation\": \"is thresholded by\", \"Tail\": \"0.5\"}, {\"Head\": \"entities that pass both stages\", \"Relation\": \"become\", \"Tail\": \"Linked UMLS Entities\"}, {\"Head\": \"Contextual triple selection\", \"Relation\": \"identifies\", \"Tail\": \"contextually relevant triples\"}, {\"Head\": \"triple head\", \"Relation\": \"must match\", \"Tail\": \"linked entity\"}, {\"Head\": \"Gemini embedding model textembedding-004\", \"Relation\": \"encodes\", \"Tail\": \"input sequences and linearized triples\"}, {\"Head\": \"cosine similarity\", \"Relation\": \"computes\", \"Tail\": \"semantic relevance scores\"}, {\"Head\": \"retrieved triples\", \"Relation\": \"are ranked and truncated to\", \"Tail\": \"top 40 triples per linked entity\"}, {\"Head\": \"KG injection algorithm\", \"Relation\": \"selects\", \"Tail\": \"seed KG triples\"}, {\"Head\": \"injection algorithm\", \"Relation\": \"maps\", \"Tail\": \"triples to chain graph semantic space\"}, {\"Head\": \"H-GAT and transformer attention\", \"Relation\": \"align with\", \"Tail\": \"injected chain graphs\"}, {\"Head\": \"injection algorithm\", \"Relation\": \"balances\", \"Tail\": \"contextual relevance and relation diversity\"}, {\"Head\": \"design goals\", \"Relation\": \"require\", \"Tail\": \"elimination of low-relevance triples\"}, {\"Head\": \"design goals\", \"Relation\": \"require\", \"Tail\": \"one triple injected per head\"}, {\"Head\": \"design goals\", \"Relation\": \"require\", \"Tail\": \"diversified injected relations\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"distills\", \"Tail\": \"explicit graph triples from internal representations\"}, {\"Head\": \"helper LLM\", \"Relation\": \"combines\", \"Tail\": \"predicted tail tokens into coherent phrases\"}, {\"Head\": \"helper LLM\", \"Relation\": \"discovers and selects\", \"Tail\": \"head entities and relations for prediction\"}, {\"Head\": \"user-defined threshold β\", \"Relation\": \"filters\", \"Tail\": \"GraphMERT-predicted triples by semantic similarity\"}, {\"Head\": \"LLM-generated KG pipeline\", \"Relation\": \"uses\", \"Tail\": \"open information extraction on text chunks\"}, {\"Head\": \"LLM-generated KG pipeline\", \"Relation\": \"restricts\", \"Tail\": \"relationships to a predefined relation set\"}, {\"Head\": \"exact string matching\", \"Relation\": \"resolves\", \"Tail\": \"multiple mentions into unique entity nodes\"}, {\"Head\": \"GraphRAG\", \"Relation\": \"evaluates\", \"Tail\": \"knowledge graphs\"}]", "event_entity_dict": [{"Event": "Retrieve the top 10 UMLS candidates based on the cosine similarity of their embeddings", "Entity": ["method", "top 10 UMLS candidates", "cosine similarity", "embeddings"]}, {"Event": "Subject the top candidates from embedding-based retrieval to a more rigorous filtering process based on string similarity", "Entity": ["top candidates", "embedding-based retrieval", "filtering process", "string similarity"]}, {"Event": "Represent each entity name as a set of character-level 3-grams", "Entity": ["entity name", "char-3grams", "set"]}, {"Event": "Compute Jaccard similarity between the 3-gram sets of the source entity and each of the 10 candidate entities", "Entity": ["Jaccard similarity", "3-gram sets", "source entity", "10 candidate entities"]}, {"Event": "Confirm a candidate entity as a valid link only if its Jaccard similarity score is greater than the threshold", "Entity": ["candidate entity", "valid link", "Jaccard similarity score", "threshold"]}, {"Event": "Set the threshold to 0.5 based on manual inspection", "Entity": ["threshold", "0.5", "manual inspection"]}, {"Event": "Consider entities that successfully pass both stages as the final Linked UMLS Entities", "Entity": ["entities", "both stages", "final Linked UMLS Entities"]}, {"Event": "Associate each input sequence with a set of UMLS concepts following the entity linking stage", "Entity": ["input sequence", "UMLS concepts", "entity linking stage"]}, {"Event": "Identify and select only the most contextually relevant triples for each sequence", "Entity": ["contextually relevant triples", "sequence"]}, {"Event": "Perform semantic similarity matching of triples to dataset sequences to find the most relevant triples", "Entity": ["semantic similarity matching", "triples", "dataset sequences"]}, {"Event": "Require the triple head to almost literally match one of the discovered entities and pick top triples whose tails are semantically close to the sequence", "Entity": ["triple head", "discovered entities", "top triples", "tails", "sequence"]}, {"Event": "Subject all matched triples to the injection algorithm which selects the top-scoring triples and limits the number of equivalent triples", "Entity": ["matched triples", "injection algorithm", "top-scoring triples", "equivalent triples"]}, {"Event": "Use the injected triples together to comprise a seed KG", "Entity": ["injected triples", "seed KG"]}, {"Event": "Retrieve the complete set of triples from the UMLS KG where any linked entities from a sequence appear as the head entity", "Entity": ["complete set of triples", "UMLS KG", "linked entities", "sequence", "head entity"]}, {"Event": "Compute a semantic relevance score for each triple with respect to the original input sequence", "Entity": ["semantic relevance score", "triple", "original input sequence"]}, {"Event": "Exclude triples with undesired relations from the search", "Entity": ["triples", "undesired relations", "search"]}, {"Event": "Transform each retrieved triple into a linearized sentence by concatenating its head, relation, and tail", "Entity": ["retrieved triple", "linearized sentence", "head", "relation", "tail"]}, {"Event": "Encode both the original input sequence and each triple sentence into high-dimensional vectors using the Gemini embedding model and textembedding-004", "Entity": ["original input sequence", "triple sentence", "high-dimensional vectors", "Gemini embedding model", "textembedding-004"]}, {"Event": "Use cosine similarity as the semantic relevance score between sequence and triple encodings", "Entity": ["cosine similarity", "semantic relevance score", "sequence encodings", "triple encodings"]}, {"Event": "Rank each linked entity's associated triples by semantic relevance scores and retain the top 40 triples", "Entity": ["linked entity", "associated triples", "semantic relevance scores", "top 40 triples"]}, {"Event": "Use the resulting contextually filtered set of triples in the subsequent injection process", "Entity": ["contextually filtered set of triples", "injection process"]}, {"Event": "Prepare a GraphMERT-compatible dataset of leafy chain graphs by selecting relevant triples from an external KG source based on similarity score thresholded with hyperparameter alpha", "Entity": ["GraphMERT-compatible dataset", "leafy chain graphs", "relevant triples", "external KG source", "similarity score", "hyperparameter α"]}, {"Event": "Map triples to the chain graph semantic space by placing the head at a root node and the tail at the root's leaf node", "Entity": ["triples", "chain graph semantic space", "head", "root node", "tail", "leaf node"]}, {"Event": "Maintain diversity in the injected relations and semantic vocabulary while selecting triples", "Entity": ["diversity", "injected relations", "semantic vocabulary", "triples"]}, {"Event": "Align transformer attention with H-GAT during training on chain graphs to avoid noisy signals from extraneous tokens", "Entity": ["transformer attention", "H-GAT", "training", "chain graphs", "extraneous tokens"]}, {"Event": "Enable vocabulary transfer from the syntactic root space into the semantic leaf space by aligning leaf and root tokens", "Entity": ["vocabulary transfer", "syntactic root space", "semantic leaf space", "leaf tokens", "root tokens"]}, {"Event": "Explain that similarity matching favors frequent terms leading ubiquitous tails to dominate the semantic space", "Entity": ["similarity matching", "frequent terms", "ubiquitous tails", "semantic space"]}, {"Event": "Describe that scoring is biased towards classificatory relations like isa or inverse_isa", "Entity": ["scoring", "classificatory relations", "isa", "inverse_isa"]}, {"Event": "State that over-injecting frequent tokens leads to a skewed training distribution and undertraining on other relations", "Entity": ["over-injecting frequent tokens", "skewed training distribution", "relation embeddings", "GraphMERT", "other relations"]}, {"Event": "Design the injection algorithm around three goals: eliminate low-relevance triples, select one triple per head, and diversify injected relations", "Entity": ["injection algorithm", "low-relevance triples", "one triple per head", "diversify injected relations", "goals"]}, {"Event": "Satisfy goal (1) by thresholding similarity scores", "Entity": ["goal (1)", "thresholding", "similarity scores"]}, {"Event": "Iteratively drop undesired triples from all matched triples in two interleaving phases by maximizing score and maximizing relation diversity", "Entity": ["undesired triples", "matched triples", "interleaving phases", "maximize score", "maximize relation diversity"]}, {"Event": "Inject the surviving triples into the semantic space to comprise the seed KG", "Entity": ["surviving triples", "semantic space", "seed KG"]}, {"Event": "Distill internal GraphMERT representations into explicit graph triples by adding leaf nodes using purely-MNM prediction", "Entity": ["internal GraphMERT representations"]}], "event_entity_output": "[{\"Event\": \"Retrieve the top 10 UMLS candidates based on the cosine similarity of their embeddings\", \"Entity\": [\"method\", \"top 10 UMLS candidates\", \"cosine similarity\", \"embeddings\"]}, {\"Event\": \"Subject the top candidates from embedding-based retrieval to a more rigorous filtering process based on string similarity\", \"Entity\": [\"top candidates\", \"embedding-based retrieval\", \"filtering process\", \"string similarity\"]}, {\"Event\": \"Represent each entity name as a set of character-level 3-grams\", \"Entity\": [\"entity name\", \"char-3grams\", \"set\"]}, {\"Event\": \"Compute Jaccard similarity between the 3-gram sets of the source entity and each of the 10 candidate entities\", \"Entity\": [\"Jaccard similarity\", \"3-gram sets\", \"source entity\", \"10 candidate entities\"]}, {\"Event\": \"Confirm a candidate entity as a valid link only if its Jaccard similarity score is greater than the threshold\", \"Entity\": [\"candidate entity\", \"valid link\", \"Jaccard similarity score\", \"threshold\"]}, {\"Event\": \"Set the threshold to 0.5 based on manual inspection\", \"Entity\": [\"threshold\", \"0.5\", \"manual inspection\"]}, {\"Event\": \"Consider entities that successfully pass both stages as the final Linked UMLS Entities\", \"Entity\": [\"entities\", \"both stages\", \"final Linked UMLS Entities\"]}, {\"Event\": \"Associate each input sequence with a set of UMLS concepts following the entity linking stage\", \"Entity\": [\"input sequence\", \"UMLS concepts\", \"entity linking stage\"]}, {\"Event\": \"Identify and select only the most contextually relevant triples for each sequence\", \"Entity\": [\"contextually relevant triples\", \"sequence\"]}, {\"Event\": \"Perform semantic similarity matching of triples to dataset sequences to find the most relevant triples\", \"Entity\": [\"semantic similarity matching\", \"triples\", \"dataset sequences\"]}, {\"Event\": \"Require the triple head to almost literally match one of the discovered entities and pick top triples whose tails are semantically close to the sequence\", \"Entity\": [\"triple head\", \"discovered entities\", \"top triples\", \"tails\", \"sequence\"]}, {\"Event\": \"Subject all matched triples to the injection algorithm which selects the top-scoring triples and limits the number of equivalent triples\", \"Entity\": [\"matched triples\", \"injection algorithm\", \"top-scoring triples\", \"equivalent triples\"]}, {\"Event\": \"Use the injected triples together to comprise a seed KG\", \"Entity\": [\"injected triples\", \"seed KG\"]}, {\"Event\": \"Retrieve the complete set of triples from the UMLS KG where any linked entities from a sequence appear as the head entity\", \"Entity\": [\"complete set of triples\", \"UMLS KG\", \"linked entities\", \"sequence\", \"head entity\"]}, {\"Event\": \"Compute a semantic relevance score for each triple with respect to the original input sequence\", \"Entity\": [\"semantic relevance score\", \"triple\", \"original input sequence\"]}, {\"Event\": \"Exclude triples with undesired relations from the search\", \"Entity\": [\"triples\", \"undesired relations\", \"search\"]}, {\"Event\": \"Transform each retrieved triple into a linearized sentence by concatenating its head, relation, and tail\", \"Entity\": [\"retrieved triple\", \"linearized sentence\", \"head\", \"relation\", \"tail\"]}, {\"Event\": \"Encode both the original input sequence and each triple sentence into high-dimensional vectors using the Gemini embedding model and textembedding-004\", \"Entity\": [\"original input sequence\", \"triple sentence\", \"high-dimensional vectors\", \"Gemini embedding model\", \"textembedding-004\"]}, {\"Event\": \"Use cosine similarity as the semantic relevance score between sequence and triple encodings\", \"Entity\": [\"cosine similarity\", \"semantic relevance score\", \"sequence encodings\", \"triple encodings\"]}, {\"Event\": \"Rank each linked entity's associated triples by semantic relevance scores and retain the top 40 triples\", \"Entity\": [\"linked entity\", \"associated triples\", \"semantic relevance scores\", \"top 40 triples\"]}, {\"Event\": \"Use the resulting contextually filtered set of triples in the subsequent injection process\", \"Entity\": [\"contextually filtered set of triples\", \"injection process\"]}, {\"Event\": \"Prepare a GraphMERT-compatible dataset of leafy chain graphs by selecting relevant triples from an external KG source based on similarity score thresholded with hyperparameter alpha\", \"Entity\": [\"GraphMERT-compatible dataset\", \"leafy chain graphs\", \"relevant triples\", \"external KG source\", \"similarity score\", \"hyperparameter α\"]}, {\"Event\": \"Map triples to the chain graph semantic space by placing the head at a root node and the tail at the root's leaf node\", \"Entity\": [\"triples\", \"chain graph semantic space\", \"head\", \"root node\", \"tail\", \"leaf node\"]}, {\"Event\": \"Maintain diversity in the injected relations and semantic vocabulary while selecting triples\", \"Entity\": [\"diversity\", \"injected relations\", \"semantic vocabulary\", \"triples\"]}, {\"Event\": \"Align transformer attention with H-GAT during training on chain graphs to avoid noisy signals from extraneous tokens\", \"Entity\": [\"transformer attention\", \"H-GAT\", \"training\", \"chain graphs\", \"extraneous tokens\"]}, {\"Event\": \"Enable vocabulary transfer from the syntactic root space into the semantic leaf space by aligning leaf and root tokens\", \"Entity\": [\"vocabulary transfer\", \"syntactic root space\", \"semantic leaf space\", \"leaf tokens\", \"root tokens\"]}, {\"Event\": \"Explain that similarity matching favors frequent terms leading ubiquitous tails to dominate the semantic space\", \"Entity\": [\"similarity matching\", \"frequent terms\", \"ubiquitous tails\", \"semantic space\"]}, {\"Event\": \"Describe that scoring is biased towards classificatory relations like isa or inverse_isa\", \"Entity\": [\"scoring\", \"classificatory relations\", \"isa\", \"inverse_isa\"]}, {\"Event\": \"State that over-injecting frequent tokens leads to a skewed training distribution and undertraining on other relations\", \"Entity\": [\"over-injecting frequent tokens\", \"skewed training distribution\", \"relation embeddings\", \"GraphMERT\", \"other relations\"]}, {\"Event\": \"Design the injection algorithm around three goals: eliminate low-relevance triples, select one triple per head, and diversify injected relations\", \"Entity\": [\"injection algorithm\", \"low-relevance triples\", \"one triple per head\", \"diversify injected relations\", \"goals\"]}, {\"Event\": \"Satisfy goal (1) by thresholding similarity scores\", \"Entity\": [\"goal (1)\", \"thresholding\", \"similarity scores\"]}, {\"Event\": \"Iteratively drop undesired triples from all matched triples in two interleaving phases by maximizing score and maximizing relation diversity\", \"Entity\": [\"undesired triples\", \"matched triples\", \"interleaving phases\", \"maximize score\", \"maximize relation diversity\"]}, {\"Event\": \"Inject the surviving triples into the semantic space to comprise the seed KG\", \"Entity\": [\"surviving triples\", \"semantic space\", \"seed KG\"]}, {\"Event\": \"Distill internal GraphMERT representations into explicit graph triples by adding leaf nodes using purely-MNM prediction\", \"Entity\": [\"internal GraphMERT representations\"]}]", "event_relation_dict": [{"Head": "Retrieve the top 10 UMLS candidates based on cosine similarity of their embeddings", "Relation": "before", "Tail": "Subject the top candidates to fine-grained filtering based on string similarity"}, {"Head": "Represent each entity name as a set of character-level 3-grams", "Relation": "because", "Tail": "We can compare entity names using standard set-based similarity metrics"}, {"Head": "Compute Jaccard similarity between the 3-gram sets of the source entity and each of the 10 candidate entities", "Relation": "because", "Tail": "A candidate entity can be confirmed as a valid link only if its Jaccard similarity score is greater than the threshold"}, {"Head": "Set the Jaccard similarity threshold to 0.5 based on manual inspection", "Relation": "as a result", "Tail": "Candidates with Jaccard similarity scores greater than 0.5 are confirmed as valid links"}, {"Head": "Entities that pass both embedding-based retrieval and string-matching filtering", "Relation": "as a result", "Tail": "Are considered the final Linked UMLS Entities and are used for the following task"}, {"Head": "Complete the entity linking stage", "Relation": "after", "Tail": "Associate each input sequence with a set of UMLS concepts"}, {"Head": "A single concept can be involved in hundreds of triples, many irrelevant to the source text", "Relation": "because", "Tail": "A crucial subsequent step is to identify and select only the most contextually relevant triples for each sequence"}, {"Head": "Perform semantic similarity matching of triples to dataset sequences", "Relation": "to", "Tail": "Find the most relevant triples for each sequence"}, {"Head": "The triple head should almost literally match one of the entities discovered in Step (I)", "Relation": "before", "Tail": "Pick the top triples whose tails are semantically close to the sequence"}, {"Head": "All matched triples", "Relation": "are subject to", "Tail": "The injection algorithm that selects top-scoring triples and limits the number of equivalent triples"}, {"Head": "Injected triples", "Relation": "as a result", "Tail": "Comprise a seed KG"}, {"Head": "For each sequence, retrieve the complete set of triples from the UMLS KG where any of the linked entities appear as the head", "Relation": "before", "Tail": "Compute a semantic relevance score for each triple with respect to the original input sequence"}, {"Head": "Transform each retrieved triple into a linearized sentence and encode it with the Gemini embedding model", "Relation": "because", "Tail": "Use cosine similarity between encoded vectors to obtain the semantic relevance score"}, {"Head": "Exclude triples with undesired relations from the search", "Relation": "as a result", "Tail": "Filter out relations that are not useful to have in the KG"}, {"Head": "Rank associated triples by semantic relevance scores for each linked entity and retain the top 40", "Relation": "as a result", "Tail": "Obtain a contextually filtered set of triples for the injection process"}, {"Head": "KG injection algorithm selects relevant triples based on similarity threshold α while maintaining diversity", "Relation": "because", "Tail": "The algorithm must prevent dominance of frequent tails and relations in the semantic space and training"}, {"Head": "Map selected triples to the chain graph semantic space with the head at the root and tail at the leaf", "Relation": "because", "Tail": "This aligns transformer attention with H-GAT during training on the chain graphs"}, {"Head": "Alignment between leaf and root tokens during training", "Relation": "as a result", "Tail": "Enables vocabulary transfer from the syntactic root space into the semantic leaf space"}, {"Head": "A naive strategy of injecting only the top-scoring triple per head", "Relation": "because", "Tail": "May be suboptimal for populating the semantic space and GraphMERT training"}, {"Head": "Similarity matching favors frequent terms and classificatory relations", "Relation": "as a result", "Tail": "A small set of ubiquitous tails would dominate the semantic space"}, {"Head": "Dominance of ubiquitous tails and relations in injected triples", "Relation": "as a result", "Tail": "Skews GraphMERT training distribution and causes relation embeddings to overfit"}, {"Head": "Design injection algorithm around goals to eliminate low-relevance triples, inject one triple per head, and diversify relations", "Relation": "as a result", "Tail": "The algorithm iteratively drops undesired triples by maximizing score and then maximizing relation diversity"}, {"Head": "Surviving triples after the injection algorithm's two-phase selection", "Relation": "as a result", "Tail": "Are injected into the semantic space and comprise the seed KG"}, {"Head": "Distill GraphMERT representations into explicit graph triples by adding leaf nodes", "Relation": "before", "Tail": "Use MNM prediction conditioned on a sequence to predict masked tail tokens"}, {"Head": "Mask the leaf and set the target relation for a sampled head span", "Relation": "before", "Tail": "Ask the model to predict the masked tail tokens and obtain top-k candidate tokens"}, {"Head": "The helper LLM combines predicted tail tokens into coherent phrases and cleans them", "Relation": "because", "Tail": "An encoder-only model conditions each masked token independently and struggles with span decoding"}, {"Head": "Filter generated triples by computing semantic similarity between each triple and its source sequence with threshold β", "Relation": "as a result", "Tail": "Discard triples with score below β and retain surviving triples to expand the KG"}, {"Head": "Set a higher β", "Relation": "as a result", "Tail": "Yield fewer but more sequence-specific triples often explicitly included in the text"}, {"Head": "Set a lower β", "Relation": "as a result", "Tail": "Allow broader, more general triples that may not be explicitly mentioned in the sequence"}, {"Head": "Constrain the helper LLM so it cannot invent new entities or relations", "Relation": "because", "Tail": "Heads must be present in the dataset, relations are restricted to the seed KG, and only GraphMERT-predicted tokens are allowed in tails"}], "event_relation_output": "[{\"Head\": \"Retrieve the top 10 UMLS candidates based on cosine similarity of their embeddings\", \"Relation\": \"before\", \"Tail\": \"Subject the top candidates to fine-grained filtering based on string similarity\"}, {\"Head\": \"Represent each entity name as a set of character-level 3-grams\", \"Relation\": \"because\", \"Tail\": \"We can compare entity names using standard set-based similarity metrics\"}, {\"Head\": \"Compute Jaccard similarity between the 3-gram sets of the source entity and each of the 10 candidate entities\", \"Relation\": \"because\", \"Tail\": \"A candidate entity can be confirmed as a valid link only if its Jaccard similarity score is greater than the threshold\"}, {\"Head\": \"Set the Jaccard similarity threshold to 0.5 based on manual inspection\", \"Relation\": \"as a result\", \"Tail\": \"Candidates with Jaccard similarity scores greater than 0.5 are confirmed as valid links\"}, {\"Head\": \"Entities that pass both embedding-based retrieval and string-matching filtering\", \"Relation\": \"as a result\", \"Tail\": \"Are considered the final Linked UMLS Entities and are used for the following task\"}, {\"Head\": \"Complete the entity linking stage\", \"Relation\": \"after\", \"Tail\": \"Associate each input sequence with a set of UMLS concepts\"}, {\"Head\": \"A single concept can be involved in hundreds of triples, many irrelevant to the source text\", \"Relation\": \"because\", \"Tail\": \"A crucial subsequent step is to identify and select only the most contextually relevant triples for each sequence\"}, {\"Head\": \"Perform semantic similarity matching of triples to dataset sequences\", \"Relation\": \"to\", \"Tail\": \"Find the most relevant triples for each sequence\"}, {\"Head\": \"The triple head should almost literally match one of the entities discovered in Step (I)\", \"Relation\": \"before\", \"Tail\": \"Pick the top triples whose tails are semantically close to the sequence\"}, {\"Head\": \"All matched triples\", \"Relation\": \"are subject to\", \"Tail\": \"The injection algorithm that selects top-scoring triples and limits the number of equivalent triples\"}, {\"Head\": \"Injected triples\", \"Relation\": \"as a result\", \"Tail\": \"Comprise a seed KG\"}, {\"Head\": \"For each sequence, retrieve the complete set of triples from the UMLS KG where any of the linked entities appear as the head\", \"Relation\": \"before\", \"Tail\": \"Compute a semantic relevance score for each triple with respect to the original input sequence\"}, {\"Head\": \"Transform each retrieved triple into a linearized sentence and encode it with the Gemini embedding model\", \"Relation\": \"because\", \"Tail\": \"Use cosine similarity between encoded vectors to obtain the semantic relevance score\"}, {\"Head\": \"Exclude triples with undesired relations from the search\", \"Relation\": \"as a result\", \"Tail\": \"Filter out relations that are not useful to have in the KG\"}, {\"Head\": \"Rank associated triples by semantic relevance scores for each linked entity and retain the top 40\", \"Relation\": \"as a result\", \"Tail\": \"Obtain a contextually filtered set of triples for the injection process\"}, {\"Head\": \"KG injection algorithm selects relevant triples based on similarity threshold α while maintaining diversity\", \"Relation\": \"because\", \"Tail\": \"The algorithm must prevent dominance of frequent tails and relations in the semantic space and training\"}, {\"Head\": \"Map selected triples to the chain graph semantic space with the head at the root and tail at the leaf\", \"Relation\": \"because\", \"Tail\": \"This aligns transformer attention with H-GAT during training on the chain graphs\"}, {\"Head\": \"Alignment between leaf and root tokens during training\", \"Relation\": \"as a result\", \"Tail\": \"Enables vocabulary transfer from the syntactic root space into the semantic leaf space\"}, {\"Head\": \"A naive strategy of injecting only the top-scoring triple per head\", \"Relation\": \"because\", \"Tail\": \"May be suboptimal for populating the semantic space and GraphMERT training\"}, {\"Head\": \"Similarity matching favors frequent terms and classificatory relations\", \"Relation\": \"as a result\", \"Tail\": \"A small set of ubiquitous tails would dominate the semantic space\"}, {\"Head\": \"Dominance of ubiquitous tails and relations in injected triples\", \"Relation\": \"as a result\", \"Tail\": \"Skews GraphMERT training distribution and causes relation embeddings to overfit\"}, {\"Head\": \"Design injection algorithm around goals to eliminate low-relevance triples, inject one triple per head, and diversify relations\", \"Relation\": \"as a result\", \"Tail\": \"The algorithm iteratively drops undesired triples by maximizing score and then maximizing relation diversity\"}, {\"Head\": \"Surviving triples after the injection algorithm's two-phase selection\", \"Relation\": \"as a result\", \"Tail\": \"Are injected into the semantic space and comprise the seed KG\"}, {\"Head\": \"Distill GraphMERT representations into explicit graph triples by adding leaf nodes\", \"Relation\": \"before\", \"Tail\": \"Use MNM prediction conditioned on a sequence to predict masked tail tokens\"}, {\"Head\": \"Mask the leaf and set the target relation for a sampled head span\", \"Relation\": \"before\", \"Tail\": \"Ask the model to predict the masked tail tokens and obtain top-k candidate tokens\"}, {\"Head\": \"The helper LLM combines predicted tail tokens into coherent phrases and cleans them\", \"Relation\": \"because\", \"Tail\": \"An encoder-only model conditions each masked token independently and struggles with span decoding\"}, {\"Head\": \"Filter generated triples by computing semantic similarity between each triple and its source sequence with threshold β\", \"Relation\": \"as a result\", \"Tail\": \"Discard triples with score below β and retain surviving triples to expand the KG\"}, {\"Head\": \"Set a higher β\", \"Relation\": \"as a result\", \"Tail\": \"Yield fewer but more sequence-specific triples often explicitly included in the text\"}, {\"Head\": \"Set a lower β\", \"Relation\": \"as a result\", \"Tail\": \"Allow broader, more general triples that may not be explicitly mentioned in the sequence\"}, {\"Head\": \"Constrain the helper LLM so it cannot invent new entities or relations\", \"Relation\": \"because\", \"Tail\": \"Heads must be present in the dataset, relations are restricted to the seed KG, and only GraphMERT-predicted tokens are allowed in tails\"}]"}
{"id": "1", "original_text": "tion in GraphRAG to answer medical questions, which enables us to compare their effectiveness directly. In our implementation, we use the Local Search method from GraphRAG and modify it to rely exclusively on the entities and relations in the querying stage. This process begins by identifying a set of entities within the KG that are semantically related to the user query. These entities act as entry points for the retrieval of connected entities and relationships. The retrieved data sources are then ranked and filtered to fit within a single predefined context window, which is used to generate a response to the user query. ## 4.6.2 Triple-level Verification At the triple level, verification can enhance factuality and validity , as we describe next. FActScore: The FActScore framework (Min et al., 2023) provides a fine-grained method for evaluating factual precision in long-form LLM outputs. Its principles transfer naturally to KG verification. FActScore evaluates atomic facts, i.e., short, self-contained statements, against a trusted text source that does not have any knowledge conflicts or overlaps. KG triples can be treated as atomic facts of equal importance. In our setting, each triple can be paired with a reliable text source: GraphMERT triples with sequences and LLM triples with short chunks, both drawn from the same trustworthy source. The short context length minimizes conflicts and overlaps. FActScore*: We follow the Retrieve → LM variant of automatic evaluation, in which an atomic fact is concatenated with the knowledge source and provided to the model. However, we strengthen triple evaluation with validity: In the prompt, we require verification of triple logical alignment in addition to context support, since the fact may appear in the text, yet the triple may still be malformed. Malformed triples should not be deemed reliable facts and would inflate the score. Because our prompt departs from the original FActScore prompt, we denote the modified version as FActScore*. Formally, let G be a set of triples τ , and C ( τ ) the text source of τ . Then FActScore* for G is: <!-- formula-not-decoded --> ValidityScore: Triples should follow semantic rules of a KG. For example, in UMLS (Bodenreider, 2004), the triple 〈 beta-receptor, part\\_of, plasma membrane 〉 is valid, since part\\_of denotes a meronymic (structural/spatial) relation: Every instance of the part must be a constituent of some instance of the whole. It follows, then, that 〈 beta-receptor, part\\_of, adrenergic signaling 〉 is invalid, because it links a physical structure to a biological process. Similarly, 〈 beta-receptor, part\\_of, human 〉 is factually plausible but still an illegitimate usage, since it violates granularity: The correct wholes are specific structures (e.g., plasma membrane), not entire organisms. To quantitatively measure the validity of triples, we propose ValidityScore. It isolates ontological alignment of triples as an independent mode of evaluation. Concretely, we use a strong LLM judge to semantically validate a triple using the following prompt. Prompt. Evaluate if these medical KG triples are valid (yes/no/maybe) and give a very short reason why: 〈 list of triples 〉 . Then ValidityScore counts the number of 'yes' responses. ## 5 Experimental Setup To demonstrate the effectiveness of our framework, we extract a high-quality diabetes KG from a GraphMERT -compatible diabetes training dataset obtained from expert-verified sources. This section provides an in-depth explanation of the proposed training, extraction, and evaluation pipeline. ## 5.1 GraphMERT Training and Extraction Next, we discuss training data preparation and triple extraction. Table 1: Dataset size | | Abstracts | Tokens | Sequences | |------------|-------------|----------|-------------| | Training | 350k | 124.7M | 989,666 | | Evaluation | 39k | 13.9M | 110,297 | Table 2: Seed KG statistics for α = 0 . 55 (after Qwen3-32B). We obtain this seed KG based on the 1.1258E+06 matched UMLS triples with a similarity score greater than or equal to α . | Triples count | Similarity score mean | Similarity score median | Similarity score max | Number of relations | |-----------------|-------------------------|---------------------------|------------------------|-----------------------| | 28533 | 0.613 | 0.605 | 0.848 | 28 | ## 5.1.1 Training Data Preparation We showcase our framework in a sensitive medical domain, where concerns over trustworthiness of AI output remain the main barrier to wider AI adoption (Wang et al., 2025b; Mishra et al., 2024), despite the undeniable potential of AI in medical practice. As a case study, we set the goal of extracting a high-quality diabetes KG. It all starts with high-quality textual data. We build a GraphMERT -compatible diabetes training dataset (Table 1) from two main sources: (1) peer-reviewed medical abstracts from MEDLINE journals accessed via PubMed Central, and (2) a seed KG derived from the UMLS Metathesaurus (Bodenreider, 2004). Text corpus: MEDLINE is the National Library of Medicine's bibliographic database and is accessible via PubMed. MEDLINE selects journals based on rigorous criteria and indexes them using MeSH terms. We retrieved diabetes-related papers from PubMed Central (see the query in Listing 1 in Appendix A), removed non-English records, parsed abstracts using the PubMed parser (Achakulvisut et al., 2020), lowercased all text, and filtered out opening boilerplate words such as 'Abstract,' 'Background,' 'Introduction,' etc., with a regular expression. The resulting dataset contains 350k abstracts for training and 39k for evaluation, totaling 124.7M and 13.9M tokens, respectively. Seed KG: From UMLS, we select SNOMED CT, US and GO (Gene Ontology) vocabularies because together they cover a broad range of biomedical concepts across clinical documentation, molecular biology, and data exchange. We exclude low-value relations (more details in Appendix A) and retrieve triples relevant to our dataset sequences based on semantic similarity matching (Sec. 4.3.1) with Gemini text-embedding-004. For matched triples, we use an injection algorithm (Sec. 4.3.3) with a similarity threshold α of 0.55, validated experimentally via grid search using GraphRAG evaluation (see Sec. 6.4.1). The resulting triples that are injected comprise the seed KG (Table 2). Statistics per relation are presented in Table B1 (Appendix B) As a helper LLM, we employ Qwen3-32B-FP8 (an 8-bit quantized version of Qwen3-32B, further referred to as Qwen3-32B), an open-source, advanced, and lightweight LLM with 'thinking mode' turned on. We always use 'thinking mode,' unless otherwise specified. Entity discovery and relation matching: For head discovery, we prompt Qwen3-32B with each abstract sequence in the dataset with few-shot examples, asking it to search for medical entities that are relevant to diabetes and its comorbidities. From our observations, changing an example in the prompt significantly changes the number of discovered entities. The outputs are validated against sequences of origin to eliminate hallucinated or misspelled entities. For relation discovery, Qwen3-32B is few-shot prompted with a relation list from the corresponding training seed KG to match entities with all relations that make sense for a given entity in the context of the current sequence. Prompts and examples are presented in Appendix E. All Qwen3-32B runs are performed on the Princeton cluster on one H100 GPU using vLLM with the vendorrecommended sampling parameters: temperature = 0 . 6, top \\_ p = 0 . 95, top \\_ k = 20, and min \\_ p = 0. In addition, max \\_ tokens and max \\_ model \\_ len are set to 8192, which is sufficient for our generation length. Figure 10: Leafy chain graph encoded sequentially: 7-leaf case. The sequence has a fixed length of 1024. The first 128 tokens are reserved for roots and leaves reside in the remaining tokens. The first group of seven leaves belongs to the first root, the second group of seven leaves belongs to the second root, and so on. Each leaf token group is padded to the maximum length of seven. <!-- image --> Chain graphs for training: Chain graphs are initialized with 128 root nodes, each connected to seven leaves, leading to a 1024-token sequence (see Fig. 10). These numbers are chosen to fit GPU memory constraints while providing sufficient room for semantic tokens dedicated to leaves. ## 5.1.2 GraphMERT Training We train GraphMERT with 12 hidden layers, eight attention heads, a hidden size of 512, and an intermediate size of a fully-connected layer of 2048, totaling 79.7M trainable parameters. We use the BioMedBERT tokenizer (Chakraborty et al., 2020), trained on a vast amount of medical vocabulary, to prevent frequent subword tokenization of common medical terms, which is particularly beneficial for the extraction stage. The tokenizer determines the vocabulary size, which is 30,522. Training runs for 25 epochs on four H100 GPUs with BF16 precision, totaling 90 GPU hours. We use an instantaneous batch size of 32 per GPU, achieving an effective batch size of 128 through gradient accumulation (steps = 2). We set dropout rates at 0.1 for regular, attention, and activation dropouts. In addition, we set an exponential mask with base λ = 0 . 6 and relation embedding dropout of 0.3. We train the model using the cosine learning rate scheduler with the maximum learning rate set to 4 × 10 -4 . We use 500 steps for warm-up. The weight decay at each step is 0.01 times the learning rate at that step. We stop training when the learning rate reaches 1 × 10 -5 . In the span masking training schema, we limit masked spans to a maximum length of seven, matching the number of leaf nodes connected to root nodes. ## 5.1.3 Triple Extraction The triple extraction pipeline runs the following steps, as shown in Fig. 11. We begin with a leaf-masked prediction over the training dataset, given head entities and their relations. This produces a vocabulary distribution for each masked leaf. From this distribution, we select the top 20 tokens per leaf and use them to prompt the helper LLM, Qwen3-32B. Conditioned on the head, relation, and the originating sequence, the LLM combines these tokens into coherent, relevant, and medically meaningful multi-token tails (see Appendix E for the prompt specification). When no valid tail can be formed, the corresponding 〈 sequence, head, relation 〉 is skipped. Next, since the LLM may hallucinate tails outside the GraphMERT -predicted Figure 11: I. Forming triple tails for a given sequence with GraphMERT . (1) Given a sequence as a context, a triple head in the sequence, and a relation, GraphMERT predicts the tail token (we obtain the top 20). (2) The helper LLM attempts to combine the tokens into a complete, coherent medical term. It may output several or no tail candidates to complete the triple. (3) We evaluate the similarity score between triples from the previous step and the sequence of origin. Only triples with a score higher than a preset threshold pass. II. An example of a triple extracted with the LLM pipeline (Qwen3-32B) from the same context. Here, LLM misinterprets the 'has\\_finding\\_site' relation, treating 'site' as a location instead of an anatomical structure, which results in an invalid triple. <!-- image --> token space, we discard any output tails that contain out-of-scope tokens. The output of this stage is a set of completed candidate tails. Next, each candidate triple is evaluated with a similarity matching algorithm (Sec. 4.3.1). Specifically, we compute the cosine similarity between the triple and its originating sequence using Gemini embeddings. All triples with a score below the similarity check threshold β = 0 . 67 (obtained through grid search, see Sec. 6.4.1) are discarded. The remaining set forms the final collection of extracted triples. Table 3 illustrates the step-by-step triple extraction process for a representative sequence. Given a sequence with its head and relation, GraphMERT predicts a token in a masked tail. From the output distribution, we select the top 20 tokens as candidate tails, striking a balance between prediction quality and diversity, and providing a sufficient pool for subsequent token combination. We may construct zero, one, or several novel triples out of these. Table 3: Examples of GraphMERT -extracted triples (UMLS-style) from a single sequence. We pass the sequence with two marked heads together with relations for these heads to the trained GraphMERT . After GraphMERT makes a prediction in the semantic space, we use the top 20 predicted tokens to form complete triples with a helper LLM. '##' is a separator for subword tokens. Sequence 1: . . . ##2 The Authors. The Journal of Pathology published by John Wiley &amp; Sons Ltd on behalf of The Pathological Society of Great Britain and Ireland. Non-alcoholic fatty liver disease (NAFLD) is one of the main causes of chronic liver disease worldwide. Flavonoids, a group of natural compounds, have garnered a great deal of attention in the management of NAFLD because of their profitable effects on glucose and lipid metabolism, inflammation, and oxidative stress which are the pivotal pathophysiological pathways in NAFLD. Naringenin is a citrus-derived flavonoid with a broad spectrum of potential biological effects including anti-inflammatory and antioxidant properties, which may. . . | Head, Relation | Top-20 GraphMERT-predicted tokens | Top-20 GraphMERT-predicted tokens | |------------------------------------------------------|-----------------------------------------------------------------------", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "GraphRAG Local Search", "Relation": "was modified to rely on", "Tail": "entities and relations in the querying stage"}, {"Head": "Entities within the KG", "Relation": "act as", "Tail": "entry points for retrieval of connected entities and relationships"}, {"Head": "Retrieved data sources", "Relation": "are ranked and filtered into", "Tail": "a single predefined context window"}, {"Head": "FActScore", "Relation": "evaluates", "Tail": "atomic facts against a trusted text source"}, {"Head": "KG triples", "Relation": "are treated as", "Tail": "atomic facts in the FActScore framework"}, {"Head": "FActScore*", "Relation": "adds", "Tail": "validity verification of triple logical alignment to FActScore"}, {"Head": "ValidityScore", "Relation": "measures", "Tail": "ontological alignment of triples via an LLM judge"}, {"Head": "UMLS semantic rules", "Relation": "classify", "Tail": "the triple 〈beta-receptor, part_of, plasma membrane〉 as valid"}, {"Head": "UMLS semantic rules", "Relation": "classify", "Tail": "the triple 〈beta-receptor, part_of, adrenergic signaling〉 as invalid"}, {"Head": "Seed KG", "Relation": "was derived from", "Tail": "UMLS Metathesaurus (SNOMED CT, US, GO)"}, {"Head": "Seed KG extraction", "Relation": "used a similarity threshold", "Tail": "alpha = 0.55 with Gemini text-embedding-004"}, {"Head": "GraphMERT", "Relation": "was trained to extract", "Tail": "a high-quality diabetes KG"}, {"Head": "Training dataset", "Relation": "was sourced from", "Tail": "peer-reviewed MEDLINE abstracts and the seed KG"}, {"Head": "Qwen3-32B", "Relation": "served as", "Tail": "helper LLM for entity discovery, relation matching, and tail generation"}, {"Head": "Triple extraction pipeline", "Relation": "filters candidate triples using", "Tail": "cosine similarity with Gemini embeddings and threshold beta = 0.67"}, {"Head": "GraphMERT architecture", "Relation": "uses", "Tail": "BioMedBERT tokenizer to reduce medical subword tokenization"}], "entity_relation_output": "[{\"Head\": \"GraphRAG Local Search\", \"Relation\": \"was modified to rely on\", \"Tail\": \"entities and relations in the querying stage\"}, {\"Head\": \"Entities within the KG\", \"Relation\": \"act as\", \"Tail\": \"entry points for retrieval of connected entities and relationships\"}, {\"Head\": \"Retrieved data sources\", \"Relation\": \"are ranked and filtered into\", \"Tail\": \"a single predefined context window\"}, {\"Head\": \"FActScore\", \"Relation\": \"evaluates\", \"Tail\": \"atomic facts against a trusted text source\"}, {\"Head\": \"KG triples\", \"Relation\": \"are treated as\", \"Tail\": \"atomic facts in the FActScore framework\"}, {\"Head\": \"FActScore*\", \"Relation\": \"adds\", \"Tail\": \"validity verification of triple logical alignment to FActScore\"}, {\"Head\": \"ValidityScore\", \"Relation\": \"measures\", \"Tail\": \"ontological alignment of triples via an LLM judge\"}, {\"Head\": \"UMLS semantic rules\", \"Relation\": \"classify\", \"Tail\": \"the triple 〈beta-receptor, part_of, plasma membrane〉 as valid\"}, {\"Head\": \"UMLS semantic rules\", \"Relation\": \"classify\", \"Tail\": \"the triple 〈beta-receptor, part_of, adrenergic signaling〉 as invalid\"}, {\"Head\": \"Seed KG\", \"Relation\": \"was derived from\", \"Tail\": \"UMLS Metathesaurus (SNOMED CT, US, GO)\"}, {\"Head\": \"Seed KG extraction\", \"Relation\": \"used a similarity threshold\", \"Tail\": \"alpha = 0.55 with Gemini text-embedding-004\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"was trained to extract\", \"Tail\": \"a high-quality diabetes KG\"}, {\"Head\": \"Training dataset\", \"Relation\": \"was sourced from\", \"Tail\": \"peer-reviewed MEDLINE abstracts and the seed KG\"}, {\"Head\": \"Qwen3-32B\", \"Relation\": \"served as\", \"Tail\": \"helper LLM for entity discovery, relation matching, and tail generation\"}, {\"Head\": \"Triple extraction pipeline\", \"Relation\": \"filters candidate triples using\", \"Tail\": \"cosine similarity with Gemini embeddings and threshold beta = 0.67\"}, {\"Head\": \"GraphMERT architecture\", \"Relation\": \"uses\", \"Tail\": \"BioMedBERT tokenizer to reduce medical subword tokenization\"}]", "event_entity_dict": [{"Event": "We use the Local Search method from GraphRAG and modify it to rely exclusively on the entities and relations in the querying stage.", "Entity": ["we", "Local Search method", "GraphRAG", "entities", "relations", "querying stage"]}, {"Event": "This process begins by identifying a set of entities within the KG that are semantically related to the user query.", "Entity": ["process", "entities", "KG", "user query"]}, {"Event": "These entities act as entry points for the retrieval of connected entities and relationships.", "Entity": ["entities", "entry points", "connected entities", "relationships", "retrieval"]}, {"Event": "The retrieved data sources are then ranked and filtered to fit within a single predefined context window.", "Entity": ["retrieved data sources", "ranking", "filtering", "predefined context window"]}, {"Event": "The context window is used to generate a response to the user query.", "Entity": ["context window", "response", "user query"]}, {"Event": "FActScore provides a fine-grained method for evaluating factual precision in long-form LLM outputs and transfers naturally to KG verification.", "Entity": ["FActScore", "method", "factual precision", "long-form LLM outputs", "KG verification"]}, {"Event": "FActScore evaluates atomic facts against a trusted text source that does not have any knowledge conflicts or overlaps.", "Entity": ["FActScore", "atomic facts", "trusted text source", "knowledge conflicts", "knowledge overlaps"]}, {"Event": "KG triples can be treated as atomic facts and paired with reliable text sources such as GraphMERT triples with sequences and LLM triples with short chunks.", "Entity": ["KG triples", "atomic facts", "reliable text sources", "GraphMERT triples", "sequences", "LLM triples", "short chunks"]}, {"Event": "We follow the Retrieve → LM variant of automatic evaluation and strengthen triple evaluation with validity by requiring verification of triple logical alignment in addition to context support.", "Entity": ["we", "Retrieve → LM variant", "automatic evaluation", "triple evaluation", "validity", "verification", "triple logical alignment", "context support"]}, {"Event": "Malformed triples should not be deemed reliable facts because they can inflate the score.", "Entity": ["malformed triples", "reliable facts", "score"]}, {"Event": "We denote the modified prompt-based evaluation as FActScore*.", "Entity": ["we", "modified prompt-based evaluation", "FActScore*"]}, {"Event": "ValidityScore isolates ontological alignment of triples as an independent mode of evaluation using a strong LLM judge to semantically validate triples.", "Entity": ["ValidityScore", "ontological alignment", "triples", "independent evaluation", "strong LLM judge", "semantic validation"]}, {"Event": "We extract a high-quality diabetes KG from a GraphMERT-compatible diabetes training dataset obtained from expert-verified sources.", "Entity": ["we", "high-quality diabetes KG", "GraphMERT-compatible dataset", "diabetes training dataset", "expert-verified sources"]}, {"Event": "We build the GraphMERT-compatible diabetes training dataset from peer-reviewed medical abstracts from MEDLINE journals accessed via PubMed Central and a seed KG derived from the UMLS Metathesaurus.", "Entity": ["we", "GraphMERT-compatible dataset", "peer-reviewed medical abstracts", "MEDLINE journals", "PubMed Central", "seed KG", "UMLS Metathesaurus"]}, {"Event": "From UMLS, we select SNOMED CT, US and GO vocabularies and retrieve triples relevant to our dataset sequences based on semantic similarity matching with Gemini text-embedding-004.", "Entity": ["we", "UMLS", "SNOMED CT", "US", "GO", "vocabularies", "triples", "dataset sequences", "semantic similarity matching", "Gemini text-embedding-004"]}, {"Event": "For matched triples we use an injection algorithm with a similarity threshold α of 0.55 validated experimentally via grid search using GraphRAG evaluation.", "Entity": ["matched triples", "injection algorithm", "similarity threshold α = 0.55", "grid search", "GraphRAG evaluation"]}, {"Event": "We employ Qwen3-32B-FP8 as a helper LLM with thinking mode turned on for entity discovery and relation matching.", "Entity": ["we", "Qwen3-32B-FP8", "helper LLM", "thinking mode", "entity discovery", "relation matching"]}, {"Event": "For head discovery we prompt Qwen3-32B with each abstract sequence using few-shot examples to search for medical entities relevant to diabetes and its comorbidities.", "Entity": ["head discovery", "Qwen3-32B", "abstract sequence", "few-shot examples", "medical entities", "diabetes", "comorbidities"]}, {"Event": "The outputs are validated against sequences of origin to eliminate hallucinated or misspelled entities.", "Entity": ["outputs", "sequences of origin", "validation", "hallucinated entities", "misspelled entities"]}, {"Event": "For relation discovery Qwen3-32B is few-shot prompted with a relation list from the training seed KG to match entities with relations that make sense in the context of the current sequence.", "Entity": ["relation discovery", "Qwen3-32B", "few-shot prompts", "relation list", "training seed KG", "entities", "relations", "current sequence", "context"]}, {"Event": "All Qwen3-32B runs are performed on the Princeton cluster on one H100 GPU using vLLM with vendor-recommended sampling parameters.", "Entity": ["Qwen3-32B runs", "Princeton cluster", "H100 GPU", "vLLM", "vendor-recommended sampling parameters"]}, {"Event": "Chain graphs for training are initialized with 128 root nodes each connected to seven leaves leading to a 1024-token sequence.", "Entity": ["chain graphs", "training", "128 root nodes", "seven leaves", "1024-token sequence"]}, {"Event": "We train GraphMERT with 12 hidden layers, eight attention heads, a hidden size of 512, intermediate size 2048, totaling 79.7M trainable parameters.", "Entity": ["we", "GraphMERT", "12 hidden layers", "eight attention heads", "hidden size 512", "intermediate size 2048", "79.7M parameters"]}, {"Event": "We train the model for 25 epochs on four H100 GPUs with BF16 precision totaling 90 GPU hours using an instantaneous batch size of 32 per GPU and effective batch size of 128 via gradient accumulation.", "Entity": ["we", "model", "25 epochs", "four H100 GPUs", "BF16 precision", "90 GPU hours", "instantaneous batch size 32", "effective batch size 128", "gradient accumulation"]}, {"Event": "In the triple extraction pipeline we begin with a leaf-masked prediction over the training dataset given head entities and their relations producing a vocabulary distribution for each masked leaf.", "Entity": ["triple extraction pipeline", "leaf-masked prediction", "training dataset", "head entities", "relations", "vocabulary distribution", "masked leaf"]}, {"Event": "From the top 20 tokens per leaf we prompt the helper LLM Qwen3-32B to combine tokens into coherent multi-token tails conditioned on the head relation and originating sequence.", "Entity": ["top 20 tokens", "leaf", "helper LLM", "Qwen3-32B", "tokens", "multi-token tails", "head", "relation", "originating sequence"]}, {"Event": "We discard output tails that contain out-of-scope tokens and skip triples when no valid tail can be formed.", "Entity": ["output tails", "out-of-scope tokens", "discard", "triples", "skip", "no valid tail"]}], "event_entity_output": "[{\"Event\": \"We use the Local Search method from GraphRAG and modify it to rely exclusively on the entities and relations in the querying stage.\", \"Entity\": [\"we\", \"Local Search method\", \"GraphRAG\", \"entities\", \"relations\", \"querying stage\"]}, {\"Event\": \"This process begins by identifying a set of entities within the KG that are semantically related to the user query.\", \"Entity\": [\"process\", \"entities\", \"KG\", \"user query\"]}, {\"Event\": \"These entities act as entry points for the retrieval of connected entities and relationships.\", \"Entity\": [\"entities\", \"entry points\", \"connected entities\", \"relationships\", \"retrieval\"]}, {\"Event\": \"The retrieved data sources are then ranked and filtered to fit within a single predefined context window.\", \"Entity\": [\"retrieved data sources\", \"ranking\", \"filtering\", \"predefined context window\"]}, {\"Event\": \"The context window is used to generate a response to the user query.\", \"Entity\": [\"context window\", \"response\", \"user query\"]}, {\"Event\": \"FActScore provides a fine-grained method for evaluating factual precision in long-form LLM outputs and transfers naturally to KG verification.\", \"Entity\": [\"FActScore\", \"method\", \"factual precision\", \"long-form LLM outputs\", \"KG verification\"]}, {\"Event\": \"FActScore evaluates atomic facts against a trusted text source that does not have any knowledge conflicts or overlaps.\", \"Entity\": [\"FActScore\", \"atomic facts\", \"trusted text source\", \"knowledge conflicts\", \"knowledge overlaps\"]}, {\"Event\": \"KG triples can be treated as atomic facts and paired with reliable text sources such as GraphMERT triples with sequences and LLM triples with short chunks.\", \"Entity\": [\"KG triples\", \"atomic facts\", \"reliable text sources\", \"GraphMERT triples\", \"sequences\", \"LLM triples\", \"short chunks\"]}, {\"Event\": \"We follow the Retrieve → LM variant of automatic evaluation and strengthen triple evaluation with validity by requiring verification of triple logical alignment in addition to context support.\", \"Entity\": [\"we\", \"Retrieve → LM variant\", \"automatic evaluation\", \"triple evaluation\", \"validity\", \"verification\", \"triple logical alignment\", \"context support\"]}, {\"Event\": \"Malformed triples should not be deemed reliable facts because they can inflate the score.\", \"Entity\": [\"malformed triples\", \"reliable facts\", \"score\"]}, {\"Event\": \"We denote the modified prompt-based evaluation as FActScore*.\", \"Entity\": [\"we\", \"modified prompt-based evaluation\", \"FActScore*\"]}, {\"Event\": \"ValidityScore isolates ontological alignment of triples as an independent mode of evaluation using a strong LLM judge to semantically validate triples.\", \"Entity\": [\"ValidityScore\", \"ontological alignment\", \"triples\", \"independent evaluation\", \"strong LLM judge\", \"semantic validation\"]}, {\"Event\": \"We extract a high-quality diabetes KG from a GraphMERT-compatible diabetes training dataset obtained from expert-verified sources.\", \"Entity\": [\"we\", \"high-quality diabetes KG\", \"GraphMERT-compatible dataset\", \"diabetes training dataset\", \"expert-verified sources\"]}, {\"Event\": \"We build the GraphMERT-compatible diabetes training dataset from peer-reviewed medical abstracts from MEDLINE journals accessed via PubMed Central and a seed KG derived from the UMLS Metathesaurus.\", \"Entity\": [\"we\", \"GraphMERT-compatible dataset\", \"peer-reviewed medical abstracts\", \"MEDLINE journals\", \"PubMed Central\", \"seed KG\", \"UMLS Metathesaurus\"]}, {\"Event\": \"From UMLS, we select SNOMED CT, US and GO vocabularies and retrieve triples relevant to our dataset sequences based on semantic similarity matching with Gemini text-embedding-004.\", \"Entity\": [\"we\", \"UMLS\", \"SNOMED CT\", \"US\", \"GO\", \"vocabularies\", \"triples\", \"dataset sequences\", \"semantic similarity matching\", \"Gemini text-embedding-004\"]}, {\"Event\": \"For matched triples we use an injection algorithm with a similarity threshold α of 0.55 validated experimentally via grid search using GraphRAG evaluation.\", \"Entity\": [\"matched triples\", \"injection algorithm\", \"similarity threshold α = 0.55\", \"grid search\", \"GraphRAG evaluation\"]}, {\"Event\": \"We employ Qwen3-32B-FP8 as a helper LLM with thinking mode turned on for entity discovery and relation matching.\", \"Entity\": [\"we\", \"Qwen3-32B-FP8\", \"helper LLM\", \"thinking mode\", \"entity discovery\", \"relation matching\"]}, {\"Event\": \"For head discovery we prompt Qwen3-32B with each abstract sequence using few-shot examples to search for medical entities relevant to diabetes and its comorbidities.\", \"Entity\": [\"head discovery\", \"Qwen3-32B\", \"abstract sequence\", \"few-shot examples\", \"medical entities\", \"diabetes\", \"comorbidities\"]}, {\"Event\": \"The outputs are validated against sequences of origin to eliminate hallucinated or misspelled entities.\", \"Entity\": [\"outputs\", \"sequences of origin\", \"validation\", \"hallucinated entities\", \"misspelled entities\"]}, {\"Event\": \"For relation discovery Qwen3-32B is few-shot prompted with a relation list from the training seed KG to match entities with relations that make sense in the context of the current sequence.\", \"Entity\": [\"relation discovery\", \"Qwen3-32B\", \"few-shot prompts\", \"relation list\", \"training seed KG\", \"entities\", \"relations\", \"current sequence\", \"context\"]}, {\"Event\": \"All Qwen3-32B runs are performed on the Princeton cluster on one H100 GPU using vLLM with vendor-recommended sampling parameters.\", \"Entity\": [\"Qwen3-32B runs\", \"Princeton cluster\", \"H100 GPU\", \"vLLM\", \"vendor-recommended sampling parameters\"]}, {\"Event\": \"Chain graphs for training are initialized with 128 root nodes each connected to seven leaves leading to a 1024-token sequence.\", \"Entity\": [\"chain graphs\", \"training\", \"128 root nodes\", \"seven leaves\", \"1024-token sequence\"]}, {\"Event\": \"We train GraphMERT with 12 hidden layers, eight attention heads, a hidden size of 512, intermediate size 2048, totaling 79.7M trainable parameters.\", \"Entity\": [\"we\", \"GraphMERT\", \"12 hidden layers\", \"eight attention heads\", \"hidden size 512\", \"intermediate size 2048\", \"79.7M parameters\"]}, {\"Event\": \"We train the model for 25 epochs on four H100 GPUs with BF16 precision totaling 90 GPU hours using an instantaneous batch size of 32 per GPU and effective batch size of 128 via gradient accumulation.\", \"Entity\": [\"we\", \"model\", \"25 epochs\", \"four H100 GPUs\", \"BF16 precision\", \"90 GPU hours\", \"instantaneous batch size 32\", \"effective batch size 128\", \"gradient accumulation\"]}, {\"Event\": \"In the triple extraction pipeline we begin with a leaf-masked prediction over the training dataset given head entities and their relations producing a vocabulary distribution for each masked leaf.\", \"Entity\": [\"triple extraction pipeline\", \"leaf-masked prediction\", \"training dataset\", \"head entities\", \"relations\", \"vocabulary distribution\", \"masked leaf\"]}, {\"Event\": \"From the top 20 tokens per leaf we prompt the helper LLM Qwen3-32B to combine tokens into coherent multi-token tails conditioned on the head relation and originating sequence.\", \"Entity\": [\"top 20 tokens\", \"leaf\", \"helper LLM\", \"Qwen3-32B\", \"tokens\", \"multi-token tails\", \"head\", \"relation\", \"originating sequence\"]}, {\"Event\": \"We discard output tails that contain out-of-scope tokens and skip triples when no valid tail can be formed.\", \"Entity\": [\"output tails\", \"out-of-scope tokens\", \"discard\", \"triples\", \"skip\", \"no valid tail\"]}]", "event_relation_dict": [{"Head": "We use the Local Search method from GraphRAG", "Relation": "after", "Tail": "we modify it to rely exclusively on the entities and relations in the querying stage"}, {"Head": "This process begins by identifying a set of entities within the KG that are semantically related to the user query", "Relation": "because", "Tail": "these entities act as entry points for the retrieval of connected entities and relationships"}, {"Head": "The retrieved data sources are ranked and filtered to fit within a single predefined context window", "Relation": "as a result", "Tail": "the context window is used to generate a response to the user query"}, {"Head": "FActScore provides a fine-grained method for evaluating factual precision in long-form LLM outputs", "Relation": "as a result", "Tail": "its principles transfer naturally to KG verification"}, {"Head": "FActScore evaluates atomic facts against a trusted text source", "Relation": "as a result", "Tail": "KG triples can be treated as atomic facts of equal importance"}, {"Head": "Each triple can be paired with a reliable text source", "Relation": "as a result", "Tail": "the short context length minimizes conflicts and overlaps"}, {"Head": "We follow the Retrieve → LM variant of automatic evaluation", "Relation": "after", "Tail": "we strengthen triple evaluation with validity in the prompt"}, {"Head": "We strengthen triple evaluation with validity in the prompt", "Relation": "because", "Tail": "a fact may appear in the text yet the triple may still be malformed"}, {"Head": "Malformed triples should not be deemed reliable facts", "Relation": "as a result", "Tail": "they would inflate the score"}, {"Head": "ValidityScore isolates ontological alignment of triples", "Relation": "as a result", "Tail": "we use a strong LLM judge to semantically validate a triple with a prompt"}, {"Head": "To demonstrate the effectiveness of our framework", "Relation": "as a result", "Tail": "we extract a high-quality diabetes KG from a GraphMERT-compatible diabetes training dataset"}, {"Head": "We build a GraphMERT-compatible diabetes training dataset from two main sources", "Relation": "as a result", "Tail": "the resulting dataset contains 350k abstracts for training and 39k for evaluation"}, {"Head": "From UMLS we select SNOMED CT, US and GO vocabularies", "Relation": "because", "Tail": "together they cover a broad range of biomedical concepts across clinical documentation, molecular biology, and data exchange"}, {"Head": "For matched triples we use an injection algorithm with a similarity threshold α of 0.55", "Relation": "after", "Tail": "the resulting triples that are injected comprise the seed KG"}, {"Head": "We prompt Qwen3-32B with each abstract sequence to search for medical entities", "Relation": "after", "Tail": "the outputs are validated against sequences of origin to eliminate hallucinated or misspelled entities"}, {"Head": "GraphMERT predicts a distribution for each masked leaf", "Relation": "after", "Tail": "we select the top 20 tokens per leaf and use them to prompt the helper LLM to form tails"}, {"Head": "We compute cosine similarity between the triple and its originating sequence using embeddings", "Relation": "as a result", "Tail": "all triples with a score below the similarity check threshold β = 0.67 are discarded"}, {"Head": "Chain graphs are initialized with 128 root nodes each connected to seven leaves", "Relation": "as a result", "Tail": "the sequence has a fixed length of 1024 with the first 128 tokens reserved for roots"}, {"Head": "We train GraphMERT for 25 epochs on four H100 GPUs with BF16 precision", "Relation": "as a result", "Tail": "training totals 90 GPU hours"}, {"Head": "We use the BioMedBERT tokenizer trained on medical vocabulary", "Relation": "as a result", "Tail": "the tokenizer vocabulary size is 30,522"}], "event_relation_output": "[{\"Head\": \"We use the Local Search method from GraphRAG\", \"Relation\": \"after\", \"Tail\": \"we modify it to rely exclusively on the entities and relations in the querying stage\"}, {\"Head\": \"This process begins by identifying a set of entities within the KG that are semantically related to the user query\", \"Relation\": \"because\", \"Tail\": \"these entities act as entry points for the retrieval of connected entities and relationships\"}, {\"Head\": \"The retrieved data sources are ranked and filtered to fit within a single predefined context window\", \"Relation\": \"as a result\", \"Tail\": \"the context window is used to generate a response to the user query\"}, {\"Head\": \"FActScore provides a fine-grained method for evaluating factual precision in long-form LLM outputs\", \"Relation\": \"as a result\", \"Tail\": \"its principles transfer naturally to KG verification\"}, {\"Head\": \"FActScore evaluates atomic facts against a trusted text source\", \"Relation\": \"as a result\", \"Tail\": \"KG triples can be treated as atomic facts of equal importance\"}, {\"Head\": \"Each triple can be paired with a reliable text source\", \"Relation\": \"as a result\", \"Tail\": \"the short context length minimizes conflicts and overlaps\"}, {\"Head\": \"We follow the Retrieve → LM variant of automatic evaluation\", \"Relation\": \"after\", \"Tail\": \"we strengthen triple evaluation with validity in the prompt\"}, {\"Head\": \"We strengthen triple evaluation with validity in the prompt\", \"Relation\": \"because\", \"Tail\": \"a fact may appear in the text yet the triple may still be malformed\"}, {\"Head\": \"Malformed triples should not be deemed reliable facts\", \"Relation\": \"as a result\", \"Tail\": \"they would inflate the score\"}, {\"Head\": \"ValidityScore isolates ontological alignment of triples\", \"Relation\": \"as a result\", \"Tail\": \"we use a strong LLM judge to semantically validate a triple with a prompt\"}, {\"Head\": \"To demonstrate the effectiveness of our framework\", \"Relation\": \"as a result\", \"Tail\": \"we extract a high-quality diabetes KG from a GraphMERT-compatible diabetes training dataset\"}, {\"Head\": \"We build a GraphMERT-compatible diabetes training dataset from two main sources\", \"Relation\": \"as a result\", \"Tail\": \"the resulting dataset contains 350k abstracts for training and 39k for evaluation\"}, {\"Head\": \"From UMLS we select SNOMED CT, US and GO vocabularies\", \"Relation\": \"because\", \"Tail\": \"together they cover a broad range of biomedical concepts across clinical documentation, molecular biology, and data exchange\"}, {\"Head\": \"For matched triples we use an injection algorithm with a similarity threshold α of 0.55\", \"Relation\": \"after\", \"Tail\": \"the resulting triples that are injected comprise the seed KG\"}, {\"Head\": \"We prompt Qwen3-32B with each abstract sequence to search for medical entities\", \"Relation\": \"after\", \"Tail\": \"the outputs are validated against sequences of origin to eliminate hallucinated or misspelled entities\"}, {\"Head\": \"GraphMERT predicts a distribution for each masked leaf\", \"Relation\": \"after\", \"Tail\": \"we select the top 20 tokens per leaf and use them to prompt the helper LLM to form tails\"}, {\"Head\": \"We compute cosine similarity between the triple and its originating sequence using embeddings\", \"Relation\": \"as a result\", \"Tail\": \"all triples with a score below the similarity check threshold β = 0.67 are discarded\"}, {\"Head\": \"Chain graphs are initialized with 128 root nodes each connected to seven leaves\", \"Relation\": \"as a result\", \"Tail\": \"the sequence has a fixed length of 1024 with the first 128 tokens reserved for roots\"}, {\"Head\": \"We train GraphMERT for 25 epochs on four H100 GPUs with BF16 precision\", \"Relation\": \"as a result\", \"Tail\": \"training totals 90 GPU hours\"}, {\"Head\": \"We use the BioMedBERT tokenizer trained on medical vocabulary\", \"Relation\": \"as a result\", \"Tail\": \"the tokenizer vocabulary size is 30,522\"}]"}
{"id": "1", "original_text": "------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | naringenin, isa | flavonoid ##in flav nar ##idin ##arin ##flav compound ##ce hydrolase plant ##ingen ##ono protein polysaccharide polyphenol family ##anol - ##onin | flavonoid ##in flav nar ##idin ##arin ##flav compound ##ce hydrolase plant ##ingen ##ono protein polysaccharide polyphenol family ##anol - ##onin | | naringenin, plays_role | therapeutic neuroprotective ##ingen antidepressant role medicinal ##arin flavonoid action baical inhibitory antibacterial bioactive medicine antimicrobial ##idin quercetin ##flav potential flavon | therapeutic neuroprotective ##ingen antidepressant role medicinal ##arin flavonoid action baical inhibitory antibacterial bioactive medicine antimicrobial ##idin quercetin ##flav potential flavon | | naringenin, has_disposition | nar flavonoid ##in hydrolase ##arin inhibitor - ##anol compound ##idin amy ##flav ##ingen derivative amide receptor acid family alkaloid product | nar flavonoid ##in hydrolase ##arin inhibitor - ##anol compound ##idin amy ##flav ##ingen derivative amide receptor acid family alkaloid product | | non-alcoholic fatty liver dis- ease, cause_of | liver disease alcoholic fatty ##osclerosis nafld steatosis disorder ##atitis ##ohep hypercholesterolemia hepatic - with syndrome mellitus myopathy fibrosis diseases hyperlipidemia | liver disease alcoholic fatty ##osclerosis nafld steatosis disorder ##atitis ##ohep hypercholesterolemia hepatic - with syndrome mellitus myopathy fibrosis diseases hyperlipidemia | | non-alcoholic fatty liver dis- ease, associated_with | hyperlipidemia disorder alcoholic obesity - dyslipidemia myopathy liver hereditary hypercholesterolemia syndrome ##ament ##tr associated ##lip fatty disease ##oid mellitus related | hyperlipidemia disorder alcoholic obesity - dyslipidemia myopathy liver hereditary hypercholesterolemia syndrome ##ament ##tr associated ##lip fatty disease ##oid mellitus related | | Head | Relation | Tail (formed from the GraphMERT-predicted tokens) | | naringenin | isa | flavonoid | | naringenin | plays_role | therapeutic role | | naringenin | has_disposition | flavonoid | | non-alcoholic fatty liver dis- ease | cause_of | fibrosis | | non-alcoholic fatty liver dis- ease | associated_with | obesity | ## 5.2 LLM-extracted KG Following the default GraphRAG indexing parameters, our diabetes corpus is split into 2,000-token chunks and processed by Qwen3-32B to extract entities and relationships. We enable the model's thinking mode and set temperature = 0 . 6, top \\_ p = 0 . 95, top \\_ k = 20, max \\_ tokens = 8192. The detailed prompt for extraction is shown in Appendix E1 and an example is shown in Appendix E2. After parsing and cleaning, the final LLM-generated KG contains 272,346 triples. ## 5.3 Evaluation with GraphRAG Next, we provide details of GraphRAG evaluations. ## 5.3.1 GraphRAG Settings Our experimental setup uses Qwen3-14B as the backbone LLM in GraphRAG, with inference accelerated using the vLLM library. For all evaluations, we enable the model's thinking mode and set temperature = 0 . 6, top \\_ p = 0 . 95, top \\_ k = 20, and max \\_ tokens = 8192. To ensure the reliability of our findings, each experiment is conducted three times with different random seeds (1, 2, and 3). We report the average accuracy across these runs in our final results. The GraphRAG query process is configured with nomic-embed-text-v1 as the embedding model. To construct the context for each query, the system retrieves the top 30 entities and the top 10 relationships per entity, with the maximum context length capped at 12,000 tokens. Furthermore, we tailor the system prompts and simplify the output table structure to better suit our tasks. The complete prompt is given in Appendix E3. The modified table schema is also detailed in Appendix E4. ## 5.3.2 Benchmark Evaluation We further verify the quality of our extracted KGs on the diabetes subsets of medical benchmarks: ICDBench (Dedhia et al., 2025), MedMCQA, MedQA, and MMLU (medical). ICD-Bench is a targeted questionanswering benchmark aligned with the International Classification of Diseases (ICD) taxonomy (World Health Organization, 1992), designed to evaluate domain-specific medical reasoning in language models across 15 medical sub-specialties. We primarily evaluate the extracted KGs on ICD-Bench, as it is the only benchmark that has a dedicated endocrinology subset; for this reason, we defer the other results to Appendix D. For evaluation, we employ GraphRAG to answer benchmark questions. To address the domain mismatch between our diabetes-specialized model, GraphMERT , and general medical benchmarks, we create domain-specific evaluation subsets. First, we synthesize our training corpus into an approximately 2000-word summary using Gemini 2.5 Pro. Subsequently, we use this summary to prompt a Qwen3-32B model to filter the question-answer pairs in each benchmark, retaining only questions relevant to the summary. All GraphRAG evaluations are then conducted on these filtered subsets to ensure a fair assessment. ## 5.3.3 Traceability and User Verification Allowing users to judge correctness is a simple but powerful principle. OpenAI's WebGPT (Nakano et al., 2022) addresses this by browsing the web and citing sources, a strategy also adopted by Perplexity AI. In these systems, the user decides (1) whether the source is credible and (2) whether the output is factual. Our framework builds on this idea: Each triple is directly traceable to its originating sequence. This enables automatic cross-checking, rather than searching external sources. The system retrieves the sequence from which the triple is derived. Since this sequence originates from a verified paper abstract, users can further validate the fact by consulting the source publication if needed. ## 6 Experimental Results Next, we provide evaluation results for GraphMERT and LLM KGs on the benchmarks. ## 6.1 Description of the Extracted KG Table 4 summarizes the statistics of the extracted KG. It inherits the 28 relations from the seed KG (mentioned in Table 2) but contains approximately four times as many triples; the comparison chart (Fig. C1) is presented in Appendix C. The extracted triples include vocabulary that extends beyond the seed KG. As expected, novel heads originate from the training dataset, which has a richer vocabulary than the seed KG. GraphMERT also generates novel tails , predicting tokens from the dataset vocabulary that are absent in the seed KG (see an example given in Table C1 in Appendix C). ## 6.2 Triple-level Evaluation Next, we present results for triple-level evaluations. ## 6.2.1 FActScore* Results We use two prompts to evaluate a triple based on: Table 4: GraphMERT -extracted KG. Number of triples over extraction stages; similarity threshold β = 0 . 67. We show the number of triples after the helper LLM combines the tail tokens, next after discarding tails hallucinated by the LLM, then after similarity filtering, and finally after dropping triple repetitions. | α value | Formed tails (non-unique) | Formed tails excluding LLM hallucinated (non-unique) | After β -filtering (non-unique) | Final: repetitions dropped (unique) | |------------|-----------------------------|--------------------------------------------------------|-----------------------------------|---------------------------------------| | α = 0 . 55 | 1,760,088 | 1,536,581 | 139,565 | 109,293 | Table 5: FActScore* KG evaluation (in percentage points) | KG type | #triples | Context only | Context and General truth | |----------------|------------|----------------|-----------------------------| | LLM (baseline) | 515,460 | 40.2 | 48.1 | | GraphMERT | 139,565 | 69.8 | 72.2 | 1. context only, 2. context and model's internal knowledge of general truth. The first prompt includes the text in black only, the second prompt includes the text in black and teal: Prompt. You will evaluate the quality of triples for a medical knowledge graph on diabetes and its comorbidities. For each triple, you are given: - A sequence providing context - A head entity, a relation, and a tail entity Your task: Accept the triple ('[yes]') or reject it ('[no]') based on: - Logical alignment : the tail must logically align with the head and relation; relation must match entity types. - Context support : the sequence should support the triple. Allow statements that are factual and general truth, even if not perfectly aligned with context, but still avoid contradictions. If the triple has no reliable support, reject the triple. - Knowledge value : the triple must add new, medically meaningful information to the graph. Output only '[yes]' or '[no]' as your final judgment. Wrap your reasoning in &lt;think&gt;...&lt;/think&gt; . Table 5 reports the FActScore* of GraphMERT KG versus the LLM KG using Qwen3-32B as the validator. We conduct two variants of the evaluation, differing only in an extra accept condition in the prompt: 1) based on context only , closely following the original FActScore, and 2) based on context + model's internal knowledge , which additionally accepts triples that express general truths even if not explicitly stated in the context. Variant (2) acknowledges cross-dataset concept linking, whereas (1) restricts evidence to the local context. Because the same triple can originate from multiple sequences, some triples are checked more than once against different texts. As a result, the reported number of triples exceeds the count in the final deduplicated KGs. We also score the seed KG with respect to the sequences into which its triples are injected. In this setting, FActScore primarily reflects the injection relevance. Why are LLM KG FActScores so low? Surprisingly, the LLM KG scores poorly even when validated by the same model (Qwen3-32B), which flags many of its own errors. This underscores weak prompt steerability: Knowledge may exist in parameters, yet prompt-based generation fails to elicit correct, ontology-respecting triples. Our analysis points to three recurring failure modes: 1. Relation misinterpretation: The model maps relations by lexical similarity rather than ontological meaning, drawing on its internal knowledge. Table 6: Validity check with Qwen3-32B (in percentage points) | KG type | # triples | yes | (ValidityScore) | maybe | no | |----------------|-------------|-------|-------------------|---------|------| | LLM (baseline) | 515,460 | | 43 | 24.1 | 31.4 | | UMLS Seed KG | 28,533 | | 53.4 | 10 | 34.7 | | GraphMERT | 139,565 | | 68.8 | 18.3 | 10.8 | 2. Systematic malformed repetition: The same ill-formed triples reappear across different text chunks. 3. Overlinking a head-tail pair: Multiple, largely invalid relations are assigned to the same entity pair. ## Illustrative errors - Misinterpreted relation: 〈 diabetes , has\\_finding\\_site , urban area 〉 . Here, 'site' is treated as a location (anatomical structure is expected). Likewise, 〈 telehealth intervention , has\\_part , diabetes 〉 misuses has\\_part to describe care; a correct variant: 〈 diabetes , focus\\_of , telehealth intervention 〉 . - Overlinking (redundant relations): For 〈 obesity , diabetes 〉 , the LLM proposed is\\_modification\\_of , part\\_of , plays\\_role , cause\\_of , causative\\_agent\\_of , has\\_component , has\\_pathological\\_process . However, only associated\\_with is valid. - Spurious co-occurrence link: 〈 diabetes , has\\_method , mammography 〉 . The entities merely cooccurred in an abstract; mammography is not used for diabetes, yet the LLM infers a spurious relation. 'Spurious co-occurrence link' illustrates a disadvantage of local KG extraction methods vs. global methods that capture how concepts are distributed and connected across the full dataset. As a result, spurious links between concepts that rarely co-occur remain weak and are less likely to be predicted. Implication: Broad, pre-trained LLMs tend to project general associations into domain-specific relations, yielding invalid triples. High-stakes domains benefit from compact, domain-tailored models and pipelines that enforce ontology and provenance. ## 6.2.2 ValidityScore Validity check on the whole KG with Qwen3-32B: To get a sense of the triple semantic quality of GraphMERT - and LLM-extracted KGs, we conduct a validity check: Test the validity of each triple in the graph with Qwen3-32B as the judge LLM. Table 6 summarizes the validity checks across KGs. GraphMERT attains a markedly higher 'yes' rate, i.e., ValidityScore, than the LLM baseline (68.8% vs. 43.0%) with far fewer 'no' judgments (10.8% vs. 31.4%), indicating substantially cleaner relation usage and predicate hygiene. Overall, the LLM KG is less conservative (more details ahead) and less valid. The typical malformed triples are shown in Tables 7 ( GraphMERT ) and 8 (LLM). Validity check on a KG subset with GPT-5: We also perform a validity check on small KG subsets with GPT-5 (Thinking). GPT-5 is particularly strict in evaluating consistency of triples and whether the relation is used in the correct direction, aligning with our goal of obtaining dependable judgments. We retrieve 100 random triples across seven diabetes-related keywords: T2DM, hyperglycemia, dyslipidemia, adiponectin, metformin, SGLT2, and CVD . Each triple is assigned a yes/maybe/no verdict (Fig. 12). The keywords are drawn from the 200", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "naringenin", "Relation": "is a", "Tail": "flavonoid"}, {"Head": "naringenin", "Relation": "plays", "Tail": "therapeutic role"}, {"Head": "non-alcoholic fatty liver disease", "Relation": "causes", "Tail": "fibrosis"}, {"Head": "non-alcoholic fatty liver disease", "Relation": "is associated with", "Tail": "obesity"}, {"Head": "GraphRAG", "Relation": "uses", "Tail": "Qwen3-14B"}, {"Head": "GraphRAG", "Relation": "accelerates inference with", "Tail": "vLLM"}, {"Head": "GraphRAG query process", "Relation": "uses embedding model", "Tail": "nomic-embed-text-v1"}, {"Head": "GraphMERT extracted KG", "Relation": "contains", "Tail": "139,565 triples"}, {"Head": "LLM baseline KG", "Relation": "contains", "Tail": "515,460 triples"}, {"Head": "GraphMERT KG", "Relation": "achieves FActScore (context only)", "Tail": "69.8%"}, {"Head": "LLM baseline KG", "Relation": "achieves FActScore (context only)", "Tail": "40.2%"}, {"Head": "GraphMERT", "Relation": "achieves ValidityScore", "Tail": "68.8% yes"}, {"Head": "LLM baseline", "Relation": "achieves ValidityScore", "Tail": "43.0% yes"}, {"Head": "extraction pipeline", "Relation": "filters tails with similarity threshold", "Tail": "β = 0.67"}, {"Head": "formed tails (non-unique)", "Relation": "reduce to final unique triples", "Tail": "109,293"}], "entity_relation_output": "[{\"Head\": \"naringenin\", \"Relation\": \"is a\", \"Tail\": \"flavonoid\"}, {\"Head\": \"naringenin\", \"Relation\": \"plays\", \"Tail\": \"therapeutic role\"}, {\"Head\": \"non-alcoholic fatty liver disease\", \"Relation\": \"causes\", \"Tail\": \"fibrosis\"}, {\"Head\": \"non-alcoholic fatty liver disease\", \"Relation\": \"is associated with\", \"Tail\": \"obesity\"}, {\"Head\": \"GraphRAG\", \"Relation\": \"uses\", \"Tail\": \"Qwen3-14B\"}, {\"Head\": \"GraphRAG\", \"Relation\": \"accelerates inference with\", \"Tail\": \"vLLM\"}, {\"Head\": \"GraphRAG query process\", \"Relation\": \"uses embedding model\", \"Tail\": \"nomic-embed-text-v1\"}, {\"Head\": \"GraphMERT extracted KG\", \"Relation\": \"contains\", \"Tail\": \"139,565 triples\"}, {\"Head\": \"LLM baseline KG\", \"Relation\": \"contains\", \"Tail\": \"515,460 triples\"}, {\"Head\": \"GraphMERT KG\", \"Relation\": \"achieves FActScore (context only)\", \"Tail\": \"69.8%\"}, {\"Head\": \"LLM baseline KG\", \"Relation\": \"achieves FActScore (context only)\", \"Tail\": \"40.2%\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"achieves ValidityScore\", \"Tail\": \"68.8% yes\"}, {\"Head\": \"LLM baseline\", \"Relation\": \"achieves ValidityScore\", \"Tail\": \"43.0% yes\"}, {\"Head\": \"extraction pipeline\", \"Relation\": \"filters tails with similarity threshold\", \"Tail\": \"β = 0.67\"}, {\"Head\": \"formed tails (non-unique)\", \"Relation\": \"reduce to final unique triples\", \"Tail\": \"109,293\"}]", "event_entity_dict": [{"Event": "naringenin is a flavonoid", "Entity": ["naringenin", "flavonoid"]}, {"Event": "naringenin plays a therapeutic role", "Entity": ["naringenin", "therapeutic role"]}, {"Event": "naringenin has disposition as a flavonoid", "Entity": ["naringenin", "flavonoid"]}, {"Event": "non-alcoholic fatty liver disease causes fibrosis", "Entity": ["non-alcoholic fatty liver disease", "fibrosis"]}, {"Event": "non-alcoholic fatty liver disease is associated with obesity", "Entity": ["non-alcoholic fatty liver disease", "obesity"]}, {"Event": "the diabetes corpus is split into 2,000-token chunks", "Entity": ["diabetes corpus", "2,000-token chunks"]}, {"Event": "Qwen3-32B is used to extract entities and relationships", "Entity": ["Qwen3-32B", "entities", "relationships"]}, {"Event": "the final LLM-generated knowledge graph contains 272,346 triples", "Entity": ["LLM-generated KG", "272,346 triples"]}, {"Event": "each experiment is conducted three times with random seeds 1, 2, and 3", "Entity": ["experiment", "random seed 1", "random seed 2", "random seed 3"]}, {"Event": "the system retrieves the top 30 entities and the top 10 relationships per entity to construct context", "Entity": ["system", "top 30 entities", "top 10 relationships per entity", "context"]}, {"Event": "GraphMERT extracted KG contains 139,565 triples after filtering", "Entity": ["GraphMERT extracted KG", "139,565 triples"]}, {"Event": "the LLM baseline KG contains 515,460 triples", "Entity": ["LLM baseline KG", "515,460 triples"]}, {"Event": "Validity checks with Qwen3-32B show GraphMERT attains a higher yes rate than the LLM baseline", "Entity": ["Qwen3-32B", "GraphMERT", "LLM baseline", "ValidityScore"]}], "event_entity_output": "[{\"Event\": \"naringenin is a flavonoid\", \"Entity\": [\"naringenin\", \"flavonoid\"]}, {\"Event\": \"naringenin plays a therapeutic role\", \"Entity\": [\"naringenin\", \"therapeutic role\"]}, {\"Event\": \"naringenin has disposition as a flavonoid\", \"Entity\": [\"naringenin\", \"flavonoid\"]}, {\"Event\": \"non-alcoholic fatty liver disease causes fibrosis\", \"Entity\": [\"non-alcoholic fatty liver disease\", \"fibrosis\"]}, {\"Event\": \"non-alcoholic fatty liver disease is associated with obesity\", \"Entity\": [\"non-alcoholic fatty liver disease\", \"obesity\"]}, {\"Event\": \"the diabetes corpus is split into 2,000-token chunks\", \"Entity\": [\"diabetes corpus\", \"2,000-token chunks\"]}, {\"Event\": \"Qwen3-32B is used to extract entities and relationships\", \"Entity\": [\"Qwen3-32B\", \"entities\", \"relationships\"]}, {\"Event\": \"the final LLM-generated knowledge graph contains 272,346 triples\", \"Entity\": [\"LLM-generated KG\", \"272,346 triples\"]}, {\"Event\": \"each experiment is conducted three times with random seeds 1, 2, and 3\", \"Entity\": [\"experiment\", \"random seed 1\", \"random seed 2\", \"random seed 3\"]}, {\"Event\": \"the system retrieves the top 30 entities and the top 10 relationships per entity to construct context\", \"Entity\": [\"system\", \"top 30 entities\", \"top 10 relationships per entity\", \"context\"]}, {\"Event\": \"GraphMERT extracted KG contains 139,565 triples after filtering\", \"Entity\": [\"GraphMERT extracted KG\", \"139,565 triples\"]}, {\"Event\": \"the LLM baseline KG contains 515,460 triples\", \"Entity\": [\"LLM baseline KG\", \"515,460 triples\"]}, {\"Event\": \"Validity checks with Qwen3-32B show GraphMERT attains a higher yes rate than the LLM baseline\", \"Entity\": [\"Qwen3-32B\", \"GraphMERT\", \"LLM baseline\", \"ValidityScore\"]}]", "event_relation_dict": [{"Head": "Naringenin is a flavonoid", "Relation": "at the same time", "Tail": "Naringenin plays a therapeutic neuroprotective and antidepressant role"}, {"Head": "Naringenin is a flavonoid", "Relation": "at the same time", "Tail": "Naringenin has a flavonoid disposition as an inhibitor"}, {"Head": "Non-alcoholic fatty liver disease occurs", "Relation": "as a result", "Tail": "Fibrosis occurs"}, {"Head": "Non-alcoholic fatty liver disease occurs", "Relation": "at the same time", "Tail": "Obesity is present"}, {"Head": "GraphRAG evaluations were conducted with specified settings", "Relation": "before", "Tail": "Experimental results for GraphMERT and LLM KGs were reported"}, {"Head": "GraphMERT extracted a knowledge graph", "Relation": "as a result", "Tail": "GraphMERT achieved a higher ValidityScore than the LLM baseline"}, {"Head": "Each triple in the system is directly traceable to its originating sequence", "Relation": "as a result", "Tail": "Automatic cross-checking and user validation of triples is possible"}], "event_relation_output": "[{\"Head\": \"Naringenin is a flavonoid\", \"Relation\": \"at the same time\", \"Tail\": \"Naringenin plays a therapeutic neuroprotective and antidepressant role\"}, {\"Head\": \"Naringenin is a flavonoid\", \"Relation\": \"at the same time\", \"Tail\": \"Naringenin has a flavonoid disposition as an inhibitor\"}, {\"Head\": \"Non-alcoholic fatty liver disease occurs\", \"Relation\": \"as a result\", \"Tail\": \"Fibrosis occurs\"}, {\"Head\": \"Non-alcoholic fatty liver disease occurs\", \"Relation\": \"at the same time\", \"Tail\": \"Obesity is present\"}, {\"Head\": \"GraphRAG evaluations were conducted with specified settings\", \"Relation\": \"before\", \"Tail\": \"Experimental results for GraphMERT and LLM KGs were reported\"}, {\"Head\": \"GraphMERT extracted a knowledge graph\", \"Relation\": \"as a result\", \"Tail\": \"GraphMERT achieved a higher ValidityScore than the LLM baseline\"}, {\"Head\": \"Each triple in the system is directly traceable to its originating sequence\", \"Relation\": \"as a result\", \"Tail\": \"Automatic cross-checking and user validation of triples is possible\"}]"}
{"id": "1", "original_text": "0-word dataset-level summary generated with Gemini 2.5 Pro, representing some of the most frequent and clinically relevant terms related to diabetes and its comorbidities. Overall, the GraphMERT KG consistently produces a higher proportion of valid ( yes ) triples and fewer incorrect ( no ) triples across all keywords, whereas the LLM KG shows more relation misuse and ontology <!-- image --> Figure 12: Validity check with GPT-5 Thinking, 100 random triples per keyword. The keywords are lined on the x -axis. Within each category, the left bars represent GraphMERT triples and right bars LLM triples. The captions below the labels show yes/maybe/no split counts for GLM and LLM. Table 7: GraphMERT -extracted KG triples: Malformed triple examples | Triples with an incomplete tail | Comment | |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------| | CKD risk prediction model, associated_with, validated gestational diabetes mellitus, associated_with, twin elastin, has_modification, carbam | adjectival tail should be twin pregnancy should be carbamylation | | Triples with overstated causality | Comment | | insulin resistance in CKD, cause_of, metabolic syndrome insulin resistance in CKD, cause_of, vascular disorder diabetes mellitus, cause_of, tuberculosis | IR is a criterion vague tail cause is mycobacterium; DM is risk | | Triples with vague tails blind patients with DM, associated_with, diabetic retinopathy atherosclerotic cardiovascular disease, associated_with, lifestyle | Comment head is a cohort vague tail | | Triples with predicate misuse atherosclerotic cardiovascular disease, has_causative_agent, apolipoprotein b type 2 diabetes mellitus, associated_with, parasitic infection glucocorticoid-induced hyperglycaemia, has_finding_site, tissue | Comment should be apolipoprotein B-containing lipoproteins weak/unspecific link wrong site (should be blood) | violations, reflected in a greater share of maybe and no verdicts. This highlights the more conservative but domain-appropriate character of the GraphMERT KG compared to the noisier LLM KG. According to verdicts (a very short reason why) , the LLM often violates ontology, confusing methods with diseases, and misuses relations, with the two errors reinforcing each other. Next, we analyze the main errors of each KG separately. GraphMERT: The main issues in GraphMERT triples are vagueness and incomplete tails, though they remain domain-appropriate. Tail incompleteness arises when the helper LLM accepts an incomplete token as a valid tail during token combination. We observe this effect across all helper LLMs we tested, including Table 8: LLM-extracted KG triples: Malformed triple examples | Triples with reversed relation | Comment | |-----------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------| | cryptogenic stroke, causative_agent_of, paradoxical embolism ischemic stroke, cause_of, ps glucocorticoids, has_part, steroidogenesis | reversed causality PS - Protein S deficiency; reversed steroidogenesis produces GCs | | Triples with predicate misuse | Comment | | ischemic stroke, cause_of, telomere length elastin, finding_site_of, vascular smooth muscle cell CKD awareness, has_component, race/ethnicity | biologically wrong cells aren't 'found' in elastin CKD = chronic kidney disease; ontologically wrong | | lockdown, associated_with, bone mineral density | mismatches ontological types | | elastin, has_pathological_process, matrix metalloproteinase | metalloproteinase is an enzyme | | Triples with ill-defined target | Comment | | chronic kidney disease (CKD), cause_of, renal | tail isn't a standard retinal disorder | | retinopathy | term | Gemini Flash 2.0 and 2.5. Tail vagueness occurs when GraphMERT does not rank the required tail tokens within its top-20 predictions; the helper LLM then stitches together a completion that is contextually acceptable but semantically weak. This also explains most of the cases of overstated causality and predicate misuse: missing key tokens required for high-quality tail completion, the LLM still attempts a plausible but semantically weak completion. A practical mitigation is to exclude low-information 128-token sequences in the prediction stage (e.g., segments dominated by measurements, dosages, or numbers). We currently do not filter these sequences, which may contaminate the extracted KG. LLM: In contrast, we observe that the LLM misinterprets UMLS biomedical relations and substitutes them with its broader internal knowledge, resulting in approximations that violate the ontology. Designing prompts to fully explain all relations is impractical. Our experiments show that even multiple examples fail to steer the model consistently: It defaults to its own internal semantics. We also observe systematic relation reversal, consistent with findings in (Berglund et al., 2024). More broadly, extracting well-formed triples requires capturing semantic rather than syntactic representations, which is challenging for LLMs trained primarily on surface text. Examples: To exemplify the difference between GraphMERT and LLM KGs explicitly, for the same prompt, we provide Tables C3, C4, C5, C6 with GPT-5 verdicts of triples sampled from GraphMERT -extracted KG and LLM-extracted KG in Appendix C. ## 6.3 Graph-level Evaluation To evaluate the extracted KG, we apply GraphRAG to the filtered benchmarks and assess accuracy based on the model's success rate in answering the questions. We compare the accuracy by using different KGs as the primary source of information in response generation. We evaluate GraphMERT KG against the baseline LLM KG on the filtered endocrinology subset of ICDBench, reporting the average question-answering accuracy across three runs. The evaluation is stratified by difficulty level, a label from the original benchmark. Our filtered test set includes 20 trivial questions (corresponding to 1-hop QA), and a total of 49 questions across difficulty levels ranging from very easy to very hard, based on the difficulty definitions from ICD-Bench. The detailed results are presented in Table 9. We also test the KGs on public benchmarks, which are described in Appendix D. The findings demonstrate that the GraphMERT KG consistently outperforms the baseline. Across the whole filtered subset, our framework achieves an overall accuracy gain of 9.2% on ICD-Bench, and 1.7% to 3.7% gain on other medical benchmarks. This highlights the advantages of the GraphMERT KG for downstream medical questionanswering tasks. Table 9: GraphRAG KG evaluation | Difficulty | Trivial | Very Easy | Easy | Medium | Hard | Very Hard | Average | |-------------------|-----------|-------------|--------|----------|--------|-------------|-----------| | # Questions | 20 | 26 | 8 | 6 | 2 | 7 | 69 | | LLM KG (baseline) | 56.7 | 68 | 33.3 | 38.9 | 0 | 9.5 | 50.2 | | Seed KG | 56.7 | 71.8 | 37.5 | 55.6 | 0 | 4.8 | 53.1 | | GraphMERT | 66.7 | 79.5 | 50 | 50 | 0 | 0 | 59.4 | Table 10: GraphRAG accuracies for different α and β . Performance gain versus LLM KG is shown in parentheses. | α value | LLM KG | Seed KG | β = 0 . 62 | β = 0 . 65 | β = 0 . 67 | β = 0 . 69 | |-----------|----------|-----------|--------------|--------------|---------------|--------------| | 0.5 | 58 | 51.7 | 55.1 (-2.9) | 55.1 (-2.9) | 54.6 (-3.4) | - | | 0.53 | 55.1 | 51.2 | 60.4 (+5.3) | 55.1 (+0.0) | 58.9 (+3.8) | - | | 0.55 | 50.2 | 53.1 | 57.5 (+7.3) | 59.2 (+9.0) | 59.4 ( +9.2 ) | 52.2 (+2.0) | | 0.57 | 51.2 | 53.1 | 56.0 (+4.8) | 54.6 (+3.4) | 52.2 (+1.0) | - | | 0.6 | 53.1 | 49.8 | 53.6 (+0.5) | 52.7 (-0.4) | 53.6 (+0.5) | - | ## 6.4 Ablations To validate our design choices and understand the contribution of different components, we conduct a series of ablation studies. We analyze the sensitivity of GraphMERT to its core hyperparameters, its robustness to the density of the seed KG, and the effect of similarity and fact-checking. ## 6.4.1 Training GraphMERT with Less-relevant Injections Our framework relies on two key similarity thresholds: the injection threshold α , which determines the relevance threshold of seed triples used for training, and the acceptance threshold β , which filters the final triples generated by the pipeline. To find the optimal configuration, we perform a grid search over a range of values for both parameters. Hyperparameter α controls the trade-off between the quality and quantity of knowledge injected during training. A higher α imposes a stricter relevance filter, ensuring high-quality injections but limiting their volume and diversity. Hyperparameter β serves as a grounding function for the final triples on the source sentence. The baseline LLM KG is filtered in each experiment to include only the relations available for the corresponding α value, ensuring an equitable evaluation. The results are presented in Figure 13. We observe that performance peaks at α = 0 . 55 and β = 0 . 67. Lower α 's likely introduce noisy, contextually irrelevant triples that degrade performance. Conversely, higher α 's appear overly restrictive, preventing the model from leveraging a sufficient breadth of knowledge. In addition, β = 0 . 67 gives good results, underscoring the importance of a final quality check on generated triples. A higher optimal β strengthens the importance of cross-document understanding for triple generation, which is not possible in LLM-generated KGs. The optimal configuration achieves a 9.2% improvement over the baseline LLM KG. ## 6.4.2 Training GraphMERT with a Smaller Seed KG To evaluate the dependency of GraphMERT on the density of provided knowledge, we conduct an experiment to measure its performance with a sparser seed KG. A robust system should be able to function effectively even when the initial knowledge base is incomplete. Using the optimal hyperparameters identified previously ( α = 0 . 55 and β = 0 . 67), we simulate varying levels of knowledge sparsity by randomly removing 25%, 50%, and 75% of the triples from the original seed KG before executing our pipeline. Figure 13: GraphRAG accuracies for different α and β . Bubble size corresponds to absolute accuracy and color indicates the accuracy gain relative to the LLM KG baseline (red denotes positive gain, blue denotes negative gain). <!-- image --> Table 11: GraphRAG accuracies upon dropping part of the seed KG. Performance gain versus LLM KG is shown in the last column. | KG type | GraphRAG accuracy | Gap vs. LLM KG | |-----------------------------------|---------------------|------------------| | GraphMERT | 59.4 | 9.2 | | GraphMERT (remove 25% of seed KG) | 54.6 | 4.4 | | GraphMERT (remove 50% of seed KG) | 56.5 | 6.3 | | GraphMERT (remove 75% of seed KG) | 54.1 | 3.9 | The results, shown in Table 11, indicate that while performance generally decreases as the seed KG becomes sparser, our framework remains effective. Even with 75% of the seed knowledge removed, GraphMERT still outperforms the baseline LLM KG by 3.86%. This finding highlights the robustness of our approach, demonstrating that it can effectively leverage even a sparse set of seed triples to generate a high-quality KG. ## 6.4.3 Ablating GraphMERT Components Next, we ablate architectural components and the training objective: No-span MLM/MNM: Replace the span masking objective with a simple one-token MLM/MNM masking objective. No H-GAT: Switch off graph attention. This implies training without relation embeddings; the model predictions are purely syntactic. No dropout: Switch off dropout on relation embeddings. Before discussing the ablation results, we outline the main observations for each one: - In the 'no H-GAT' ablation, we observe a large number of irrelevant tokens in the topk predicted tokens, with commas and articles being primarily predicted in the top 3. This is supported by findings by García-Silva et al. (2023): They attempted to complete triples with topk tokens extracted from Table 12: GraphRAG accuracies when ablating GraphMERT features | KG type | Trivial | Very Easy | Easy | Medium | Hard | Very Hard | Average | |-----------------------------|-----------|-------------|--------|----------|--------|-------------|-----------| | GraphMERT | 66.7 | 79.5 | 50 | 50 | 0 | 0 | 59.4 | | GraphMERT (no-span MLM/MNM) | 66.7 | 76.9 | 29.2 | 61.1 | 0 | 9.5 | 58 | | GraphMERT (no H-GAT) | 65 | 68 | 33.3 | 55.6 | 0 | 0 | 53.1 | | GraphMERT (no dropout) | 56.7 | 65.4 | 45.8 | 50 | 0 | 14.3 | 52.2 | Table 13: FActScore* KG evaluation (in percentage points) when ablating GraphMERT features | KG type | #triples | Context only | Context and General truth | |-----------------------------|------------|----------------|-----------------------------| | GraphMERT | 139,565 | 69.8 | 72.2 | | GraphMERT (no-span MLM/MNM) | 188,211 | 69 | 72.2 | | GraphMERT (no H-GAT) | 167,443 | 68.3 | 70 | | GraphMERT (no dropout) | 149,952 | 68.9 | 70.9 | Table 14: Validity check with Qwen3-32B (in percentage points) when ablating GraphMERT features | KG type | # triples | yes | maybe | no | |-----------------------------|-------------|-------|---------|------| | GraphMERT | 139,565 | 68.8 | 18.3 | 10.8 | | GraphMERT (no-span MLM/MNM) | 188,211 | 69.4 | 18.1 | 10.2 | ", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "GraphMERT KG", "Relation": "produces", "Tail": "higher proportion of valid triples"}, {"Head": "LLM KG", "Relation": "exhibits", "Tail": "more relation misuse and ontology violations"}, {"Head": "GPT-5 Thinking", "Relation": "provides", "Tail": "validity verdicts for triples"}, {"Head": "helper LLM", "Relation": "causes", "Tail": "tail incompleteness in GraphMERT triples"}, {"Head": "tail incompleteness", "Relation": "leads to", "Tail": "vague or semantically weak completions"}, {"Head": "LLM KG", "Relation": "misinterprets", "Tail": "UMLS biomedical relations"}, {"Head": "LLM KG", "Relation": "substitutes with", "Tail": "broader internal knowledge"}, {"Head": "LLM KG", "Relation": "shows", "Tail": "systematic relation reversal"}, {"Head": "GraphRAG", "Relation": "evaluates", "Tail": "extracted knowledge graphs"}, {"Head": "GraphMERT KG", "Relation": "outperforms", "Tail": "LLM KG on ICD-Bench"}, {"Head": "GraphMERT framework", "Relation": "achieves", "Tail": "9.2% overall accuracy gain on ICD-Bench"}, {"Head": "injection threshold α", "Relation": "controls", "Tail": "relevance of seed triples used for training"}, {"Head": "acceptance threshold β", "Relation": "filters", "Tail": "final triples generated by the pipeline"}, {"Head": "optimal hyperparameters", "Relation": "are", "Tail": "α = 0.55 and β = 0.67"}, {"Head": "Seed KG sparsity", "Relation": "reduces", "Tail": "GraphMERT performance but maintains advantage over LLM KG"}, {"Head": "GraphMERT (no H-GAT ablation)", "Relation": "results in", "Tail": "irrelevant top-k token predictions"}, {"Head": "No-span MLM/MNM ablation", "Relation": "replaces", "Tail": "span masking objective with one-token masking"}, {"Head": "No dropout ablation", "Relation": "removes", "Tail": "dropout on relation embeddings"}, {"Head": "Ablation studies", "Relation": "show", "Tail": "component contributions to KG quality"}, {"Head": "low-information 128-token sequences", "Relation": "contaminate", "Tail": "extracted KG"}, {"Head": "predicate misuse", "Relation": "manifests as", "Tail": "wrong relation types or ontologically incorrect predicates"}, {"Head": "overstated causality", "Relation": "occurs when", "Tail": "key tokens required for tail completion are missing"}, {"Head": "GraphMERT KG", "Relation": "is", "Tail": "more conservative and domain-appropriate than LLM KG"}], "entity_relation_output": "[{\"Head\": \"GraphMERT KG\", \"Relation\": \"produces\", \"Tail\": \"higher proportion of valid triples\"}, {\"Head\": \"LLM KG\", \"Relation\": \"exhibits\", \"Tail\": \"more relation misuse and ontology violations\"}, {\"Head\": \"GPT-5 Thinking\", \"Relation\": \"provides\", \"Tail\": \"validity verdicts for triples\"}, {\"Head\": \"helper LLM\", \"Relation\": \"causes\", \"Tail\": \"tail incompleteness in GraphMERT triples\"}, {\"Head\": \"tail incompleteness\", \"Relation\": \"leads to\", \"Tail\": \"vague or semantically weak completions\"}, {\"Head\": \"LLM KG\", \"Relation\": \"misinterprets\", \"Tail\": \"UMLS biomedical relations\"}, {\"Head\": \"LLM KG\", \"Relation\": \"substitutes with\", \"Tail\": \"broader internal knowledge\"}, {\"Head\": \"LLM KG\", \"Relation\": \"shows\", \"Tail\": \"systematic relation reversal\"}, {\"Head\": \"GraphRAG\", \"Relation\": \"evaluates\", \"Tail\": \"extracted knowledge graphs\"}, {\"Head\": \"GraphMERT KG\", \"Relation\": \"outperforms\", \"Tail\": \"LLM KG on ICD-Bench\"}, {\"Head\": \"GraphMERT framework\", \"Relation\": \"achieves\", \"Tail\": \"9.2% overall accuracy gain on ICD-Bench\"}, {\"Head\": \"injection threshold α\", \"Relation\": \"controls\", \"Tail\": \"relevance of seed triples used for training\"}, {\"Head\": \"acceptance threshold β\", \"Relation\": \"filters\", \"Tail\": \"final triples generated by the pipeline\"}, {\"Head\": \"optimal hyperparameters\", \"Relation\": \"are\", \"Tail\": \"α = 0.55 and β = 0.67\"}, {\"Head\": \"Seed KG sparsity\", \"Relation\": \"reduces\", \"Tail\": \"GraphMERT performance but maintains advantage over LLM KG\"}, {\"Head\": \"GraphMERT (no H-GAT ablation)\", \"Relation\": \"results in\", \"Tail\": \"irrelevant top-k token predictions\"}, {\"Head\": \"No-span MLM/MNM ablation\", \"Relation\": \"replaces\", \"Tail\": \"span masking objective with one-token masking\"}, {\"Head\": \"No dropout ablation\", \"Relation\": \"removes\", \"Tail\": \"dropout on relation embeddings\"}, {\"Head\": \"Ablation studies\", \"Relation\": \"show\", \"Tail\": \"component contributions to KG quality\"}, {\"Head\": \"low-information 128-token sequences\", \"Relation\": \"contaminate\", \"Tail\": \"extracted KG\"}, {\"Head\": \"predicate misuse\", \"Relation\": \"manifests as\", \"Tail\": \"wrong relation types or ontologically incorrect predicates\"}, {\"Head\": \"overstated causality\", \"Relation\": \"occurs when\", \"Tail\": \"key tokens required for tail completion are missing\"}, {\"Head\": \"GraphMERT KG\", \"Relation\": \"is\", \"Tail\": \"more conservative and domain-appropriate than LLM KG\"}]", "event_entity_dict": [{"Event": "The GraphMERT KG consistently produces a higher proportion of valid triples and fewer incorrect triples across all keywords", "Entity": ["GraphMERT KG", "valid triples", "incorrect triples", "keywords"]}, {"Event": "The LLM KG shows more relation misuse and ontology violations reflected in a greater share of maybe and no verdicts", "Entity": ["LLM KG", "relation misuse", "ontology violations", "maybe verdicts", "no verdicts"]}, {"Event": "The LLM often violates ontology, confusing methods with diseases, and misuses relations", "Entity": ["LLM", "ontology", "methods", "diseases", "relations"]}, {"Event": "GraphMERT main issues are vagueness and incomplete tails though they remain domain-appropriate", "Entity": ["GraphMERT", "vagueness", "incomplete tails", "domain-appropriate"]}, {"Event": "Tail incompleteness arises when the helper LLM accepts an incomplete token as a valid tail during token combination", "Entity": ["tail incompleteness", "helper LLM", "incomplete token", "tail", "token combination"]}, {"Event": "Tail vagueness occurs when GraphMERT does not rank the required tail tokens within its top-20 predictions and the helper LLM stitches together a semantically weak completion", "Entity": ["tail vagueness", "GraphMERT", "required tail tokens", "top-20 predictions", "helper LLM", "completion"]}, {"Event": "Missing key tokens required for high-quality tail completion explain most cases of overstated causality and predicate misuse", "Entity": ["missing key tokens", "high-quality tail completion", "overstated causality", "predicate misuse"]}, {"Event": "A practical mitigation is to exclude low-information 128-token sequences in the prediction stage", "Entity": ["mitigation", "low-information 128-token sequences", "prediction stage"]}, {"Event": "The LLM misinterprets UMLS biomedical relations and substitutes them with its broader internal knowledge resulting in approximations that violate the ontology", "Entity": ["LLM", "UMLS biomedical relations", "internal knowledge", "approximations", "ontology"]}, {"Event": "Designing prompts to fully explain all relations is impractical and even multiple examples fail to steer the model consistently", "Entity": ["prompts", "relations", "multiple examples", "model"]}, {"Event": "We observe systematic relation reversal in the LLM-extracted triples", "Entity": ["systematic relation reversal", "LLM-extracted triples"]}, {"Event": "Extracting well-formed triples requires capturing semantic rather than syntactic representations which is challenging for LLMs trained primarily on surface text", "Entity": ["well-formed triples", "semantic representations", "syntactic representations", "LLMs", "surface text"]}, {"Event": "We evaluate the extracted KG by applying GraphRAG to the filtered benchmarks and assess accuracy based on the model's success rate in answering the questions", "Entity": ["extracted KG", "GraphRAG", "filtered benchmarks", "accuracy", "model", "questions"]}, {"Event": "We compare accuracy using different KGs as the primary source of information and evaluate GraphMERT KG against the baseline LLM KG on the filtered endocrinology subset of ICD-Bench", "Entity": ["GraphMERT KG", "baseline LLM KG", "filtered endocrinology subset", "ICD-Bench", "accuracy"]}, {"Event": "Our framework achieves an overall accuracy gain of 9.2% on ICD-Bench and 1.7% to 3.7% gain on other medical benchmarks", "Entity": ["framework", "accuracy gain 9.2%", "ICD-Bench", "medical benchmarks", "accuracy gain 1.7% to 3.7%"]}, {"Event": "We conduct ablation studies to validate design choices and understand contributions of different components", "Entity": ["ablation studies", "design choices", "components"]}, {"Event": "Two key similarity thresholds control injections: injection threshold α determines relevance of seed triples used for training and acceptance threshold β filters final triples generated by the pipeline", "Entity": ["injection threshold α", "acceptance threshold β", "seed triples", "training", "final triples", "pipeline"]}, {"Event": "We perform a grid search over α and β and observe performance peaks at α = 0.55 and β = 0.67", "Entity": ["grid search", "α", "β", "performance peaks", "α = 0.55", "β = 0.67"]}, {"Event": "Lower α likely introduces noisy, contextually irrelevant triples while higher α appear overly restrictive preventing leveraging sufficient breadth of knowledge", "Entity": ["lower α", "noisy triples", "contextually irrelevant triples", "higher α", "overly restrictive", "breadth of knowledge"]}, {"Event": "A higher optimal β strengthens the importance of cross-document understanding for triple generation which is not possible in LLM-generated KGs", "Entity": ["higher optimal β", "cross-document understanding", "triple generation", "LLM-generated KGs"]}, {"Event": "Using α = 0.55 and β = 0.67 we simulate knowledge sparsity by removing 25%, 50%, and 75% of triples from the original seed KG and measure GraphMERT performance", "Entity": ["α = 0.55", "β = 0.67", "knowledge sparsity", "25% removal", "50% removal", "75% removal", "seed KG", "GraphMERT performance"]}, {"Event": "Even with 75% of the seed knowledge removed GraphMERT still outperforms the baseline LLM KG by 3.86%", "Entity": ["75% seed knowledge removed", "GraphMERT", "baseline LLM KG", "3.86%"]}, {"Event": "Ablations include No-span MLM/MNM, No H-GAT, and No dropout to evaluate impact of replacing span masking, switching off graph attention, and switching off dropout on relation embeddings", "Entity": ["No-span MLM/MNM", "No H-GAT", "No dropout", "span masking", "graph attention", "dropout", "relation embeddings"]}, {"Event": "In the no H-GAT ablation we observe a large number of irrelevant tokens in top-k predicted tokens with commas and articles primarily predicted in the top 3", "Entity": ["no H-GAT ablation", "irrelevant tokens", "top-k predicted tokens", "commas", "articles"]}], "event_entity_output": "[{\"Event\": \"The GraphMERT KG consistently produces a higher proportion of valid triples and fewer incorrect triples across all keywords\", \"Entity\": [\"GraphMERT KG\", \"valid triples\", \"incorrect triples\", \"keywords\"]}, {\"Event\": \"The LLM KG shows more relation misuse and ontology violations reflected in a greater share of maybe and no verdicts\", \"Entity\": [\"LLM KG\", \"relation misuse\", \"ontology violations\", \"maybe verdicts\", \"no verdicts\"]}, {\"Event\": \"The LLM often violates ontology, confusing methods with diseases, and misuses relations\", \"Entity\": [\"LLM\", \"ontology\", \"methods\", \"diseases\", \"relations\"]}, {\"Event\": \"GraphMERT main issues are vagueness and incomplete tails though they remain domain-appropriate\", \"Entity\": [\"GraphMERT\", \"vagueness\", \"incomplete tails\", \"domain-appropriate\"]}, {\"Event\": \"Tail incompleteness arises when the helper LLM accepts an incomplete token as a valid tail during token combination\", \"Entity\": [\"tail incompleteness\", \"helper LLM\", \"incomplete token\", \"tail\", \"token combination\"]}, {\"Event\": \"Tail vagueness occurs when GraphMERT does not rank the required tail tokens within its top-20 predictions and the helper LLM stitches together a semantically weak completion\", \"Entity\": [\"tail vagueness\", \"GraphMERT\", \"required tail tokens\", \"top-20 predictions\", \"helper LLM\", \"completion\"]}, {\"Event\": \"Missing key tokens required for high-quality tail completion explain most cases of overstated causality and predicate misuse\", \"Entity\": [\"missing key tokens\", \"high-quality tail completion\", \"overstated causality\", \"predicate misuse\"]}, {\"Event\": \"A practical mitigation is to exclude low-information 128-token sequences in the prediction stage\", \"Entity\": [\"mitigation\", \"low-information 128-token sequences\", \"prediction stage\"]}, {\"Event\": \"The LLM misinterprets UMLS biomedical relations and substitutes them with its broader internal knowledge resulting in approximations that violate the ontology\", \"Entity\": [\"LLM\", \"UMLS biomedical relations\", \"internal knowledge\", \"approximations\", \"ontology\"]}, {\"Event\": \"Designing prompts to fully explain all relations is impractical and even multiple examples fail to steer the model consistently\", \"Entity\": [\"prompts\", \"relations\", \"multiple examples\", \"model\"]}, {\"Event\": \"We observe systematic relation reversal in the LLM-extracted triples\", \"Entity\": [\"systematic relation reversal\", \"LLM-extracted triples\"]}, {\"Event\": \"Extracting well-formed triples requires capturing semantic rather than syntactic representations which is challenging for LLMs trained primarily on surface text\", \"Entity\": [\"well-formed triples\", \"semantic representations\", \"syntactic representations\", \"LLMs\", \"surface text\"]}, {\"Event\": \"We evaluate the extracted KG by applying GraphRAG to the filtered benchmarks and assess accuracy based on the model's success rate in answering the questions\", \"Entity\": [\"extracted KG\", \"GraphRAG\", \"filtered benchmarks\", \"accuracy\", \"model\", \"questions\"]}, {\"Event\": \"We compare accuracy using different KGs as the primary source of information and evaluate GraphMERT KG against the baseline LLM KG on the filtered endocrinology subset of ICD-Bench\", \"Entity\": [\"GraphMERT KG\", \"baseline LLM KG\", \"filtered endocrinology subset\", \"ICD-Bench\", \"accuracy\"]}, {\"Event\": \"Our framework achieves an overall accuracy gain of 9.2% on ICD-Bench and 1.7% to 3.7% gain on other medical benchmarks\", \"Entity\": [\"framework\", \"accuracy gain 9.2%\", \"ICD-Bench\", \"medical benchmarks\", \"accuracy gain 1.7% to 3.7%\"]}, {\"Event\": \"We conduct ablation studies to validate design choices and understand contributions of different components\", \"Entity\": [\"ablation studies\", \"design choices\", \"components\"]}, {\"Event\": \"Two key similarity thresholds control injections: injection threshold α determines relevance of seed triples used for training and acceptance threshold β filters final triples generated by the pipeline\", \"Entity\": [\"injection threshold α\", \"acceptance threshold β\", \"seed triples\", \"training\", \"final triples\", \"pipeline\"]}, {\"Event\": \"We perform a grid search over α and β and observe performance peaks at α = 0.55 and β = 0.67\", \"Entity\": [\"grid search\", \"α\", \"β\", \"performance peaks\", \"α = 0.55\", \"β = 0.67\"]}, {\"Event\": \"Lower α likely introduces noisy, contextually irrelevant triples while higher α appear overly restrictive preventing leveraging sufficient breadth of knowledge\", \"Entity\": [\"lower α\", \"noisy triples\", \"contextually irrelevant triples\", \"higher α\", \"overly restrictive\", \"breadth of knowledge\"]}, {\"Event\": \"A higher optimal β strengthens the importance of cross-document understanding for triple generation which is not possible in LLM-generated KGs\", \"Entity\": [\"higher optimal β\", \"cross-document understanding\", \"triple generation\", \"LLM-generated KGs\"]}, {\"Event\": \"Using α = 0.55 and β = 0.67 we simulate knowledge sparsity by removing 25%, 50%, and 75% of triples from the original seed KG and measure GraphMERT performance\", \"Entity\": [\"α = 0.55\", \"β = 0.67\", \"knowledge sparsity\", \"25% removal\", \"50% removal\", \"75% removal\", \"seed KG\", \"GraphMERT performance\"]}, {\"Event\": \"Even with 75% of the seed knowledge removed GraphMERT still outperforms the baseline LLM KG by 3.86%\", \"Entity\": [\"75% seed knowledge removed\", \"GraphMERT\", \"baseline LLM KG\", \"3.86%\"]}, {\"Event\": \"Ablations include No-span MLM/MNM, No H-GAT, and No dropout to evaluate impact of replacing span masking, switching off graph attention, and switching off dropout on relation embeddings\", \"Entity\": [\"No-span MLM/MNM\", \"No H-GAT\", \"No dropout\", \"span masking\", \"graph attention\", \"dropout\", \"relation embeddings\"]}, {\"Event\": \"In the no H-GAT ablation we observe a large number of irrelevant tokens in top-k predicted tokens with commas and articles primarily predicted in the top 3\", \"Entity\": [\"no H-GAT ablation\", \"irrelevant tokens\", \"top-k predicted tokens\", \"commas\", \"articles\"]}]", "event_relation_dict": [{"Head": "The GraphMERT KG consistently produces a higher proportion of valid triples and fewer incorrect triples across all keywords", "Relation": "as a result", "Tail": "The LLM KG shows more relation misuse and ontology violations"}, {"Head": "Tail incompleteness arises when the helper LLM accepts an incomplete token as a valid tail during token combination", "Relation": "because", "Tail": "The helper LLM stitches together a completion that is contextually acceptable but semantically weak"}, {"Head": "Missing key tokens required for high-quality tail completion", "Relation": "because", "Tail": "The LLM still attempts a plausible but semantically weak completion"}, {"Head": "The LLM misinterprets UMLS biomedical relations and substitutes them with its broader internal knowledge", "Relation": "as a result", "Tail": "The LLM produces approximations that violate the ontology"}, {"Head": "Designing prompts to fully explain all relations is impractical and multiple examples fail to steer the LLM consistently", "Relation": "as a result", "Tail": "The LLM defaults to its own internal semantics"}, {"Head": "A practical mitigation is to exclude low-information 128-token sequences in the prediction stage", "Relation": "as a result", "Tail": "Contamination of the extracted KG by semantically weak completions would be reduced"}, {"Head": "GraphMERT outperforms the baseline LLM KG on the filtered endocrinology subset of ICD-Bench with a 9.2% overall accuracy gain", "Relation": "as a result", "Tail": "GraphMERT demonstrates advantages for downstream medical question-answering tasks"}, {"Head": "Performance peaks at alpha = 0.55 and beta = 0.67 in the hyperparameter grid search", "Relation": "at the same time", "Tail": "These optimal hyperparameters yield the observed 9.2% improvement over the baseline LLM KG"}, {"Head": "Lower alpha values introduce noisy, contextually irrelevant triples", "Relation": "because", "Tail": "They degrade GraphMERT performance"}, {"Head": "Higher alpha values impose a stricter relevance filter", "Relation": "because", "Tail": "They limit volume and diversity of injected knowledge and can prevent the model from leveraging sufficient breadth of knowledge"}, {"Head": "Randomly removing 25%, 50%, and 75% of triples from the original seed KG", "Relation": "before", "Tail": "The study measures GraphMERT performance with a sparser seed KG"}, {"Head": "As the seed KG becomes sparser", "Relation": "as a result", "Tail": "GraphMERT performance generally decreases but remains effective and still outperforms the baseline LLM KG even with 75% removal"}, {"Head": "Ablating the H-GAT component (no H-GAT)", "Relation": "as a result", "Tail": "Produces a large number of irrelevant tokens in the top-k predicted tokens"}], "event_relation_output": "[{\"Head\": \"The GraphMERT KG consistently produces a higher proportion of valid triples and fewer incorrect triples across all keywords\", \"Relation\": \"as a result\", \"Tail\": \"The LLM KG shows more relation misuse and ontology violations\"}, {\"Head\": \"Tail incompleteness arises when the helper LLM accepts an incomplete token as a valid tail during token combination\", \"Relation\": \"because\", \"Tail\": \"The helper LLM stitches together a completion that is contextually acceptable but semantically weak\"}, {\"Head\": \"Missing key tokens required for high-quality tail completion\", \"Relation\": \"because\", \"Tail\": \"The LLM still attempts a plausible but semantically weak completion\"}, {\"Head\": \"The LLM misinterprets UMLS biomedical relations and substitutes them with its broader internal knowledge\", \"Relation\": \"as a result\", \"Tail\": \"The LLM produces approximations that violate the ontology\"}, {\"Head\": \"Designing prompts to fully explain all relations is impractical and multiple examples fail to steer the LLM consistently\", \"Relation\": \"as a result\", \"Tail\": \"The LLM defaults to its own internal semantics\"}, {\"Head\": \"A practical mitigation is to exclude low-information 128-token sequences in the prediction stage\", \"Relation\": \"as a result\", \"Tail\": \"Contamination of the extracted KG by semantically weak completions would be reduced\"}, {\"Head\": \"GraphMERT outperforms the baseline LLM KG on the filtered endocrinology subset of ICD-Bench with a 9.2% overall accuracy gain\", \"Relation\": \"as a result\", \"Tail\": \"GraphMERT demonstrates advantages for downstream medical question-answering tasks\"}, {\"Head\": \"Performance peaks at alpha = 0.55 and beta = 0.67 in the hyperparameter grid search\", \"Relation\": \"at the same time\", \"Tail\": \"These optimal hyperparameters yield the observed 9.2% improvement over the baseline LLM KG\"}, {\"Head\": \"Lower alpha values introduce noisy, contextually irrelevant triples\", \"Relation\": \"because\", \"Tail\": \"They degrade GraphMERT performance\"}, {\"Head\": \"Higher alpha values impose a stricter relevance filter\", \"Relation\": \"because\", \"Tail\": \"They limit volume and diversity of injected knowledge and can prevent the model from leveraging sufficient breadth of knowledge\"}, {\"Head\": \"Randomly removing 25%, 50%, and 75% of triples from the original seed KG\", \"Relation\": \"before\", \"Tail\": \"The study measures GraphMERT performance with a sparser seed KG\"}, {\"Head\": \"As the seed KG becomes sparser\", \"Relation\": \"as a result\", \"Tail\": \"GraphMERT performance generally decreases but remains effective and still outperforms the baseline LLM KG even with 75% removal\"}, {\"Head\": \"Ablating the H-GAT component (no H-GAT)\", \"Relation\": \"as a result\", \"Tail\": \"Produces a large number of irrelevant tokens in the top-k predicted tokens\"}]"}
{"id": "1", "original_text": "| GraphMERT (no dropout) | 149,952 | 66.5 | 19.2 | 12 | | GraphMERT (no H-GAT) | 167,443 | 68.2 | 17.2 | 12.2 | the BERT model in a purely syntactic manner, and had to rely on a stop word list to make the results usable. - Disabling dropout leads to overfitting on the seed KG vocabulary; hence, less diverse tails. - Training with a no-span MLM/MNM objective produces simpler tail completions (1-2 tokens long), because each individual candidate is not well aligned with the others. Table 12 demonstrates that the full GraphMERT KG configuration achieves the highest performance. While the full model achieves the best results, the variant without span-masking performs only slightly worse. In contrast, the removal of either dropout or H-GAT leads to a substantial decrease in accuracy, underscoring their importance for robust performance. Table 13 demonstrates that the full model FActScore* is the highest: removing dropout or H-GAT lowers acceptance and increases rejections. GraphMERT without span-masking reaches the same FActScore* in 'Context and General truth' case. GraphMERT without span-masking achieves the best acceptance (69.4% yes, 10.2% no) (Table 14), but, according to GraphRAG, the KG remains less informative overall. In effect, the KG obtained from this variant tends to be populated with trivially correct tiples, i.e., 〈 diabetes, is\\_a , disease 〉 . This leads to a higher rate of successful tail completion: 188k against 140k with span masking. Such short, obvious facts pass a validity check, manifesting in a higher ValidityScore. However, this simplicity comes at a cost: Nospan-masked completions lack the nuance and granularity provided by span masking, resulting in poorer coverage and a loss of fine-grained domain details. This trade-off stresses the importance of evaluating KGs both at the graph and triple levels. We advise employing token-level MLM/MNM when the simplicity of triples is not a limitation. ## 7 Discussion, Limitations, and Future work Discussion: Our results show that GraphMERT yields higher factuality and validity of triples than LLMbased KG extraction while preserving ontology fidelity. We observe a consistent difference between GraphMERT and LLM KGs in relation usage and predicate hygiene. GraphMERT generally employs relations correctly, aligns tails with heads, and preserves biomedical categories (diseases, syndromes, complications). The LLM KG often misuses or reverses the direction of relations, mixes categories in ontology-violating ways (e.g., socio-economic with biomedical), and produces inverse/ill-typed statements. The GraphMERT KG has far fewer ontology violations and hews closer to UMLS. The GraphMERT KG vocabulary is more conservative: The conservativenss can be explained based on the limited scope of the seed KG's vocabulary and its tendency to restate head tokens (mimicking UMLS's tautological triples). We attribute the difference in factuality and validity of triples to the usage of semantic relation embeddings, which move predictions toward ontology-aligned ones. Triple-level error analysis shows GraphMERT may sometimes extract incomplete and vague but often domain-appropriate tails with factual relations, whereas LLMs usually produce diverse tails but frequently misuse or reverse the direction of relations. Our graphlevel evaluation may conflate the KG signal with backbone model knowledge under GraphRAG; future work will include graph-level metrics that isolate the contribution of KGs as well as relation-aware retrieval. Limitations: The main limitation of GraphMERT is its reliance on the seed KG. First, running the framework requires a high-quality seed with 100-1000 examples per relation. Second, once training is complete, the relation set is fixed. Hence, adding new relations requires retraining. A further limitation is its dependence on a helper LLM for tail combination, which introduces occasional incompleteness in the extracted triple tails. As a neural model, GraphMERT also tends to prioritize frequent entities, potentially overlooking rare but meaningful ones. In addition, we did not evaluate the model's ability to predict or handle numerical tokens, which remains an open direction for future work. Finally, its robustness to unseen entities remains untested; extracting entirely novel concepts from new texts would likely require fine-tuning, limiting adaptability in fast-changing domains. Future work: We plan to improve the KG quality by unifying entity spellings, replacing the fixed topk limit with high-probability token selection. We aim to extend GraphMERT to direct multi-token span prediction in the semantic space, reducing reliance on the helper LLM for tail token combining. Further, we plan to conduct more rigorous graph-level evaluations, since GraphRAG alone often blends KG information with model knowledge, and does not guarantee retrieval of the most relevant subgraph, as its retrieval is entity-guided and relations play only a secondary role. It may also be valuable to investigate how the GraphMERT evaluation loss correlates with the quality of the extracted KGs. We also plan to extract KGs in other domains and employ them in various downstream applications. ## 8 Conclusion Weproposed a new framework for automatically extracting domain-specific KGs from unstructured, sentencelevel text. Central to this work is our idea of encoding both semantic and syntactic information into textual chain graphs, a new representation we introduced. To operate in this space, we presented GraphMERT , a transformer-based model that unifies an encoder-only architecture with graph attention. Together, these contributions enable the distillation of explicit semantic structures from trained neural networks, bridging neural and symbolic representations and advancing interpretable, reliable KG construction. We also outlined KG-powered applications, underscoring that future progress hinges on reliable, factual KGs and other high-level explicit abstractions that embody collective knowledge while remaining compatible with AI inference and downstream tasks. We argue that neural-KG integration is a key step toward domainspecific superintelligence. Looking ahead, we foresee the research community embracing the neurosymbolic paradigm, where explicit, auditable, and evolving KGs complement neural inference that is approximate, efficient, and capable of handling ambiguity. Acknowledgment: This work was supported by NSF under Grant No. CNS-2216746. ## References - Titipat Achakulvisut, Daniel Acuna, and Konrad Kording. Pubmed parser: A Python parser for PubMed open-access XML subset and MEDLINE XML dataset. Journal of Open Source Software , 5(46):1979, 2020. - Kian Ahrabian, Xinwei Du, Richard Delwin Myloth, Arun Baalaaji Sankar Ananthan, and Jay Pujara. PubGraph: A large-scale scientific knowledge graph, 2023. arXiv:2302.02231 [cs.AI]. - Ekin Akyurek, Tolga Bolukbasi, Frederick Liu, Binbin Xiong, Ian Tenney, Jacob Andreas, and Kelvin Guu. Towards tracing knowledge in language models back to the training data, December 2022. In Findings of the Association for Computational Linguistics: EMNLP 2022 . - Laith Alzubaidi, Aiman Al-Sabaawi, Jinshuai Bai, Ammar Dukhan, Ahmed H. Alkenani, Ahmed Al-Asadi, Haider A. Alwzwazy, Mohamed Manoufali, Mohammed A. Fadhel, A. S. Albahri, Catarina Moreira, Chun Ouyang, Jinglan Zhang, Jose Santamaría, Asma Salhi, Freek Hollman, Ashish Gupta, Ye Duan, Timon Rabczuk, Amin Abbosh, and Yuantong Gu. Towards risk-free trustworthy artificial intelligence: Significance and requirements. International Journal of Intelligent Systems , 2023(1):4459198, 2023. doi: 10.1155/2023/4459198. - Chenxin An, Jun Zhang, Ming Zhong, Lei Li, Shansan Gong, Yao Luo, Jingjing Xu, and Lingpeng Kong. Why does the effective context length of LLMs fall short?, 2024. arXiv:2410.18745 [cs.CL]. - Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate, 2016. arXiv:1409.0473 [cs.CL]. - Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. The reversal curse: LLMs trained on 'A is B\" fail to learn 'B is A\", 2024. arXiv:2309.12288 [cs.CL]. - Tarek R. Besold, Artur d'Avila Garcez, Sebastian Bader, Howard Bowman, Pedro Domingos, Pascal Hitzler, Kai-Uwe Kuehnberger, Luis C. Lamb, Daniel Lowd, Priscila Machado Vieira Lima, Leo de Penning, Gadi Pinkas, Hoifung Poon, and Gerson Zaverucha. Neural-symbolic learning and reasoning: A survey and interpretation, 2017. arXiv:1711.03902 [cs.AI]. - Olivier Bodenreider. The Unified Medical Language System (UMLS): Integrating biomedical terminology. Nucleic Acids Research , 32:267-270, 2004. Nick Bostrom. Superintelligence: Paths, Dangers, Strategies . 2014. Samuel R. Bowman. Eight things to know about large language models, 2023. arXiv:2304.00612 [cs.CL]. - Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020. In Advances in Neural Information Processing Systems . - Boxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingyong Yan, Meng Liao, Tong Xue, and Jin Xu. Knowledgeable or educated guess? Revisiting language models as knowledge bases, August 2021. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) . - Salvatore Carta, Alessandro Giuliani, Leonardo Piano, Alessandro Sebastian Podda, Livio Pompianu, and Sandro Gabriele Tiddia. Iterative zero-shot LLM prompting for knowledge graph construction, 2023. arXiv:2307.01128 [cs.CL]. - Souradip Chakraborty, Ekaba Bisong, Shweta Bhatt, Thomas Wagner, Riley Elliott, and Francesco Mosconi. BioMedBERT: A pre-trained biomedical language model for QA and IR, December 2020. In Proceedings of the 28th International Conference on Computational Linguistics . - Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, and Minjoon Seo. How do large language models acquire factual knowledge during pretraining?, 2025. In Proceedings of the 38th International Conference on Neural Information Processing Systems . - Hanzhu Chen, Xu Shen, Qitan Lv, Jie Wang, Xiaoqi Ni, and Jieping Ye. SAC-KG: Exploiting large language models as skilled automatic constructors for domain knowledge graph, August 2024. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . - Hao Chen, Yiming Zhang, Qi Zhang, Hantao Yang, Xiaomeng Hu, Xuetao Ma, Yifan Yanggong, and Junbo Zhao. Maybe only 0.5% data is needed: A preliminary exploration of low training data instruction tuning, 2023a. arXiv:2305.09246 [cs.AI]. - Mingyang Chen, Wen Zhang, Yuxia Geng, Zezhong Xu, Jeff Z. Pan, and Huajun Chen. Generalizing to unseen elements: a survey on knowledge extrapolation for knowledge graphs, 2023b. In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence . - Zhisong Chen and Ching Y. Suen. Measuring the complexity of rule-based expert systems. Expert Systems with Applications , 7(4):467-481, 1994. ISSN 0957-4174. doi: 10.1016/0957-4174(94)90072-8. - Kewei Cheng, Nesreen K. Ahmed, Ryan A. Rossi, Theodore Willke, and Yizhou Sun. Neural-symbolic methods for knowledge graph reasoning: A survey. ACM Transactions on Knowledge Discovery from Data , 18(9), November 2024. ISSN 1556-4681. doi: 10.1145/3686806. - Alain Colmerauer and Philippe Roussel. The birth of Prolog , pp. 331-367. 1996. ISBN 0201895021. doi: 10.1145/234286.1057820. - Artur d'Avila Garcez, Marco Gori, Luis C. Lamb, Luciano Serafini, Michael Spranger, and Son N. Tran. Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning, 2019. arXiv:1905.06088 [cs.AI]. - Artur S. d'Avila Garcez, Krysia B. Broda, and Dov. M. Gabbay. Introduction and Overview . 2002. ISBN 978-1-4471-0211-3. doi: 10.1007/978-1-4471-0211-3\\_1. In Foundations and Applications . - Bhishma Dedhia, Yuval Kansal, and Niraj K. Jha. Bottom-up domain-specific superintelligence: A reliable knowledge graph is what we need, 2025. arXiv:2507.13966 [cs.CL]. - Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding, 2019. arXiv:1810.04805 [cs.CL]. - Esin Durmus, Faisal Ladhak, and Tatsunori Hashimoto. Spurious correlations in reference-free evaluation of text generation, 2022. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . - Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph RAG approach to query-focused summarization, 2024. arXiv:2404.16130 [cs.CL]. - Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. A survey on RAG meeting LLMs: Towards retrieval-augmented large language models, 2024. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . - Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang Wu, and G", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "GraphMERT", "Relation": "achieves", "Tail": "higher factuality and validity of triples"}, {"Head": "GraphMERT", "Relation": "preserves", "Tail": "ontology fidelity"}, {"Head": "GraphMERT", "Relation": "employs", "Tail": "semantic relation embeddings"}, {"Head": "semantic relation embeddings", "Relation": "move predictions toward", "Tail": "ontology-aligned relations"}, {"Head": "no dropout", "Relation": "leads to", "Tail": "overfitting on the seed KG vocabulary"}, {"Head": "overfitting on the seed KG vocabulary", "Relation": "causes", "Tail": "less diverse tails"}, {"Head": "no-span MLM/MNM objective", "Relation": "produces", "Tail": "simpler tail completions"}, {"Head": "span masking", "Relation": "provides", "Tail": "nuance and granularity in completions"}, {"Head": "no span-masking variant", "Relation": "results in", "Tail": "trivially correct triples"}, {"Head": "trivially correct triples", "Relation": "increase", "Tail": "Validit yScore"}, {"Head": "no span-masking completions", "Relation": "lead to", "Tail": "poorer coverage and loss of fine-grained details"}, {"Head": "disabling H-GAT", "Relation": "causes", "Tail": "substantial decrease in accuracy"}, {"Head": "removing dropout or H-GAT", "Relation": "lowers", "Tail": "acceptance and increases rejections"}, {"Head": "GraphMERT KG", "Relation": "has fewer", "Tail": "ontology violations than LLM KG"}, {"Head": "LLM KG", "Relation": "misuses", "Tail": "relation directions and categories"}, {"Head": "seed KG", "Relation": "is required by", "Tail": "GraphMERT training"}, {"Head": "seed KG", "Relation": "provides", "Tail": "relation vocabulary scope"}, {"Head": "helper LLM", "Relation": "introduces", "Tail": "occasional incompleteness in triple tails"}, {"Head": "GraphRAG evaluation", "Relation": "conflates", "Tail": "KG signal with backbone model knowledge"}, {"Head": "future work", "Relation": "includes", "Tail": "relation-aware retrieval and graph-level metrics"}, {"Head": "proposed textual chain graphs", "Relation": "encode", "Tail": "semantic and syntactic information"}, {"Head": "GraphMERT architecture", "Relation": "unifies", "Tail": "encoder-only transformer with graph attention"}, {"Head": "neural-KG integration", "Relation": "is argued to be", "Tail": "a key step toward domain-specific superintelligence"}, {"Head": "limitations of GraphMERT", "Relation": "include", "Tail": "dependence on seed KG and fixed relation set"}, {"Head": "limitations of GraphMERT", "Relation": "include", "Tail": "prioritization of frequent entities over rare ones"}, {"Head": "planned improvements", "Relation": "involve", "Tail": "unifying entity spellings and token-level selection"}, {"Head": "planned improvements", "Relation": "involve", "Tail": "direct multi-token span prediction in semantic space"}], "entity_relation_output": "[{\"Head\": \"GraphMERT\", \"Relation\": \"achieves\", \"Tail\": \"higher factuality and validity of triples\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"preserves\", \"Tail\": \"ontology fidelity\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"employs\", \"Tail\": \"semantic relation embeddings\"}, {\"Head\": \"semantic relation embeddings\", \"Relation\": \"move predictions toward\", \"Tail\": \"ontology-aligned relations\"}, {\"Head\": \"no dropout\", \"Relation\": \"leads to\", \"Tail\": \"overfitting on the seed KG vocabulary\"}, {\"Head\": \"overfitting on the seed KG vocabulary\", \"Relation\": \"causes\", \"Tail\": \"less diverse tails\"}, {\"Head\": \"no-span MLM/MNM objective\", \"Relation\": \"produces\", \"Tail\": \"simpler tail completions\"}, {\"Head\": \"span masking\", \"Relation\": \"provides\", \"Tail\": \"nuance and granularity in completions\"}, {\"Head\": \"no span-masking variant\", \"Relation\": \"results in\", \"Tail\": \"trivially correct triples\"}, {\"Head\": \"trivially correct triples\", \"Relation\": \"increase\", \"Tail\": \"Validit yScore\"}, {\"Head\": \"no span-masking completions\", \"Relation\": \"lead to\", \"Tail\": \"poorer coverage and loss of fine-grained details\"}, {\"Head\": \"disabling H-GAT\", \"Relation\": \"causes\", \"Tail\": \"substantial decrease in accuracy\"}, {\"Head\": \"removing dropout or H-GAT\", \"Relation\": \"lowers\", \"Tail\": \"acceptance and increases rejections\"}, {\"Head\": \"GraphMERT KG\", \"Relation\": \"has fewer\", \"Tail\": \"ontology violations than LLM KG\"}, {\"Head\": \"LLM KG\", \"Relation\": \"misuses\", \"Tail\": \"relation directions and categories\"}, {\"Head\": \"seed KG\", \"Relation\": \"is required by\", \"Tail\": \"GraphMERT training\"}, {\"Head\": \"seed KG\", \"Relation\": \"provides\", \"Tail\": \"relation vocabulary scope\"}, {\"Head\": \"helper LLM\", \"Relation\": \"introduces\", \"Tail\": \"occasional incompleteness in triple tails\"}, {\"Head\": \"GraphRAG evaluation\", \"Relation\": \"conflates\", \"Tail\": \"KG signal with backbone model knowledge\"}, {\"Head\": \"future work\", \"Relation\": \"includes\", \"Tail\": \"relation-aware retrieval and graph-level metrics\"}, {\"Head\": \"proposed textual chain graphs\", \"Relation\": \"encode\", \"Tail\": \"semantic and syntactic information\"}, {\"Head\": \"GraphMERT architecture\", \"Relation\": \"unifies\", \"Tail\": \"encoder-only transformer with graph attention\"}, {\"Head\": \"neural-KG integration\", \"Relation\": \"is argued to be\", \"Tail\": \"a key step toward domain-specific superintelligence\"}, {\"Head\": \"limitations of GraphMERT\", \"Relation\": \"include\", \"Tail\": \"dependence on seed KG and fixed relation set\"}, {\"Head\": \"limitations of GraphMERT\", \"Relation\": \"include\", \"Tail\": \"prioritization of frequent entities over rare ones\"}, {\"Head\": \"planned improvements\", \"Relation\": \"involve\", \"Tail\": \"unifying entity spellings and token-level selection\"}, {\"Head\": \"planned improvements\", \"Relation\": \"involve\", \"Tail\": \"direct multi-token span prediction in semantic space\"}]", "event_entity_dict": [{"Event": "Disabling dropout leads to overfitting on the seed KG vocabulary", "Entity": ["dropout", "seed KG vocabulary", "GraphMERT"]}, {"Event": "Training with a no-span MLM/MNM objective produces simpler tail completions", "Entity": ["no-span MLM/MNM objective", "tail completions", "GraphMERT"]}, {"Event": "The full GraphMERT KG configuration achieves the highest performance", "Entity": ["full GraphMERT KG configuration", "performance", "Table 12"]}, {"Event": "The variant without span-masking performs only slightly worse than the full model", "Entity": ["variant without span-masking", "full model", "GraphMERT"]}, {"Event": "Removal of either dropout or H-GAT leads to a substantial decrease in accuracy", "Entity": ["dropout", "H-GAT", "accuracy", "GraphMERT"]}, {"Event": "The full model FActScore* is the highest", "Entity": ["full model", "FActScore*", "Table 13"]}, {"Event": "Removing dropout or H-GAT lowers acceptance and increases rejections", "Entity": ["dropout", "H-GAT", "acceptance", "rejections", "GraphMERT"]}, {"Event": "GraphMERT without span-masking reaches the same FActScore* in 'Context and General truth' case", "Entity": ["GraphMERT without span-masking", "FActScore*", "Context and General truth case"]}, {"Event": "GraphMERT without span-masking achieves the best acceptance", "Entity": ["GraphMERT without span-masking", "acceptance", "Table 14"]}, {"Event": "According to GraphRAG, the KG from the no-span variant remains less informative overall", "Entity": ["GraphRAG", "KG from no-span variant", "informativeness", "GraphMERT"]}, {"Event": "The KG obtained from the no-span variant tends to be populated with trivially correct triples", "Entity": ["KG obtained from no-span variant", "trivially correct triples", "GraphMERT"]}, {"Event": "This leads to a higher rate of successful tail completion: 188k against 140k with span masking", "Entity": ["no-span variant", "successful tail completion", "188k", "140k", "span masking"]}, {"Event": "Such short, obvious facts pass a validity check, manifesting in a higher ValidityScore", "Entity": ["short obvious facts", "validity check", "ValidityScore"]}, {"Event": "Nospan-masked completions lack the nuance and granularity provided by span masking", "Entity": ["Nospan-masked completions", "span masking", "nuance", "granularity"]}, {"Event": "This simplicity results in poorer coverage and a loss of fine-grained domain details", "Entity": ["simplicity of triples", "coverage", "fine-grained domain details", "no-span variant"]}, {"Event": "We advise employing token-level MLM/MNM when the simplicity of triples is not a limitation", "Entity": ["token-level MLM/MNM", "triples simplicity", "advice", "GraphMERT users"]}, {"Event": "Our results show that GraphMERT yields higher factuality and validity of triples than LLM-based KG extraction", "Entity": ["GraphMERT", "factuality", "validity of triples", "LLM-based KG extraction", "results"]}, {"Event": "GraphMERT preserves ontology fidelity while outperforming LLM-based KG extraction", "Entity": ["GraphMERT", "ontology fidelity", "LLM-based KG extraction"]}, {"Event": "We observe a consistent difference between GraphMERT and LLM KGs in relation usage and predicate hygiene", "Entity": ["GraphMERT KG", "LLM KG", "relation usage", "predicate hygiene", "observations"]}, {"Event": "GraphMERT generally employs relations correctly, aligns tails with heads, and preserves biomedical categories", "Entity": ["GraphMERT", "relations", "tails", "heads", "biomedical categories", "diseases", "syndromes", "complications"]}, {"Event": "The LLM KG often misuses or reverses the direction of relations and mixes categories in ontology-violating ways", "Entity": ["LLM KG", "relations", "ontology violations", "socio-economic categories", "biomedical categories"]}, {"Event": "The GraphMERT KG has far fewer ontology violations and hews closer to UMLS", "Entity": ["GraphMERT KG", "ontology violations", "UMLS"]}, {"Event": "The GraphMERT KG vocabulary is more conservative due to the limited scope of the seed KG's vocabulary", "Entity": ["GraphMERT KG vocabulary", "seed KG's vocabulary", "conservativeness"]}, {"Event": "We attribute the difference in factuality and validity to the usage of semantic relation embeddings", "Entity": ["factuality", "validity", "semantic relation embeddings", "GraphMERT"]}, {"Event": "Triple-level error analysis shows GraphMERT may extract incomplete and vague but often domain-appropriate tails", "Entity": ["triple-level error analysis", "GraphMERT", "incomplete tails", "vague tails", "domain-appropriate tails", "factual relations"]}, {"Event": "LLMs usually produce diverse tails but frequently misuse or reverse the direction of relations", "Entity": ["LLMs", "diverse tails", "misuse relations", "reverse direction of relations"]}, {"Event": "Our graph-level evaluation may conflate the KG signal with backbone model knowledge under GraphRAG", "Entity": ["graph-level evaluation", "KG signal", "backbone model knowledge", "GraphRAG"]}, {"Event": "Future work will include graph-level metrics that isolate the contribution of KGs as well as relation-aware retrieval", "Entity": ["future work", "graph-level metrics", "contribution of KGs", "relation-aware retrieval"]}, {"Event": "The main limitation of GraphMERT is its reliance on the seed KG", "Entity": ["main limitation", "GraphMERT", "seed KG", "reliance"]}, {"Event": "Running the framework requires a high-quality seed with 100-1000 examples per relation", "Entity": ["running the framework", "high-quality seed", "100-1000 examples per relation", "GraphMERT"]}, {"Event": "Once training is complete, the relation set is fixed and adding new relations requires retraining", "Entity": ["training", "relation set", "retraining", "GraphMERT"]}, {"Event": "GraphMERT depends on a helper LLM for tail combination which introduces occasional incompleteness", "Entity": ["GraphMERT", "helper LLM", "tail combination", "incompleteness"]}], "event_entity_output": "[{\"Event\": \"Disabling dropout leads to overfitting on the seed KG vocabulary\", \"Entity\": [\"dropout\", \"seed KG vocabulary\", \"GraphMERT\"]}, {\"Event\": \"Training with a no-span MLM/MNM objective produces simpler tail completions\", \"Entity\": [\"no-span MLM/MNM objective\", \"tail completions\", \"GraphMERT\"]}, {\"Event\": \"The full GraphMERT KG configuration achieves the highest performance\", \"Entity\": [\"full GraphMERT KG configuration\", \"performance\", \"Table 12\"]}, {\"Event\": \"The variant without span-masking performs only slightly worse than the full model\", \"Entity\": [\"variant without span-masking\", \"full model\", \"GraphMERT\"]}, {\"Event\": \"Removal of either dropout or H-GAT leads to a substantial decrease in accuracy\", \"Entity\": [\"dropout\", \"H-GAT\", \"accuracy\", \"GraphMERT\"]}, {\"Event\": \"The full model FActScore* is the highest\", \"Entity\": [\"full model\", \"FActScore*\", \"Table 13\"]}, {\"Event\": \"Removing dropout or H-GAT lowers acceptance and increases rejections\", \"Entity\": [\"dropout\", \"H-GAT\", \"acceptance\", \"rejections\", \"GraphMERT\"]}, {\"Event\": \"GraphMERT without span-masking reaches the same FActScore* in 'Context and General truth' case\", \"Entity\": [\"GraphMERT without span-masking\", \"FActScore*\", \"Context and General truth case\"]}, {\"Event\": \"GraphMERT without span-masking achieves the best acceptance\", \"Entity\": [\"GraphMERT without span-masking\", \"acceptance\", \"Table 14\"]}, {\"Event\": \"According to GraphRAG, the KG from the no-span variant remains less informative overall\", \"Entity\": [\"GraphRAG\", \"KG from no-span variant\", \"informativeness\", \"GraphMERT\"]}, {\"Event\": \"The KG obtained from the no-span variant tends to be populated with trivially correct triples\", \"Entity\": [\"KG obtained from no-span variant\", \"trivially correct triples\", \"GraphMERT\"]}, {\"Event\": \"This leads to a higher rate of successful tail completion: 188k against 140k with span masking\", \"Entity\": [\"no-span variant\", \"successful tail completion\", \"188k\", \"140k\", \"span masking\"]}, {\"Event\": \"Such short, obvious facts pass a validity check, manifesting in a higher ValidityScore\", \"Entity\": [\"short obvious facts\", \"validity check\", \"ValidityScore\"]}, {\"Event\": \"Nospan-masked completions lack the nuance and granularity provided by span masking\", \"Entity\": [\"Nospan-masked completions\", \"span masking\", \"nuance\", \"granularity\"]}, {\"Event\": \"This simplicity results in poorer coverage and a loss of fine-grained domain details\", \"Entity\": [\"simplicity of triples\", \"coverage\", \"fine-grained domain details\", \"no-span variant\"]}, {\"Event\": \"We advise employing token-level MLM/MNM when the simplicity of triples is not a limitation\", \"Entity\": [\"token-level MLM/MNM\", \"triples simplicity\", \"advice\", \"GraphMERT users\"]}, {\"Event\": \"Our results show that GraphMERT yields higher factuality and validity of triples than LLM-based KG extraction\", \"Entity\": [\"GraphMERT\", \"factuality\", \"validity of triples\", \"LLM-based KG extraction\", \"results\"]}, {\"Event\": \"GraphMERT preserves ontology fidelity while outperforming LLM-based KG extraction\", \"Entity\": [\"GraphMERT\", \"ontology fidelity\", \"LLM-based KG extraction\"]}, {\"Event\": \"We observe a consistent difference between GraphMERT and LLM KGs in relation usage and predicate hygiene\", \"Entity\": [\"GraphMERT KG\", \"LLM KG\", \"relation usage\", \"predicate hygiene\", \"observations\"]}, {\"Event\": \"GraphMERT generally employs relations correctly, aligns tails with heads, and preserves biomedical categories\", \"Entity\": [\"GraphMERT\", \"relations\", \"tails\", \"heads\", \"biomedical categories\", \"diseases\", \"syndromes\", \"complications\"]}, {\"Event\": \"The LLM KG often misuses or reverses the direction of relations and mixes categories in ontology-violating ways\", \"Entity\": [\"LLM KG\", \"relations\", \"ontology violations\", \"socio-economic categories\", \"biomedical categories\"]}, {\"Event\": \"The GraphMERT KG has far fewer ontology violations and hews closer to UMLS\", \"Entity\": [\"GraphMERT KG\", \"ontology violations\", \"UMLS\"]}, {\"Event\": \"The GraphMERT KG vocabulary is more conservative due to the limited scope of the seed KG's vocabulary\", \"Entity\": [\"GraphMERT KG vocabulary\", \"seed KG's vocabulary\", \"conservativeness\"]}, {\"Event\": \"We attribute the difference in factuality and validity to the usage of semantic relation embeddings\", \"Entity\": [\"factuality\", \"validity\", \"semantic relation embeddings\", \"GraphMERT\"]}, {\"Event\": \"Triple-level error analysis shows GraphMERT may extract incomplete and vague but often domain-appropriate tails\", \"Entity\": [\"triple-level error analysis\", \"GraphMERT\", \"incomplete tails\", \"vague tails\", \"domain-appropriate tails\", \"factual relations\"]}, {\"Event\": \"LLMs usually produce diverse tails but frequently misuse or reverse the direction of relations\", \"Entity\": [\"LLMs\", \"diverse tails\", \"misuse relations\", \"reverse direction of relations\"]}, {\"Event\": \"Our graph-level evaluation may conflate the KG signal with backbone model knowledge under GraphRAG\", \"Entity\": [\"graph-level evaluation\", \"KG signal\", \"backbone model knowledge\", \"GraphRAG\"]}, {\"Event\": \"Future work will include graph-level metrics that isolate the contribution of KGs as well as relation-aware retrieval\", \"Entity\": [\"future work\", \"graph-level metrics\", \"contribution of KGs\", \"relation-aware retrieval\"]}, {\"Event\": \"The main limitation of GraphMERT is its reliance on the seed KG\", \"Entity\": [\"main limitation\", \"GraphMERT\", \"seed KG\", \"reliance\"]}, {\"Event\": \"Running the framework requires a high-quality seed with 100-1000 examples per relation\", \"Entity\": [\"running the framework\", \"high-quality seed\", \"100-1000 examples per relation\", \"GraphMERT\"]}, {\"Event\": \"Once training is complete, the relation set is fixed and adding new relations requires retraining\", \"Entity\": [\"training\", \"relation set\", \"retraining\", \"GraphMERT\"]}, {\"Event\": \"GraphMERT depends on a helper LLM for tail combination which introduces occasional incompleteness\", \"Entity\": [\"GraphMERT\", \"helper LLM\", \"tail combination\", \"incompleteness\"]}]", "event_relation_dict": [{"Head": "Disabling dropout leads to overfitting on the seed KG vocabulary", "Relation": "because", "Tail": "there are less diverse tails"}, {"Head": "Training with a no-span MLM/MNM objective produces simpler tail completions", "Relation": "because", "Tail": "each individual candidate is not well aligned with the others"}, {"Head": "The full GraphMERT KG configuration achieves the highest performance", "Relation": "as a result", "Tail": "the full model achieves the best results"}, {"Head": "The variant without span-masking performs slightly worse", "Relation": "after", "Tail": "the full model achieves the best results"}, {"Head": "Removal of either dropout or H-GAT leads to a substantial decrease in accuracy", "Relation": "as a result", "Tail": "their importance for robust performance is underscored"}, {"Head": "Removing dropout or H-GAT lowers acceptance and increases rejections", "Relation": "as a result", "Tail": "the full model FActScore* is the highest"}, {"Head": "GraphMERT without span-masking reaches the same FActScore* in the 'Context and General truth' case", "Relation": "at the same time", "Tail": "the full model FActScore* is the highest"}, {"Head": "GraphMERT without span-masking achieves the best acceptance (69.4% yes, 10.2% no)", "Relation": "because", "Tail": "the KG obtained from this variant tends to be populated with trivially correct triples"}, {"Head": "The KG from the no-span-masked variant is populated with trivially correct triples", "Relation": "as a result", "Tail": "there is a higher rate of successful tail completion: 188k against 140k with span masking"}, {"Head": "Such short, obvious facts pass a validity check", "Relation": "as a result", "Tail": "they manifest in a higher ValidityScore"}, {"Head": "No-span-masked completions lack nuance and granularity provided by span masking", "Relation": "as a result", "Tail": "they produce poorer coverage and a loss of fine-grained domain details"}, {"Head": "This trade-off stresses the importance of evaluating KGs both at the graph and triple levels", "Relation": "because", "Tail": "simplicity of triples can hide poorer coverage and loss of domain details"}, {"Head": "We advise employing token-level MLM/MNM", "Relation": "because", "Tail": "the simplicity of triples from no-span masking is a limitation in some cases"}, {"Head": "GraphMERT yields higher factuality and validity of triples than LLM-based KG extraction", "Relation": "as a result", "Tail": "GraphMERT preserves ontology fidelity better than LLM KGs"}, {"Head": "GraphMERT generally employs relations correctly and preserves biomedical categories", "Relation": "as a result", "Tail": "the GraphMERT KG has far fewer ontology violations and hews closer to UMLS"}, {"Head": "The GraphMERT KG vocabulary is more conservative", "Relation": "because", "Tail": "the seed KG's limited scope tends to restate head tokens and mimic tautological triples"}, {"Head": "We attribute the difference in factuality and validity of triples to the usage of semantic relation embeddings", "Relation": "because", "Tail": "embeddings move predictions toward ontology-aligned ones"}, {"Head": "Triple-level error analysis shows GraphMERT may extract incomplete and vague but often domain-appropriate tails", "Relation": "at the same time", "Tail": "LLMs usually produce diverse tails but frequently misuse or reverse the direction of relations"}, {"Head": "Our graph-level evaluation may conflate the KG signal with backbone model knowledge under GraphRAG", "Relation": "because", "Tail": "GraphRAG blends KG information with model knowledge and does not isolate KG contribution"}, {"Head": "Future work will include graph-level metrics that isolate the contribution of KGs", "Relation": "after", "Tail": "we address the current conflation caused by GraphRAG"}, {"Head": "The main limitation of GraphMERT is its reliance on the seed KG", "Relation": "because", "Tail": "running the framework requires a high-quality seed with 100-1000 examples per relation"}, {"Head": "Once training is complete, the relation set is fixed", "Relation": "as a result", "Tail": "adding new relations requires retraining"}, {"Head": "GraphMERT depends on a helper LLM for tail combination", "Relation": "as a result", "Tail": "this introduces occasional incompleteness in the extracted triple tails"}, {"Head": "GraphMERT tends to prioritize frequent entities", "Relation": "as a result", "Tail": "it can potentially overlook rare but meaningful entities"}, {"Head": "We plan to extend GraphMERT to direct multi-token span prediction in the semantic space", "Relation": "because", "Tail": "this will reduce reliance on the helper LLM for tail token combining"}, {"Head": "We plan to conduct more rigorous graph-level evaluations", "Relation": "because", "Tail": "GraphRAG often blends KG information with model knowledge and may not retrieve the most relevant subgraph"}], "event_relation_output": "[{\"Head\": \"Disabling dropout leads to overfitting on the seed KG vocabulary\", \"Relation\": \"because\", \"Tail\": \"there are less diverse tails\"}, {\"Head\": \"Training with a no-span MLM/MNM objective produces simpler tail completions\", \"Relation\": \"because\", \"Tail\": \"each individual candidate is not well aligned with the others\"}, {\"Head\": \"The full GraphMERT KG configuration achieves the highest performance\", \"Relation\": \"as a result\", \"Tail\": \"the full model achieves the best results\"}, {\"Head\": \"The variant without span-masking performs slightly worse\", \"Relation\": \"after\", \"Tail\": \"the full model achieves the best results\"}, {\"Head\": \"Removal of either dropout or H-GAT leads to a substantial decrease in accuracy\", \"Relation\": \"as a result\", \"Tail\": \"their importance for robust performance is underscored\"}, {\"Head\": \"Removing dropout or H-GAT lowers acceptance and increases rejections\", \"Relation\": \"as a result\", \"Tail\": \"the full model FActScore* is the highest\"}, {\"Head\": \"GraphMERT without span-masking reaches the same FActScore* in the 'Context and General truth' case\", \"Relation\": \"at the same time\", \"Tail\": \"the full model FActScore* is the highest\"}, {\"Head\": \"GraphMERT without span-masking achieves the best acceptance (69.4% yes, 10.2% no)\", \"Relation\": \"because\", \"Tail\": \"the KG obtained from this variant tends to be populated with trivially correct triples\"}, {\"Head\": \"The KG from the no-span-masked variant is populated with trivially correct triples\", \"Relation\": \"as a result\", \"Tail\": \"there is a higher rate of successful tail completion: 188k against 140k with span masking\"}, {\"Head\": \"Such short, obvious facts pass a validity check\", \"Relation\": \"as a result\", \"Tail\": \"they manifest in a higher ValidityScore\"}, {\"Head\": \"No-span-masked completions lack nuance and granularity provided by span masking\", \"Relation\": \"as a result\", \"Tail\": \"they produce poorer coverage and a loss of fine-grained domain details\"}, {\"Head\": \"This trade-off stresses the importance of evaluating KGs both at the graph and triple levels\", \"Relation\": \"because\", \"Tail\": \"simplicity of triples can hide poorer coverage and loss of domain details\"}, {\"Head\": \"We advise employing token-level MLM/MNM\", \"Relation\": \"because\", \"Tail\": \"the simplicity of triples from no-span masking is a limitation in some cases\"}, {\"Head\": \"GraphMERT yields higher factuality and validity of triples than LLM-based KG extraction\", \"Relation\": \"as a result\", \"Tail\": \"GraphMERT preserves ontology fidelity better than LLM KGs\"}, {\"Head\": \"GraphMERT generally employs relations correctly and preserves biomedical categories\", \"Relation\": \"as a result\", \"Tail\": \"the GraphMERT KG has far fewer ontology violations and hews closer to UMLS\"}, {\"Head\": \"The GraphMERT KG vocabulary is more conservative\", \"Relation\": \"because\", \"Tail\": \"the seed KG's limited scope tends to restate head tokens and mimic tautological triples\"}, {\"Head\": \"We attribute the difference in factuality and validity of triples to the usage of semantic relation embeddings\", \"Relation\": \"because\", \"Tail\": \"embeddings move predictions toward ontology-aligned ones\"}, {\"Head\": \"Triple-level error analysis shows GraphMERT may extract incomplete and vague but often domain-appropriate tails\", \"Relation\": \"at the same time\", \"Tail\": \"LLMs usually produce diverse tails but frequently misuse or reverse the direction of relations\"}, {\"Head\": \"Our graph-level evaluation may conflate the KG signal with backbone model knowledge under GraphRAG\", \"Relation\": \"because\", \"Tail\": \"GraphRAG blends KG information with model knowledge and does not isolate KG contribution\"}, {\"Head\": \"Future work will include graph-level metrics that isolate the contribution of KGs\", \"Relation\": \"after\", \"Tail\": \"we address the current conflation caused by GraphRAG\"}, {\"Head\": \"The main limitation of GraphMERT is its reliance on the seed KG\", \"Relation\": \"because\", \"Tail\": \"running the framework requires a high-quality seed with 100-1000 examples per relation\"}, {\"Head\": \"Once training is complete, the relation set is fixed\", \"Relation\": \"as a result\", \"Tail\": \"adding new relations requires retraining\"}, {\"Head\": \"GraphMERT depends on a helper LLM for tail combination\", \"Relation\": \"as a result\", \"Tail\": \"this introduces occasional incompleteness in the extracted triple tails\"}, {\"Head\": \"GraphMERT tends to prioritize frequent entities\", \"Relation\": \"as a result\", \"Tail\": \"it can potentially overlook rare but meaningful entities\"}, {\"Head\": \"We plan to extend GraphMERT to direct multi-token span prediction in the semantic space\", \"Relation\": \"because\", \"Tail\": \"this will reduce reliance on the helper LLM for tail token combining\"}, {\"Head\": \"We plan to conduct more rigorous graph-level evaluations\", \"Relation\": \"because\", \"Tail\": \"GraphRAG often blends KG information with model knowledge and may not retrieve the most relevant subgraph\"}]"}
{"id": "1", "original_text": "raham Neubig. Better synthetic data by retrieving and transforming existing datasets, August 2024. In Findings of the Association for Computational Linguistics: ACL 2024 . - Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. Retrieval-augmented generation for large language models: A survey, 2024. arXiv:2312.10997 [cs.CL]. - Artur d'Avila Garcez and Luís C. Lamb. Neurosymbolic AI: The 3rd wave. Artificial Intelligence Review , 56(11):12387-12406, March 2023. ISSN 0269-2821. doi: 10.1007/s10462-023-10448-w. - Andrés García-Silva, Cristian Berrío, and Jose Manuel Gómez-Pérez. Textual entailment for effective triple validation in object prediction, 2023. In The Semantic Web - ISWC 2023 . - R. Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah Tang, and Jenny Huang. Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from?, 2020. In Proceedings of the Conference on Fairness, Accountability, and Transparency . - Hatem Ghanem and Carlos Cruz. Fine-tuning or prompting on LLMs: Evaluating knowledge graph construction task. Frontiers in Big Data , 8:1505877, June 2025. doi: 10.3389/fdata.2025.1505877. - Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, and Arijit Khan. Logical consistency of large language models in fact-checking, 2025. In Proceedings of the Thirteenth International Conference on Learning Representations . - Rajan Gupta, Gaurav Pandey, and Saibal Kumar Pal. Automating government report generation: A generative AI approach for efficient data extraction, analysis, and visualization. Digital Government: Research and Practice , 6(1), February 2025. doi: 10.1145/3691352. - Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, and Richard Johansson. The effect of scaling, retrieval augmentation and form on the factual consistency of language models, December 2023. In Proceedings of the Conference on Empirical Methods in Natural Language Processing . - Stevan Harnad. The symbol grounding problem. Physica D: Nonlinear Phenomena , 42(1):335-346, 1990. ISSN 0167-2789. doi: 10.1016/0167-2789(90)90087-6. John Haugeland. Artificial Intelligence: The Very Idea . 1985. Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (GELUs), 2023. arXiv:1606.08415 [cs.LG]. - Pascal Hitzler, Aaron Eberhart, Monireh Ebrahimi, Md Kamruzzaman Sarker, and Lu Zhou. Neuro-symbolic approaches in artificial intelligence. National Science Review , 9(6):nwac035, 2022. ISSN 2095-5138. doi: 10.1093/nsr/nwac035. - Marvin Hofer, Daniel Obraczka, Alieh Saeedi, Hanna Köpcke, and Erhard Rahm. Construction of knowledge graphs: Current state and challenges. Information , 15(8), 2024. ISSN 2078-2489. doi: 10.3390/info15080509. - Jiri Hron, Laura A. Culp, Gamaleldin Fathy Elsayed, Rosanne Liu, Jasper Snoek, Simon Kornblith, Alex Rizkowsky, Isabelle Simpson, Jascha Sohl-Dickstein, Noah Fiedel, Aaron T. Parisi, Alexander A. Alemi, Azade Nova, Ben Adlam, Bernd Bohnet, Gaurav Mishra, Hanie Sedghi, Izzeddin Gur, Jaehoon Lee, John D. Co-Reyes, Kathleen Kenealy, Kelvin Xu, Kevin Swersky, Igor Mordatch, Lechao Xiao, Maxwell Bileschi, Peter J. Liu, Roman Novak, Sharad Vikram, Tris Warkentin, and Jeffrey Pennington. Training language models on the knowledge graph: Insights on hallucinations and their detectability, 2024. In Proceedings of the First Conference on Language Modeling . - Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models, 2022. In Proceedings of the International Conference on Learning Representations . - Haoyu Huang, Chong Chen, Zeang Sheng, Yang Li, and Wentao Zhang. Can LLMs be good graph judge for knowledge graph construction?, 2025a. arXiv:2411.17388 [cs.CL]. - Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems , 43(2):1-55, January 2025b. ISSN 1558-2868. doi: 10.1145/3703155. - N. Ibrahim, S. Aboulela, A. Ibrahim, et al. A survey on augmenting knowledge graphs (KGs) with large language models (LLMs): Models, evaluation metrics, benchmarks, and challenges. Discover Artificial Intelligence , 4(1):76, 2024. doi: 10.1007/s44163-024-00175-8. - Shadi Iskander, Sofia Tolmach, Ori Shapira, Nachshon Cohen, and Zohar Karnin. Quality matters: Evaluating synthetic data for tool-using LLMs, November 2024. In Proceedings of the Conference on Empirical Methods in Natural Language Processing . - Mohamed Yahya Jaradeh, Kuldeep Singh, Markus Stocker, Andreas Both, and Sören Auer. Information extraction pipelines for knowledge graphs. Knowledge and Information Systems , 65(5):1989-2016, 2023. ISSN 0219-1377. doi: 10.1007/s10115-022-01826-x. - Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and Philip S. Yu. A survey on knowledge graphs: Representation, acquisition, and applications. IEEE Transactions on Neural Networks and Learning Systems , 33(2):494-514, 2022. doi: 10.1109/TNNLS.2021.3070843. - Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys , 55(12), March 2023. ISSN 0360-0300. doi: 10.1145/3571730. - Jiajie Jin, Yutao Zhu, Yujia Zhou, and Zhicheng Dou. BIDER: Bridging knowledge inconsistency for efficient retrieval-augmented LLMs via key supporting evidence, August 2024. In Findings of the Association for Computational Linguistics: ACL 2024 . - Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. SpanBERT: Improving pre-training by representing and predicting spans. Transactions of the Association for Computational Linguistics , 8:64-77, 2020. doi: 10.1162/tacl\\_a\\_00300. - Tal Kadosh, Niranjan Hasabnis, Vy A. Vo, Nadav Schneider, Neva Krien, Mihai Capotă, Abdul Wasay, Guy Tamir, Ted Willke, Nesreen Ahmed, Yuval Pinter, Timothy Mattson, and Gal Oren. MonoCoder: Domain-specific code language model for HPC codes and tasks, 2024. In Proceedings of the IEEE High Performance Extreme Computing Conference . - Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models, 2020. arXiv:2001.08361 [cs.LG]. - Muhammad Khalifa, David Wadden, Emma Strubell, Honglak Lee, Lu Wang, Iz Beltagy, and Hao Peng. Source-aware training enables knowledge attribution in language models, 2024. arXiv:2404.01019 [cs.CL]. - Yubin Kim, Hyewon Jeong, Shan Chen, Shuyue Stella Li, Mingyu Lu, Kumail Alhamoud, Jimin Mun, Cristina Grau, Minseok Jung, Rodrigo Gameiro, Lizhou Fan, Eugene Park, Tristan Lin, Joonsik Yoon, Wonjin Yoon, Maarten Sap, Yulia Tsvetkov, Paul Liang, Xuhai Xu, Xin Liu, Daniel McDuff, Hyeonhoon Lee, Hae Won Park, Samir Tulebaev, and Cynthia Breazeal. Medical hallucinations in foundation models and their impact on healthcare, 2025. arXiv:2503.05777 [cs.CL]. - Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks, 2012. In Advances in Neural Information Processing Systems . - Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature , 521(7553):436-444, 2015. ISSN 1476-4687. doi: 10.1038/nature14539. - Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. The dawn after the dark: An empirical study on factuality hallucination in large language models, August 2024. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . - Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. BERT-ATTACK: Adversarial attack against BERT using BERT, November 2020. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) . - Mingchen Li, Halil Kilicoglu, Hua Xu, and Rui Zhang. BiomedRAG: A retrieval augmented large language model for biomedicine. Journal of Biomedical Informatics , 162:104769, 2025. ISSN 1532-0464. doi: 10.1016/j.jbi.2024.104769. - Seunguook Lim and Jihie Kim. SapBERT: Speaker-aware pretrained BERT for emotion recognition in conversation. Algorithms , 16(1):8, 2022. - Robert K. Lindsay, Bruce G. Buchanan, Edward A. Feigenbaum, and Joshua Lederberg. DENDRAL: A case study of the first expert system for scientific hypothesis formation. Artificial Intelligence , 61(2):209-261, 1993. ISSN 0004-3702. doi: 10.1016/0004-3702(93)90068-M. - Chuang Liu, Zelin Yao, Yibing Zhan, Xueqi Ma, Shirui Pan, and Wenbin Hu. Gradformer: Graph transformer with exponential decay, 2024a. In Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence . - Y. Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, M. Lewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pretraining approach, 2019. arXiv:1907.11692 [cs.CL]. - Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, and Lianwen Jin. Datasets for large language models: A comprehensive survey, 2024b. arXiv:2402.18041 [cs.CL]. - Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, Martin Ringsquandl, Rime Raissouni, and Volker Tresp. Neural multi-hop reasoning with logical rules on biomedical knowledge graphs, 2021. In The Semantic Web . - Xinyu Lu, Lifang Wang, Zejun Jiang, Shizhong Liu, and Jiashi Lin. MRE: A translational knowledge graph completion model based on multiple relation embedding. Mathematical Biosciences and Engineering , 20 (3):5881-5900, 2023. ISSN 1551-0018. doi: 10.3934/mbe.2023253. - Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. Reasoning on graphs: Faithful and interpretable large language model reasoning, 2024. In Proceedings of the International Conference on Learning Representations . - Andreas Madsen, Sarath Chandar, and Siva Reddy. Are self-explanations from large language models faithful?, August 2024. In Findings of the Association for Computational Linguistics: ACL 2024 . - Gary Marcus. Deep learning: A critical appraisal, 2018. arXiv:1801.00631 [cs.AI]. - John McCarthy. Circumscription-a form of non-monotonic reasoning. Artificial Intelligence , 13(1):27-39, 1980. ISSN 0004-3702. doi: 10.1016/0004-3702(80)90011-9. Special Issue on Non-Monotonic Logic. - Dhruv Mehrotra and Tim Marchman. Perplexity is a bullshit machine, 2024. URL https://www.wired. com/story/perplexity-is-a-bullshit-machine/ . WIRED , investigation documenting data scraping and multiple hallucinations/misattributions. - Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-Tau Yih, Pang Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. FActScore: Fine-grained atomic evaluation of factual precision in long form text generation, December 2023. In Proceedings of the Conference on Empirical Methods in Natural Language Processing . - Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao. Large language models: A survey, 2025. arXiv:2402.06196 [cs.CL]. - Prakamya Mishra, Zonghai Yao, Parth Vashisht, Feiyun Ouyang, Beining Wang, Vidhi Dhaval Mody, and Hong Yu. SYNFAC-EDIT: Synthetic imitation edit feedback for factual alignment in clinical summarization, November 2024. In Proceedings of the Conference on Empirical Methods in Natural Language Processing . - Seyed Mahed Mousavi, Simone Alghisi, and Giuseppe Riccardi. DyKnow: Dynamically verifying timesensitive factual knowledge in LLMs, November 2024. In Findings of the Association for Computational Linguistics: EMNLP 2024 . - Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. WebGPT: Browserassisted question-answering with human feedback, 2022. arXiv:2112.09332 [cs.CL]. - Deepak Nathani, Jatin Chauhan, Charu Sharma, and Manohar Kaul. Learning attention-based embeddings for relation prediction in knowledge graphs, 2019. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics . - Allen Newell and Herbert A. Simon. Computer science as empirical inquiry: Symbols and search. Communications of the ACM , 19(3):113-126, March 1976. ISSN 0001-0782. doi: 10.1145/360018.360022. - Thuat Nguyen, Chien Van Nguyen, Viet Dac Lai, Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Ryan A. Rossi, and Thien Huu Nguyen. CulturaX: A cleaned, enormous, and multilingual dataset for large language models in 167 languages, May 2024. In Proceedings of the Joint International Conference on Computational Linguistics, Language Resources and Evaluation . - Jeff Z. Pan, Simon Razniewski, Jan-Christoph Kalo, Sneha Singhania, Jiaoyan Chen, Stefan Dietze, Hajira Jabeen, Janna Omeliyanenko, Wen Zhang, Matteo Lissandrini, Russa Biswas, Gerard de Melo, Angela Bonifati, Edlira Vakaj, Mauro Dragoni, and Damien Graux. Large language models and knowledge graphs: Opportunities and challenges. Transactions on Graph Data and Knowledge , 1(1):2:1-2:38, 2023a. doi: 10.4230/TGDK.1.1.2. - Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. Unifying large language models and knowledge graphs: A roadmap. IEEE Transactions on Knowledge a", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "Yunfan Gao et al.", "Relation": "authored", "Tail": "Retrieval-augmented generation for large language models: A survey"}, {"Head": "Artur d'Avila Garcez and Luís C. Lamb", "Relation": "authored", "Tail": "Neurosymbolic AI: The 3rd wave"}, {"Head": "Andrés García-Silva et al.", "Relation": "proposed", "Tail": "Textual entailment for effective triple validation in object prediction"}, {"Head": "R. Stuart Geiger et al.", "Relation": "investigated", "Tail": "reporting of human-labeled training data provenance in machine learning papers"}, {"Head": "Hatem Ghanem and Carlos Cruz", "Relation": "evaluated", "Tail": "Fine-tuning or prompting on LLMs for knowledge graph construction"}, {"Head": "Bishwamittra Ghosh et al.", "Relation": "studied", "Tail": "logical consistency of large language models in fact-checking"}, {"Head": "Rajan Gupta et al.", "Relation": "developed", "Tail": "generative AI approach for automating government report generation"}, {"Head": "Lovisa Hagström et al.", "Relation": "examined", "Tail": "effect of scaling, retrieval augmentation and form on factual consistency of language models"}, {"Head": "Stevan Harnad", "Relation": "introduced", "Tail": "The symbol grounding problem"}, {"Head": "Pascal Hitzler et al.", "Relation": "surveyed", "Tail": "neuro-symbolic approaches in artificial intelligence"}, {"Head": "Marvin Hofer et al.", "Relation": "reviewed", "Tail": "construction of knowledge graphs: current state and challenges"}, {"Head": "Jiri Hron et al.", "Relation": "investigated", "Tail": "training language models on the knowledge graph and hallucination detectability"}, {"Head": "Edward J. Hu et al.", "Relation": "proposed", "Tail": "LoRA: Low-rank adaptation of large language models"}, {"Head": "Haoyu Huang et al.", "Relation": "asked", "Tail": "Can LLMs be good graph judge for knowledge graph construction?"}, {"Head": "Lei Huang et al.", "Relation": "surveyed", "Tail": "hallucination in large language models: principles, taxonomy, challenges"}, {"Head": "N. Ibrahim et al.", "Relation": "surveyed", "Tail": "augmenting knowledge graphs with large language models"}, {"Head": "Shadi Iskander et al.", "Relation": "evaluated", "Tail": "synthetic data quality for tool-using LLMs"}, {"Head": "Mohamed Yahya Jaradeh et al.", "Relation": "reviewed", "Tail": "information extraction pipelines for knowledge graphs"}, {"Head": "Shaoxiong Ji et al.", "Relation": "surveyed", "Tail": "knowledge graphs: representation, acquisition, and applications"}, {"Head": "Jiajie Jin et al.", "Relation": "proposed", "Tail": "BIDER: Bridging knowledge inconsistency for retrieval-augmented LLMs"}, {"Head": "Mandar Joshi et al.", "Relation": "introduced", "Tail": "SpanBERT: improving pre-training by representing and predicting spans"}, {"Head": "Tal Kadosh et al.", "Relation": "developed", "Tail": "MonoCoder: domain-specific code language model for HPC codes and tasks"}, {"Head": "Jared Kaplan et al.", "Relation": "formulated", "Tail": "scaling laws for neural language models"}, {"Head": "Muhammad Khalifa et al.", "Relation": "proposed", "Tail": "source-aware training for knowledge attribution in language models"}, {"Head": "Yubin Kim et al.", "Relation": "studied", "Tail": "medical hallucinations in foundation models and their impact on healthcare"}, {"Head": "Alex Krizhevsky et al.", "Relation": "introduced", "Tail": "ImageNet classification with deep convolutional neural networks"}, {"Head": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton", "Relation": "surveyed", "Tail": "deep learning"}, {"Head": "Junyi Li et al.", "Relation": "empirically studied", "Tail": "factuality hallucination in large language models"}, {"Head": "Linhao Luo et al.", "Relation": "proposed", "Tail": "faithful and interpretable large language model reasoning on graphs"}, {"Head": "Andreas Madsen et al.", "Relation": "questioned", "Tail": "faithfulness of self-explanations from large language models"}, {"Head": "John McCarthy", "Relation": "introduced", "Tail": "Circumscription as a form of non-monotonic reasoning"}, {"Head": "Dhruv Mehrotra and Tim Marchman", "Relation": "reported", "Tail": "critical investigation of data scraping and hallucinations in Perplexity (WIRED)"}, {"Head": "Sewon Min et al.", "Relation": "proposed", "Tail": "FActScore: fine-grained atomic evaluation of factual precision"}, {"Head": "Prakamya Mishra et al.", "Relation": "introduced", "Tail": "SYNFAC-EDIT: synthetic imitation edit feedback for factual alignment in clinical summarization"}, {"Head": "Seyed Mahed Mousavi et al.", "Relation": "proposed", "Tail": "DyKnow: dynamically verifying time-sensitive factual knowledge in LLMs"}, {"Head": "Reiichiro Nakano et al.", "Relation": "developed", "Tail": "WebGPT: browser-assisted question-answering with human feedback"}, {"Head": "Deepak Nathani et al.", "Relation": "studied", "Tail": "attention-based embeddings for relation prediction in knowledge graphs"}, {"Head": "Thuat Nguyen et al.", "Relation": "released", "Tail": "CulturaX: cleaned multilingual dataset for LLMs in 167 languages"}, {"Head": "Jeff Z. Pan et al.", "Relation": "reviewed", "Tail": "opportunities and challenges at the intersection of large language models and knowledge graphs"}, {"Head": "Chuang Liu et al.", "Relation": "proposed", "Tail": "Gradformer: graph transformer with exponential decay"}, {"Head": "Y. Liu et al.", "Relation": "introduced", "Tail": "RoBERTa: a robustly optimized BERT pretraining approach"}, {"Head": "Yang Liu et al.", "Relation": "surveyed", "Tail": "datasets for large language models"}, {"Head": "Yushan Liu et al.", "Relation": "proposed", "Tail": "neural multi-hop reasoning with logical rules on biomedical knowledge graphs"}, {"Head": "Xinyu Lu et al.", "Relation": "proposed", "Tail": "MRE: translational knowledge graph completion model based on multiple relation embedding"}, {"Head": "Gary Marcus", "Relation": "critiqued", "Tail": "deep learning in a critical appraisal"}], "entity_relation_output": "[{\"Head\": \"Yunfan Gao et al.\", \"Relation\": \"authored\", \"Tail\": \"Retrieval-augmented generation for large language models: A survey\"}, {\"Head\": \"Artur d'Avila Garcez and Luís C. Lamb\", \"Relation\": \"authored\", \"Tail\": \"Neurosymbolic AI: The 3rd wave\"}, {\"Head\": \"Andrés García-Silva et al.\", \"Relation\": \"proposed\", \"Tail\": \"Textual entailment for effective triple validation in object prediction\"}, {\"Head\": \"R. Stuart Geiger et al.\", \"Relation\": \"investigated\", \"Tail\": \"reporting of human-labeled training data provenance in machine learning papers\"}, {\"Head\": \"Hatem Ghanem and Carlos Cruz\", \"Relation\": \"evaluated\", \"Tail\": \"Fine-tuning or prompting on LLMs for knowledge graph construction\"}, {\"Head\": \"Bishwamittra Ghosh et al.\", \"Relation\": \"studied\", \"Tail\": \"logical consistency of large language models in fact-checking\"}, {\"Head\": \"Rajan Gupta et al.\", \"Relation\": \"developed\", \"Tail\": \"generative AI approach for automating government report generation\"}, {\"Head\": \"Lovisa Hagström et al.\", \"Relation\": \"examined\", \"Tail\": \"effect of scaling, retrieval augmentation and form on factual consistency of language models\"}, {\"Head\": \"Stevan Harnad\", \"Relation\": \"introduced\", \"Tail\": \"The symbol grounding problem\"}, {\"Head\": \"Pascal Hitzler et al.\", \"Relation\": \"surveyed\", \"Tail\": \"neuro-symbolic approaches in artificial intelligence\"}, {\"Head\": \"Marvin Hofer et al.\", \"Relation\": \"reviewed\", \"Tail\": \"construction of knowledge graphs: current state and challenges\"}, {\"Head\": \"Jiri Hron et al.\", \"Relation\": \"investigated\", \"Tail\": \"training language models on the knowledge graph and hallucination detectability\"}, {\"Head\": \"Edward J. Hu et al.\", \"Relation\": \"proposed\", \"Tail\": \"LoRA: Low-rank adaptation of large language models\"}, {\"Head\": \"Haoyu Huang et al.\", \"Relation\": \"asked\", \"Tail\": \"Can LLMs be good graph judge for knowledge graph construction?\"}, {\"Head\": \"Lei Huang et al.\", \"Relation\": \"surveyed\", \"Tail\": \"hallucination in large language models: principles, taxonomy, challenges\"}, {\"Head\": \"N. Ibrahim et al.\", \"Relation\": \"surveyed\", \"Tail\": \"augmenting knowledge graphs with large language models\"}, {\"Head\": \"Shadi Iskander et al.\", \"Relation\": \"evaluated\", \"Tail\": \"synthetic data quality for tool-using LLMs\"}, {\"Head\": \"Mohamed Yahya Jaradeh et al.\", \"Relation\": \"reviewed\", \"Tail\": \"information extraction pipelines for knowledge graphs\"}, {\"Head\": \"Shaoxiong Ji et al.\", \"Relation\": \"surveyed\", \"Tail\": \"knowledge graphs: representation, acquisition, and applications\"}, {\"Head\": \"Jiajie Jin et al.\", \"Relation\": \"proposed\", \"Tail\": \"BIDER: Bridging knowledge inconsistency for retrieval-augmented LLMs\"}, {\"Head\": \"Mandar Joshi et al.\", \"Relation\": \"introduced\", \"Tail\": \"SpanBERT: improving pre-training by representing and predicting spans\"}, {\"Head\": \"Tal Kadosh et al.\", \"Relation\": \"developed\", \"Tail\": \"MonoCoder: domain-specific code language model for HPC codes and tasks\"}, {\"Head\": \"Jared Kaplan et al.\", \"Relation\": \"formulated\", \"Tail\": \"scaling laws for neural language models\"}, {\"Head\": \"Muhammad Khalifa et al.\", \"Relation\": \"proposed\", \"Tail\": \"source-aware training for knowledge attribution in language models\"}, {\"Head\": \"Yubin Kim et al.\", \"Relation\": \"studied\", \"Tail\": \"medical hallucinations in foundation models and their impact on healthcare\"}, {\"Head\": \"Alex Krizhevsky et al.\", \"Relation\": \"introduced\", \"Tail\": \"ImageNet classification with deep convolutional neural networks\"}, {\"Head\": \"Yann LeCun, Yoshua Bengio, and Geoffrey Hinton\", \"Relation\": \"surveyed\", \"Tail\": \"deep learning\"}, {\"Head\": \"Junyi Li et al.\", \"Relation\": \"empirically studied\", \"Tail\": \"factuality hallucination in large language models\"}, {\"Head\": \"Linhao Luo et al.\", \"Relation\": \"proposed\", \"Tail\": \"faithful and interpretable large language model reasoning on graphs\"}, {\"Head\": \"Andreas Madsen et al.\", \"Relation\": \"questioned\", \"Tail\": \"faithfulness of self-explanations from large language models\"}, {\"Head\": \"John McCarthy\", \"Relation\": \"introduced\", \"Tail\": \"Circumscription as a form of non-monotonic reasoning\"}, {\"Head\": \"Dhruv Mehrotra and Tim Marchman\", \"Relation\": \"reported\", \"Tail\": \"critical investigation of data scraping and hallucinations in Perplexity (WIRED)\"}, {\"Head\": \"Sewon Min et al.\", \"Relation\": \"proposed\", \"Tail\": \"FActScore: fine-grained atomic evaluation of factual precision\"}, {\"Head\": \"Prakamya Mishra et al.\", \"Relation\": \"introduced\", \"Tail\": \"SYNFAC-EDIT: synthetic imitation edit feedback for factual alignment in clinical summarization\"}, {\"Head\": \"Seyed Mahed Mousavi et al.\", \"Relation\": \"proposed\", \"Tail\": \"DyKnow: dynamically verifying time-sensitive factual knowledge in LLMs\"}, {\"Head\": \"Reiichiro Nakano et al.\", \"Relation\": \"developed\", \"Tail\": \"WebGPT: browser-assisted question-answering with human feedback\"}, {\"Head\": \"Deepak Nathani et al.\", \"Relation\": \"studied\", \"Tail\": \"attention-based embeddings for relation prediction in knowledge graphs\"}, {\"Head\": \"Thuat Nguyen et al.\", \"Relation\": \"released\", \"Tail\": \"CulturaX: cleaned multilingual dataset for LLMs in 167 languages\"}, {\"Head\": \"Jeff Z. Pan et al.\", \"Relation\": \"reviewed\", \"Tail\": \"opportunities and challenges at the intersection of large language models and knowledge graphs\"}, {\"Head\": \"Chuang Liu et al.\", \"Relation\": \"proposed\", \"Tail\": \"Gradformer: graph transformer with exponential decay\"}, {\"Head\": \"Y. Liu et al.\", \"Relation\": \"introduced\", \"Tail\": \"RoBERTa: a robustly optimized BERT pretraining approach\"}, {\"Head\": \"Yang Liu et al.\", \"Relation\": \"surveyed\", \"Tail\": \"datasets for large language models\"}, {\"Head\": \"Yushan Liu et al.\", \"Relation\": \"proposed\", \"Tail\": \"neural multi-hop reasoning with logical rules on biomedical knowledge graphs\"}, {\"Head\": \"Xinyu Lu et al.\", \"Relation\": \"proposed\", \"Tail\": \"MRE: translational knowledge graph completion model based on multiple relation embedding\"}, {\"Head\": \"Gary Marcus\", \"Relation\": \"critiqued\", \"Tail\": \"deep learning in a critical appraisal\"}]", "event_entity_dict": [{"Event": "Raham Neubig. Better synthetic data by retrieving and transforming existing datasets, August 2024.", "Entity": ["Raham Neubig"]}, {"Event": "In Findings of the Association for Computational Linguistics: ACL 2024.", "Entity": ["Findings of the Association for Computational Linguistics", "ACL 2024"]}, {"Event": "Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. Retrieval-augmented generation for large language models: A survey, 2024.", "Entity": ["Yunfan Gao", "Yun Xiong", "Xinyu Gao", "Kangxiang Jia", "Jinliu Pan", "Yuxi Bi", "Yi Dai", "Jiawei Sun", "Meng Wang", "Haofen Wang"]}, {"Event": "arXiv:2312.10997 [cs.CL].", "Entity": ["arXiv:2312.10997", "cs.CL"]}, {"Event": "Artur d'Avila Garcez and Luís C. Lamb. Neurosymbolic AI: The 3rd wave.", "Entity": ["Artur d'Avila Garcez", "Luís C. Lamb"]}, {"Event": "Artificial Intelligence Review, 56(11):12387-12406, March 2023.", "Entity": ["Artificial Intelligence Review"]}, {"Event": "Andrés García-Silva, Cristian Berrío, and Jose Manuel Gómez-Pérez. Textual entailment for effective triple validation in object prediction, 2023.", "Entity": ["Andrés García-Silva", "Cristian Berrío", "Jose Manuel Gómez-Pérez"]}, {"Event": "In The Semantic Web - ISWC 2023.", "Entity": ["The Semantic Web", "ISWC 2023"]}, {"Event": "R. Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah Tang, and Jenny Huang. Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from?, 2020.", "Entity": ["R. Stuart Geiger", "Kevin Yu", "Yanlai Yang", "Mindy Dai", "Jie Qiu", "Rebekah Tang", "Jenny Huang"]}, {"Event": "In Proceedings of the Conference on Fairness, Accountability, and Transparency.", "Entity": ["Proceedings of the Conference on Fairness, Accountability, and Transparency"]}, {"Event": "Hatem Ghanem and Carlos Cruz. Fine-tuning or prompting on LLMs: Evaluating knowledge graph construction task.", "Entity": ["Hatem Ghanem", "Carlos Cruz"]}, {"Event": "Frontiers in Big Data, 8:1505877, June 2025.", "Entity": ["Frontiers in Big Data"]}, {"Event": "Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, and Arijit Khan. Logical consistency of large language models in fact-checking, 2025.", "Entity": ["Bishwamittra Ghosh", "Sarah Hasan", "Naheed Anjum Arafat", "Arijit Khan"]}, {"Event": "In Proceedings of the Thirteenth International Conference on Learning Representations.", "Entity": ["Proceedings of the Thirteenth International Conference on Learning Representations"]}, {"Event": "Rajan Gupta, Gaurav Pandey, and Saibal Kumar Pal. Automating government report generation: A generative AI approach for efficient data extraction, analysis, and visualization.", "Entity": ["Rajan Gupta", "Gaurav Pandey", "Saibal Kumar Pal"]}, {"Event": "Digital Government: Research and Practice, 6(1), February 2025.", "Entity": ["Digital Government: Research and Practice"]}, {"Event": "Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, and Richard Johansson. The effect of scaling, retrieval augmentation and form on the factual consistency of language models, December 2023.", "Entity": ["Lovisa Hagström", "Denitsa Saynova", "Tobias Norlund", "Moa Johansson", "Richard Johansson"]}, {"Event": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "Entity": ["Proceedings of the Conference on Empirical Methods in Natural Language Processing"]}, {"Event": "Stevan Harnad. The symbol grounding problem.", "Entity": ["Stevan Harnad"]}, {"Event": "Physica D: Nonlinear Phenomena, 42(1):335-346, 1990.", "Entity": ["Physica D: Nonlinear Phenomena"]}, {"Event": "John Haugeland. Artificial Intelligence: The Very Idea.", "Entity": ["John Haugeland"]}, {"Event": "Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (GELUs), 2023.", "Entity": ["Dan Hendrycks", "Kevin Gimpel"]}, {"Event": "arXiv:1606.08415 [cs.LG].", "Entity": ["arXiv:1606.08415", "cs.LG"]}, {"Event": "Pascal Hitzler, Aaron Eberhart, Monireh Ebrahimi, Md Kamruzzaman Sarker, and Lu Zhou. Neuro-symbolic approaches in artificial intelligence.", "Entity": ["Pascal Hitzler", "Aaron Eberhart", "Monireh Ebrahimi", "Md Kamruzzaman Sarker", "Lu Zhou"]}, {"Event": "National Science Review, 9(6):nwac035, 2022.", "Entity": ["National Science Review"]}, {"Event": "Marvin Hofer, Daniel Obraczka, Alieh Saeedi, Hanna Köpcke, and Erhard Rahm. Construction of knowledge graphs: Current state and challenges.", "Entity": ["Marvin Hofer", "Daniel Obraczka", "Alieh Saeedi", "Hanna Köpcke", "Erhard Rahm"]}, {"Event": "Information, 15(8), 2024.", "Entity": ["Information"]}, {"Event": "Jiri Hron, Laura A. Culp, Gamaleldin Fathy Elsayed, Rosanne Liu, Jasper Snoek, Simon Kornblith, Alex Rizkowsky, Isabelle Simpson, Jascha Sohl-Dickstein, Noah Fiedel, Aaron T. Parisi, Alexander A. Alemi, Azade Nova, Ben Adlam, Bernd Bohnet, Gaurav Mishra, Hanie Sedghi, Izzeddin Gur, Jaehoon Lee, John D. Co-Reyes, Kathleen Kenealy, Kelvin Xu, Kevin Swersky, Igor Mordatch, Lechao Xiao, Maxwell Bileschi, Peter J. Liu, Roman Novak, Sharad Vikram, Tris Warkentin, and Jeffrey Pennington. Training language models on the knowledge graph: Insights on hallucinations and their detectability, 2024.", "Entity": ["Jiri Hron", "Laura A. Culp", "Gamaleldin Fathy Elsayed", "Rosanne Liu", "Jasper Snoek", "Simon Kornblith", "Alex Rizkowsky", "Isabelle Simpson", "Jascha Sohl-Dickstein", "Noah Fiedel", "Aaron T. Parisi", "Alexander A. Alemi", "Azade Nova", "Ben Adlam", "Bernd Bohnet", "Gaurav Mishra", "Hanie Sedghi", "Izzeddin Gur", "Jaehoon Lee", "John D. Co-Reyes", "Kathleen Kenealy", "Kelvin Xu", "Kevin Swersky", "Igor Mordatch", "Lechao Xiao", "Maxwell Bileschi", "Peter J. Liu", "Roman Novak", "Sharad Vikram", "Tris Warkentin", "Jeffrey Pennington"]}], "event_entity_output": "[{\"Event\": \"Raham Neubig. Better synthetic data by retrieving and transforming existing datasets, August 2024.\", \"Entity\": [\"Raham Neubig\"]}, {\"Event\": \"In Findings of the Association for Computational Linguistics: ACL 2024.\", \"Entity\": [\"Findings of the Association for Computational Linguistics\", \"ACL 2024\"]}, {\"Event\": \"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. Retrieval-augmented generation for large language models: A survey, 2024.\", \"Entity\": [\"Yunfan Gao\", \"Yun Xiong\", \"Xinyu Gao\", \"Kangxiang Jia\", \"Jinliu Pan\", \"Yuxi Bi\", \"Yi Dai\", \"Jiawei Sun\", \"Meng Wang\", \"Haofen Wang\"]}, {\"Event\": \"arXiv:2312.10997 [cs.CL].\", \"Entity\": [\"arXiv:2312.10997\", \"cs.CL\"]}, {\"Event\": \"Artur d'Avila Garcez and Luís C. Lamb. Neurosymbolic AI: The 3rd wave.\", \"Entity\": [\"Artur d'Avila Garcez\", \"Luís C. Lamb\"]}, {\"Event\": \"Artificial Intelligence Review, 56(11):12387-12406, March 2023.\", \"Entity\": [\"Artificial Intelligence Review\"]}, {\"Event\": \"Andrés García-Silva, Cristian Berrío, and Jose Manuel Gómez-Pérez. Textual entailment for effective triple validation in object prediction, 2023.\", \"Entity\": [\"Andrés García-Silva\", \"Cristian Berrío\", \"Jose Manuel Gómez-Pérez\"]}, {\"Event\": \"In The Semantic Web - ISWC 2023.\", \"Entity\": [\"The Semantic Web\", \"ISWC 2023\"]}, {\"Event\": \"R. Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah Tang, and Jenny Huang. Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from?, 2020.\", \"Entity\": [\"R. Stuart Geiger\", \"Kevin Yu\", \"Yanlai Yang\", \"Mindy Dai\", \"Jie Qiu\", \"Rebekah Tang\", \"Jenny Huang\"]}, {\"Event\": \"In Proceedings of the Conference on Fairness, Accountability, and Transparency.\", \"Entity\": [\"Proceedings of the Conference on Fairness, Accountability, and Transparency\"]}, {\"Event\": \"Hatem Ghanem and Carlos Cruz. Fine-tuning or prompting on LLMs: Evaluating knowledge graph construction task.\", \"Entity\": [\"Hatem Ghanem\", \"Carlos Cruz\"]}, {\"Event\": \"Frontiers in Big Data, 8:1505877, June 2025.\", \"Entity\": [\"Frontiers in Big Data\"]}, {\"Event\": \"Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, and Arijit Khan. Logical consistency of large language models in fact-checking, 2025.\", \"Entity\": [\"Bishwamittra Ghosh\", \"Sarah Hasan\", \"Naheed Anjum Arafat\", \"Arijit Khan\"]}, {\"Event\": \"In Proceedings of the Thirteenth International Conference on Learning Representations.\", \"Entity\": [\"Proceedings of the Thirteenth International Conference on Learning Representations\"]}, {\"Event\": \"Rajan Gupta, Gaurav Pandey, and Saibal Kumar Pal. Automating government report generation: A generative AI approach for efficient data extraction, analysis, and visualization.\", \"Entity\": [\"Rajan Gupta\", \"Gaurav Pandey\", \"Saibal Kumar Pal\"]}, {\"Event\": \"Digital Government: Research and Practice, 6(1), February 2025.\", \"Entity\": [\"Digital Government: Research and Practice\"]}, {\"Event\": \"Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, and Richard Johansson. The effect of scaling, retrieval augmentation and form on the factual consistency of language models, December 2023.\", \"Entity\": [\"Lovisa Hagström\", \"Denitsa Saynova\", \"Tobias Norlund\", \"Moa Johansson\", \"Richard Johansson\"]}, {\"Event\": \"In Proceedings of the Conference on Empirical Methods in Natural Language Processing.\", \"Entity\": [\"Proceedings of the Conference on Empirical Methods in Natural Language Processing\"]}, {\"Event\": \"Stevan Harnad. The symbol grounding problem.\", \"Entity\": [\"Stevan Harnad\"]}, {\"Event\": \"Physica D: Nonlinear Phenomena, 42(1):335-346, 1990.\", \"Entity\": [\"Physica D: Nonlinear Phenomena\"]}, {\"Event\": \"John Haugeland. Artificial Intelligence: The Very Idea.\", \"Entity\": [\"John Haugeland\"]}, {\"Event\": \"Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (GELUs), 2023.\", \"Entity\": [\"Dan Hendrycks\", \"Kevin Gimpel\"]}, {\"Event\": \"arXiv:1606.08415 [cs.LG].\", \"Entity\": [\"arXiv:1606.08415\", \"cs.LG\"]}, {\"Event\": \"Pascal Hitzler, Aaron Eberhart, Monireh Ebrahimi, Md Kamruzzaman Sarker, and Lu Zhou. Neuro-symbolic approaches in artificial intelligence.\", \"Entity\": [\"Pascal Hitzler\", \"Aaron Eberhart\", \"Monireh Ebrahimi\", \"Md Kamruzzaman Sarker\", \"Lu Zhou\"]}, {\"Event\": \"National Science Review, 9(6):nwac035, 2022.\", \"Entity\": [\"National Science Review\"]}, {\"Event\": \"Marvin Hofer, Daniel Obraczka, Alieh Saeedi, Hanna Köpcke, and Erhard Rahm. Construction of knowledge graphs: Current state and challenges.\", \"Entity\": [\"Marvin Hofer\", \"Daniel Obraczka\", \"Alieh Saeedi\", \"Hanna Köpcke\", \"Erhard Rahm\"]}, {\"Event\": \"Information, 15(8), 2024.\", \"Entity\": [\"Information\"]}, {\"Event\": \"Jiri Hron, Laura A. Culp, Gamaleldin Fathy Elsayed, Rosanne Liu, Jasper Snoek, Simon Kornblith, Alex Rizkowsky, Isabelle Simpson, Jascha Sohl-Dickstein, Noah Fiedel, Aaron T. Parisi, Alexander A. Alemi, Azade Nova, Ben Adlam, Bernd Bohnet, Gaurav Mishra, Hanie Sedghi, Izzeddin Gur, Jaehoon Lee, John D. Co-Reyes, Kathleen Kenealy, Kelvin Xu, Kevin Swersky, Igor Mordatch, Lechao Xiao, Maxwell Bileschi, Peter J. Liu, Roman Novak, Sharad Vikram, Tris Warkentin, and Jeffrey Pennington. Training language models on the knowledge graph: Insights on hallucinations and their detectability, 2024.\", \"Entity\": [\"Jiri Hron\", \"Laura A. Culp\", \"Gamaleldin Fathy Elsayed\", \"Rosanne Liu\", \"Jasper Snoek\", \"Simon Kornblith\", \"Alex Rizkowsky\", \"Isabelle Simpson\", \"Jascha Sohl-Dickstein\", \"Noah Fiedel\", \"Aaron T. Parisi\", \"Alexander A. Alemi\", \"Azade Nova\", \"Ben Adlam\", \"Bernd Bohnet\", \"Gaurav Mishra\", \"Hanie Sedghi\", \"Izzeddin Gur\", \"Jaehoon Lee\", \"John D. Co-Reyes\", \"Kathleen Kenealy\", \"Kelvin Xu\", \"Kevin Swersky\", \"Igor Mordatch\", \"Lechao Xiao\", \"Maxwell Bileschi\", \"Peter J. Liu\", \"Roman Novak\", \"Sharad Vikram\", \"Tris Warkentin\", \"Jeffrey Pennington\"]}]", "event_relation_dict": [{"Head": "John Haugeland published Artificial Intelligence: The Very Idea in 1985", "Relation": "before", "Tail": "Stevan Harnad published The symbol grounding problem in 1990"}, {"Head": "Stevan Harnad published The symbol grounding problem in 1990", "Relation": "before", "Tail": "Robert K. Lindsay and colleagues published DENDRAL: A case study of the first expert system for scientific hypothesis formation in 1993"}, {"Head": "Robert K. Lindsay and colleagues published DENDRAL: A case study of the first expert system for scientific hypothesis formation in 1993", "Relation": "before", "Tail": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton published Imagenet classification with deep convolutional neural networks in 2012"}, {"Head": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton published Imagenet classification with deep convolutional neural networks in 2012", "Relation": "before", "Tail": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton published Deep learning in Nature in 2015"}, {"Head": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton published Deep learning in Nature in 2015", "Relation": "before", "Tail": "Gary Marcus published Deep learning: A critical appraisal in 2018"}, {"Head": "Gary Marcus published Deep learning: A critical appraisal in 2018", "Relation": "before", "Tail": "Y. Liu and colleagues published RoBERTa: A robustly optimized BERT pretraining approach in 2019"}, {"Head": "Y. Liu and colleagues published RoBERTa: A robustly optimized BERT pretraining approach in 2019", "Relation": "before", "Tail": "Jared Kaplan and colleagues published Scaling laws for neural language models in 2020"}, {"Head": "Jared Kaplan and colleagues published Scaling laws for neural language models in 2020", "Relation": "before", "Tail": "Multiple surveys and empirical studies on LLMs and knowledge graphs were published in 2024"}, {"Head": "Jiri Hron and colleagues published Training language models on the knowledge graph: Insights on hallucinations and their detectability in 2024", "Relation": "at the same time", "Tail": "Jiajie Jin and colleagues published BIDER: Bridging knowledge inconsistency for efficient retrieval-augmented LLMs via key supporting evidence in August 2024"}, {"Head": "Graham Neubig published Better synthetic data by retrieving and transforming existing datasets in August 2024", "Relation": "at the same time", "Tail": "Jiajie Jin and colleagues published BIDER: Bridging knowledge inconsistency for efficient retrieval-augmented LLMs via key supporting evidence in August 2024"}, {"Head": "Many foundational and methodological works from 2012–2020 existed before the wave of 2024–2025 surveys and empirical evaluations", "Relation": "before", "Tail": "A broad set of surveys and empirical papers on hallucination, synthetic data, retrieval augmentation, and knowledge graphs were published in 2024 and 2025"}, {"Head": "Several 2024 publications appeared in conference findings and proceedings", "Relation": "at the same time", "Tail": "Multiple 2024 arXiv surveys and preprints on LLMs and knowledge graphs were released in 2024"}], "event_relation_output": "[{\"Head\": \"John Haugeland published Artificial Intelligence: The Very Idea in 1985\", \"Relation\": \"before\", \"Tail\": \"Stevan Harnad published The symbol grounding problem in 1990\"}, {\"Head\": \"Stevan Harnad published The symbol grounding problem in 1990\", \"Relation\": \"before\", \"Tail\": \"Robert K. Lindsay and colleagues published DENDRAL: A case study of the first expert system for scientific hypothesis formation in 1993\"}, {\"Head\": \"Robert K. Lindsay and colleagues published DENDRAL: A case study of the first expert system for scientific hypothesis formation in 1993\", \"Relation\": \"before\", \"Tail\": \"Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton published Imagenet classification with deep convolutional neural networks in 2012\"}, {\"Head\": \"Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton published Imagenet classification with deep convolutional neural networks in 2012\", \"Relation\": \"before\", \"Tail\": \"Yann LeCun, Yoshua Bengio, and Geoffrey Hinton published Deep learning in Nature in 2015\"}, {\"Head\": \"Yann LeCun, Yoshua Bengio, and Geoffrey Hinton published Deep learning in Nature in 2015\", \"Relation\": \"before\", \"Tail\": \"Gary Marcus published Deep learning: A critical appraisal in 2018\"}, {\"Head\": \"Gary Marcus published Deep learning: A critical appraisal in 2018\", \"Relation\": \"before\", \"Tail\": \"Y. Liu and colleagues published RoBERTa: A robustly optimized BERT pretraining approach in 2019\"}, {\"Head\": \"Y. Liu and colleagues published RoBERTa: A robustly optimized BERT pretraining approach in 2019\", \"Relation\": \"before\", \"Tail\": \"Jared Kaplan and colleagues published Scaling laws for neural language models in 2020\"}, {\"Head\": \"Jared Kaplan and colleagues published Scaling laws for neural language models in 2020\", \"Relation\": \"before\", \"Tail\": \"Multiple surveys and empirical studies on LLMs and knowledge graphs were published in 2024\"}, {\"Head\": \"Jiri Hron and colleagues published Training language models on the knowledge graph: Insights on hallucinations and their detectability in 2024\", \"Relation\": \"at the same time\", \"Tail\": \"Jiajie Jin and colleagues published BIDER: Bridging knowledge inconsistency for efficient retrieval-augmented LLMs via key supporting evidence in August 2024\"}, {\"Head\": \"Graham Neubig published Better synthetic data by retrieving and transforming existing datasets in August 2024\", \"Relation\": \"at the same time\", \"Tail\": \"Jiajie Jin and colleagues published BIDER: Bridging knowledge inconsistency for efficient retrieval-augmented LLMs via key supporting evidence in August 2024\"}, {\"Head\": \"Many foundational and methodological works from 2012–2020 existed before the wave of 2024–2025 surveys and empirical evaluations\", \"Relation\": \"before\", \"Tail\": \"A broad set of surveys and empirical papers on hallucination, synthetic data, retrieval augmentation, and knowledge graphs were published in 2024 and 2025\"}, {\"Head\": \"Several 2024 publications appeared in conference findings and proceedings\", \"Relation\": \"at the same time\", \"Tail\": \"Multiple 2024 arXiv surveys and preprints on LLMs and knowledge graphs were released in 2024\"}]"}
{"id": "1", "original_text": "nd Data Engineering , 36: 3580-3599, 2023b. - Mayana Pereira, Sikha Pentyala, Anderson Nascimento, Rafael T. de Sousa Jr., and Martine De Cock. Secure multiparty computation for synthetic data generation from distributed data, 2022. arXiv:2210.07332 [cs.CR]. - Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases?, 2019. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing . - Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-context retrieval-augmented language models. Transactions of the Association for Computational Linguistics , 11:1316-1331, 2023. - Qiang Rao and Tiejun Wang. Semantic enhancement based knowledge graph completion for graph convolutional neural networks, 2023. In Proceedings of the International Conference on Electrical, Mechanical and Computer Engineering . - Rohan Rao, Benika Hall, Sunil Patel, Christopher Brissette, and Gordana Neskovic. Insights, techniques, and evaluation for LLM-driven knowledge graphs, December 2024. URL https://developer.nvidia.com/ blog/insights-techniques-and-evaluation-for-llm-driven-knowledge-graphs/ . [Online; published Dec. 16, 2024; last accessed 26 Jul, 2025]. - Rick Rejeleene, Xiaowei Xu, and John Talburt. Towards trustable language models: Investigating information quality of large language models, 2024. arXiv:2401.13086 [cs.CL]. - Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence , 1(5):206-215, 2019. ISSN 2522-5839. doi: 10.1038/s42256-019-0048-x. - Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, and Dhagash Mehta. HybridRAG: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction, 2024. arXiv:2408.04948 [cs.CL]. - Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas GoldowskyDill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, et al. Open problems in mechanistic interpretability, 2025. arXiv:2501.16496 [cs.AI]. - Jude W. Shavlik, Raymond J. Mooney, and Geoffrey G. Towell. Symbolic and neural learning algorithms: An experimental comparison. Machine Learning , 6(2):111-143, 1991. - Fobo Shi, Duantengchuan Li, Xiaoguang Wang, Bing Li, and Xindong Wu. TGformer: A graph transformer framework for knowledge graph embedding. IEEE Transactions on Knowledge and Data Engineering , 37 (1):526-541, 2025. doi: 10.1109/TKDE.2024.3486747. - Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. Retrieval augmentation reduces hallucination in conversation, November 2021. In Findings of the Association for Computational Linguistics: EMNLP 2021 . - Nianwen Si, Hao Zhang, Heyu Chang, Wenlin Zhang, Dan Qu, and Weiqiang Zhang. Knowledge unlearning for LLMs: Tasks, methods, and challenges, 2023. arXiv:2311.15766 [cs.CL]. - Amit Singhal. Introducing the knowledge graph: Things, not strings. Google The Keyword Blog, May 2012. URL https://blog.google/products/search/introducing-knowledge-graph-things-not/ . [Online; accessed 1-Aug-2025]. - Richard Sutton. The bitter lesson. Incomplete Ideas (blog) , 13(1):38, 2019. - Vinitra Swamy, Angelika Romanou, and Martin Jaggi. Interpreting language models through knowledge graph extraction, 2021. arXiv:2111.08546 [cs.LG]. - Konrad Szocik, Bartłomiej Tkacz, and Patryk Gulczyński. The revelation of superintelligence. AI &amp; Society , 35(3):755-758, September 2020. ISSN 1435-5655. doi: 10.1007/s00146-020-00947-7. - A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F. Tan, and D. S. W. Ting. Large language models in medicine. Nature Medicine , 29:1930-1940, 2023. doi: 10.1038/s41591-023-02448-8. - Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, and Ningyu Zhang. To forget or not? Towards practical knowledge unlearning for large language models, November 2024. In Findings of the Association for Computational Linguistics: EMNLP 2024 . - Geoffrey G. Towell. Using neural networks. Machine Learning: A Multistrategy Approach, Volume IV , 4: 405, 1994. - Son Tran, Edjard Mota, and Artur d'Avila Garcez. Reasoning in neurosymbolic AI, 2025. arXiv:2505.20313 [cs.AI]. - Md Shahab Uddin, Ahsan Ahmed, Md Aktarujjaman, Mohammad Moniruzzaman, Mumtahina Ahmed, M. F. Mridha, and Md. Jakir Hossen. A hybrid reinforcement learning and knowledge graph framework for financial risk optimization in healthcare systems. Scientific Reports , 15(1):29057, 2025. ISSN 2045-2322. doi: 10.1038/s41598-025-14355-8. - William van Melle. MYCIN: A knowledge-based consultation program for infectious disease diagnosis. International Journal of Man-Machine Studies , 10(3):313-322, 1978. ISSN 0020-7373. doi: 10.1016/ S0020-7373(78)80049-2. - Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information Processing Systems , 30: 5998-6008, 2017. - Pablo Villalobos, Anson Ho, Jaime Sevilla, Tamay Besiroglu, Lennart Heim, and Marius Hobbhahn. Position: Will we run out of data? Limits of LLM scaling based on human-generated data, 2024. In Proceedings of the 41st International Conference on Machine Learning . - Warren J. von Eschenbach. Transparency and the black box problem: Why we do not trust AI. Philosophy &amp; Technology , 34(4):1607-1622, 2021. ISSN 2210-5441. doi: 10.1007/s13347-021-00477-0. - Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Qipeng Guo, Xiangkun Hu, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao, Xuming Hu, Zehan Qi, Wenyang Gao, Yidong Wang, Linyi Yang, Jindong Wang, Xing Xie, Zheng Zhang, and Yue Zhang. Survey on factuality in large language models. ACM Computing Surveys , 58(1), September 2025a. ISSN 0360-0300. doi: 10.1145/3742420. - Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen, and Sercan O. Arik. Astute RAG: Overcoming imperfect retrieval augmentation and knowledge conflicts for large language models, 2024a. arXiv:2410.07176 [cs.CL]. - J. Wang, Y. Liu, P. Li, Z. Lin, S. Sindakis, and S. Aggarwal. Overview of data quality: Examining the dimensions, antecedents, and impacts of data quality. Journal of the Knowledge Economy , pp. 1-20, 2023. doi: 10.1007/s13132-022-01096-6. Epub ahead of print, PMID: 40479478, PMCID: PMC9912223. - Junda Wang, Zonghai Yao, Zhichao Yang, Huixue Zhou, Rumeng Li, Xun Wang, Yucheng Xu, and Hong Yu. NoteChat: A dataset of synthetic patient-physician conversations conditioned on clinical notes, August 2024b. In Findings of the Association for Computational Linguistics: ACL 2024 . - Ke Wang, Jiahui Zhu, Minjie Ren, Zeming Liu, Shiwei Li, Zongye Zhang, Chenkai Zhang, Xiaoyu Wu, Qiqi Zhan, Qingjie Liu, and Yunhong Wang. A survey on data synthesis and augmentation for large language models, 2024c. arXiv:2410.12896 [cs.CL]. - Rui Wang, Fei Mi, Yi Chen, Boyang Xue, Hongru Wang, Qi Zhu, Kam-Fai Wong, and Ruifeng Xu. Role prompting guided domain adaptation with general capability preserve for large language models, June 2024d. In Findings of the Association for Computational Linguistics: NAACL 2024 . - Xiangyu Wang, Lyuzhou Chen, Taiyu Ban, Muhammad Usman, Yifeng Guan, Shikang Liu, Tianhao Wu, and Huanhuan Chen. Knowledge graph quality control: A survey. Fundamental Research , 1(5):607-626, 2021. ISSN 2667-3258. doi: 10.1016/j.fmre.2021.09.003. - Xiaoye Wang, Nicole Xi Zhang, Hongyu He, Trang Nguyen, Kun-Hsing Yu, Hao Deng, Cynthia Brandt, Danielle S. Bitterman, Ling Pan, Ching-Yu Cheng, James Zou, and Dianbo Liu. Safety challenges of AI in medicine in the era of large language models, 2025b. arXiv:2409.18968 [cs.CY]. - Yuhao Wang, Ruiyang Ren, Junyi Li, Xin Zhao, Jing Liu, and Ji-Rong Wen. Rear: A relevance-aware retrieval-augmented framework for open-domain question answering, 2024e. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024) , Miami, Florida, USA. - Yuxia Wang, Minghan Wang, Muhammad Arslan Manzoor, Fei Liu, Georgi Nenkov Georgiev, Rocktim Jyoti Das, and Preslav Nakov. Factuality of large language models: A survey, November 2024f. In Proceedings of the Conference on Empirical Methods in Natural Language Processing . - Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models, 2022. arXiv:2206.07682 [cs.CL]. - Peter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. Symbolic knowledge distillation: From general language models to commonsense models, July 2022. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies . - Wolfram Research Inc. Mathematica, version 14.3. Champaign, IL, 2025. Available from https://www.wolfram.com/mathematica/. - World Health Organization. International Statistical Classification of Diseases and Related Health Problems, 10th Revision (ICD-10) . 1992. URL https://icd.who.int/browse10/2019/en . - Tianle Xia, Liang Ding, Guojia Wan, Yibing Zhan, Bo Du, and Dacheng Tao. Improving complex reasoning over knowledge graph with logic-aware curriculum tuning. Proceedings of the AAAI Conference on Artificial Intelligence , 39(12):12881-12889, 2025. doi: 10.1609/aaai.v39i12.33405. - F. Xiao, L. Zhou, Y. Li, C. Zhang, Y. Liu, H. Yu, X. Li, C. Wang, X. Yin, and X. Gao. Comparison of brain gray matter volume changes in peritoneal dialysis and hemodialysis patients with chronic kidney disease: a VBM study. Frontiers in Neuroscience , 18:1394169, 2024. doi: 10.3389/fnins.2024.1394169. - Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, Yang Wang, and Enhong Chen. Large language models for generative information extraction: a survey. Frontiers of Computer Science , 18, 2024. doi: 10.1007/s11704-024-40555-y. - Xiao Xu, Xian Xu, Yuyao Sun, Xiaoshuang Liu, Xiang Li, Guotong Xie, and Fei Wang. Predictive modeling of clinical events with mutual enhancement between longitudinal patient records and medical knowledge graph, 2021. In Proceedings of the IEEE International Conference on Data Mining . - Ziwei Xu, Sanjay Jain, and Mohan Kankanhalli. Hallucination is inevitable: An innate limitation of large language models, 2025. arXiv:2401.11817 [cs.CL]. - Fangkai Yang, Pu Zhao, Zezhong Wang, Lu Wang, Bo Qiao, Jue Zhang, Mohit Garg, Qingwei Lin, Saravan Rajmohan, and Dongmei Zhang. Empower large language model to perform better on industrial domainspecific question answering, December 2023. In Proceedings of the Conference on Empirical Methods in Natural Language Processing: Industry Track . - Hao Yang, Jinhui Li, Chen Zhang, Alejandro P. Sierra, and Bin Shen. Large language model-driven knowledge graph construction in sepsis care using multicenter clinical databases: Development and usability study. Journal of Medical Internet Research , 27:e65537, March 2025. doi: 10.2196/65537. - Xi Ye and Greg Durrett. The unreliability of explanations in few-shot prompting for textual reasoning, 2022. In Advances in Neural Information Processing Systems . - Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan Liu. Do transformers really perform badly for graph representation? Advances in Neural Information Processing Systems , 34:28877-28888, 2021. - Shenglai Zeng, Jiankun Zhang, Bingheng Li, Yuping Lin, Tianqi Zheng, Dante Everaert, Hanqing Lu, Hui Liu, Hui Liu, Yue Xing, Monica Xiao Cheng, and Jiliang Tang. Towards knowledge checking in retrievalaugmented generation: A representation perspective, April 2025. In Proceedings of the Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) . - Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, and Haipeng Ding. Neural, symbolic and neural-symbolic reasoning on knowledge graphs. AI Open , 2:14-35, 2021. ISSN 2666-6510. doi: 10.1016/j.aiopen.2021.03. 001. - Ruizhe Zhang, Yongxin Xu, Yuzhen Xiao, Runchuan Zhu, Xinke Jiang, Xu Chu, Junfeng Zhao, and Yasha Wang. KnowPO: Knowledge-aware preference optimization for controllable knowledge selection in retrieval-augmented language models, 2025. In Proceedings of the Association for the Advancement of Artificial Intelligence Conference . - Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, and Huajun Chen. Knowledge graph reasoning with logics and embeddings: Survey and perspective, 2024a. In Proccedings of the IEEE International Conference on Knowledge Graph . - Yuji Zhang, Sha Li, Jiateng Liu, Pengfei Yu, Yi R. Fung, Jing Li, Manling Li, and Heng Ji. Knowledge overshadowing causes amalgamated hallucination in large language models, 2024b. arXiv:2407.08039 [cs.CL]. - Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models, 2025. arXiv:2303.18223 [cs.CL]. - Shuran Zheng, X", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "Mayana Pereira, Sikha Pentyala, Anderson Nascimento, Rafael T. de Sousa Jr., Martine De Cock", "Relation": "authored", "Tail": "Secure multiparty computation for synthetic data generation from distributed data"}, {"Head": "Fabio Petroni, Tim Rockt&auml;schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller", "Relation": "argued that", "Tail": "Language models can function as knowledge bases"}, {"Head": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham", "Relation": "proposed", "Tail": "In-context retrieval-augmented language models"}, {"Head": "Qiang Rao, Tiejun Wang", "Relation": "developed", "Tail": "Semantic enhancement based knowledge graph completion for graph convolutional neural networks"}, {"Head": "Rohan Rao, Benika Hall, Sunil Patel, Christopher Brissette, Gordana Neskovic", "Relation": "wrote", "Tail": "Insights, techniques, and evaluation for LLM-driven knowledge graphs"}, {"Head": "Cynthia Rudin", "Relation": "recommended", "Tail": "using interpretable models instead of explaining black box machine learning models for high stakes decisions"}, {"Head": "Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta", "Relation": "introduced", "Tail": "HybridRAG: integration of knowledge graphs and vector retrieval augmented generation for information extraction"}, {"Head": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin", "Relation": "presented", "Tail": "Attention is all you need (Transformer architecture)"}, {"Head": "J. Wang, Y. Liu, P. Li, Z. Lin, S. Sindakis, S. Aggarwal", "Relation": "surveyed", "Tail": "data quality dimensions, antecedents, and impacts"}, {"Head": "Tianle Xia, Liang Ding, Guojia Wan, Yibing Zhan, Bo Du, Dacheng Tao", "Relation": "improved", "Tail": "complex reasoning over knowledge graph with logic-aware curriculum tuning"}, {"Head": "Hao Yang, Jinhui Li, Chen Zhang, Alejandro P. Sierra, Bin Shen", "Relation": "developed", "Tail": "LLM-driven knowledge graph construction in sepsis care using multicenter clinical databases"}, {"Head": "Xiangyu Wang, Lyuzhou Chen, Taiyu Ban, Muhammad Usman, Yifeng Guan, Shikang Liu, Tianhao Wu, Huanhuan Chen", "Relation": "surveyed", "Tail": "knowledge graph quality control"}, {"Head": "Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen", "Relation": "reviewed", "Tail": "knowledge graph reasoning with logics and embeddings"}, {"Head": "Ziwei Xu, Sanjay Jain, Mohan Kankanhalli", "Relation": "claimed", "Tail": "hallucination is an innate limitation of large language models"}, {"Head": "World Health Organization", "Relation": "published", "Tail": "International Statistical Classification of Diseases and Related Health Problems, 10th Revision (ICD-10)"}, {"Head": "Wolfram Research Inc.", "Relation": "released", "Tail": "Mathematica version 14.3"}], "entity_relation_output": "[{\"Head\": \"Mayana Pereira, Sikha Pentyala, Anderson Nascimento, Rafael T. de Sousa Jr., Martine De Cock\", \"Relation\": \"authored\", \"Tail\": \"Secure multiparty computation for synthetic data generation from distributed data\"}, {\"Head\": \"Fabio Petroni, Tim Rockt&auml;schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller\", \"Relation\": \"argued that\", \"Tail\": \"Language models can function as knowledge bases\"}, {\"Head\": \"Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham\", \"Relation\": \"proposed\", \"Tail\": \"In-context retrieval-augmented language models\"}, {\"Head\": \"Qiang Rao, Tiejun Wang\", \"Relation\": \"developed\", \"Tail\": \"Semantic enhancement based knowledge graph completion for graph convolutional neural networks\"}, {\"Head\": \"Rohan Rao, Benika Hall, Sunil Patel, Christopher Brissette, Gordana Neskovic\", \"Relation\": \"wrote\", \"Tail\": \"Insights, techniques, and evaluation for LLM-driven knowledge graphs\"}, {\"Head\": \"Cynthia Rudin\", \"Relation\": \"recommended\", \"Tail\": \"using interpretable models instead of explaining black box machine learning models for high stakes decisions\"}, {\"Head\": \"Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta\", \"Relation\": \"introduced\", \"Tail\": \"HybridRAG: integration of knowledge graphs and vector retrieval augmented generation for information extraction\"}, {\"Head\": \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin\", \"Relation\": \"presented\", \"Tail\": \"Attention is all you need (Transformer architecture)\"}, {\"Head\": \"J. Wang, Y. Liu, P. Li, Z. Lin, S. Sindakis, S. Aggarwal\", \"Relation\": \"surveyed\", \"Tail\": \"data quality dimensions, antecedents, and impacts\"}, {\"Head\": \"Tianle Xia, Liang Ding, Guojia Wan, Yibing Zhan, Bo Du, Dacheng Tao\", \"Relation\": \"improved\", \"Tail\": \"complex reasoning over knowledge graph with logic-aware curriculum tuning\"}, {\"Head\": \"Hao Yang, Jinhui Li, Chen Zhang, Alejandro P. Sierra, Bin Shen\", \"Relation\": \"developed\", \"Tail\": \"LLM-driven knowledge graph construction in sepsis care using multicenter clinical databases\"}, {\"Head\": \"Xiangyu Wang, Lyuzhou Chen, Taiyu Ban, Muhammad Usman, Yifeng Guan, Shikang Liu, Tianhao Wu, Huanhuan Chen\", \"Relation\": \"surveyed\", \"Tail\": \"knowledge graph quality control\"}, {\"Head\": \"Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen\", \"Relation\": \"reviewed\", \"Tail\": \"knowledge graph reasoning with logics and embeddings\"}, {\"Head\": \"Ziwei Xu, Sanjay Jain, Mohan Kankanhalli\", \"Relation\": \"claimed\", \"Tail\": \"hallucination is an innate limitation of large language models\"}, {\"Head\": \"World Health Organization\", \"Relation\": \"published\", \"Tail\": \"International Statistical Classification of Diseases and Related Health Problems, 10th Revision (ICD-10)\"}, {\"Head\": \"Wolfram Research Inc.\", \"Relation\": \"released\", \"Tail\": \"Mathematica version 14.3\"}]", "event_entity_dict": [{"Event": "Mayana Pereira, Sikha Pentyala, Anderson Nascimento, Rafael T. de Sousa Jr., and Martine De Cock published 'Secure multiparty computation for synthetic data generation from distributed data' in 2022 on arXiv.", "Entity": ["Mayana Pereira", "Sikha Pentyala", "Anderson Nascimento", "Rafael T. de Sousa Jr.", "Martine De Cock", "arXiv"]}, {"Event": "Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller published 'Language models as knowledge bases?' in 2019 in the Proceedings of EMNLP and IJCNLP conference.", "Entity": ["Fabio Petroni", "Tim Rocktäschel", "Sebastian Riedel", "Patrick Lewis", "Anton Bakhtin", "Yuxiang Wu", "Alexander Miller", "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing", "9th International Joint Conference on Natural Language Processing"]}, {"Event": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham published 'In-context retrieval-augmented language models' in Transactions of the Association for Computational Linguistics in 2023.", "Entity": ["Ori Ram", "Yoav Levine", "Itay Dalmedigos", "Dor Muhlgay", "Amnon Shashua", "Kevin Leyton-Brown", "Yoav Shoham", "Transactions of the Association for Computational Linguistics"]}, {"Event": "Qiang Rao and Tiejun Wang published 'Semantic enhancement based knowledge graph completion for graph convolutional neural networks' in 2023 in the Proceedings of the International Conference on Electrical, Mechanical and Computer Engineering.", "Entity": ["Qiang Rao", "Tiejun Wang", "Proceedings of the International Conference on Electrical, Mechanical and Computer Engineering"]}, {"Event": "Rohan Rao, Benika Hall, Sunil Patel, Christopher Brissette, and Gordana Neskovic published 'Insights, techniques, and evaluation for LLM-driven knowledge graphs' in December 2024 on the NVIDIA developer blog.", "Entity": ["Rohan Rao", "Benika Hall", "Sunil Patel", "Christopher Brissette", "Gordana Neskovic", "NVIDIA developer blog"]}, {"Event": "Rick Rejeleene, Xiaowei Xu, and John Talburt published 'Towards trustable language models: Investigating information quality of large language models' in 2024 on arXiv.", "Entity": ["Rick Rejeleene", "Xiaowei Xu", "John Talburt", "arXiv"]}, {"Event": "Cynthia Rudin published 'Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead' in Nature Machine Intelligence in 2019.", "Entity": ["Cynthia Rudin", "Nature Machine Intelligence"]}, {"Event": "Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, and Dhagash Mehta published 'HybridRAG: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction' in 2024 on arXiv.", "Entity": ["Bhaskarjit Sarmah", "Benika Hall", "Rohan Rao", "Sunil Patel", "Stefano Pasquali", "Dhagash Mehta", "arXiv"]}, {"Event": "Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas GoldowskyDill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, and others published 'Open problems in mechanistic interpretability' in 2025 on arXiv.", "Entity": ["Lee Sharkey", "Bilal Chughtai", "Joshua Batson", "Jack Lindsey", "Jeff Wu", "Lucius Bushnaq", "Nicholas GoldowskyDill", "Stefan Heimersheim", "Alejandro Ortega", "Joseph Bloom", "arXiv"]}, {"Event": "Jude W. Shavlik, Raymond J. Mooney, and Geoffrey G. Towell published 'Symbolic and neural learning algorithms: An experimental comparison' in Machine Learning in 1991.", "Entity": ["Jude W. Shavlik", "Raymond J. Mooney", "Geoffrey G. Towell", "Machine Learning journal"]}, {"Event": "Fobo Shi, Duantengchuan Li, Xiaoguang Wang, Bing Li, and Xindong Wu published 'TGformer: A graph transformer framework for knowledge graph embedding' in IEEE Transactions on Knowledge and Data Engineering in 2025.", "Entity": ["Fobo Shi", "Duantengchuan Li", "Xiaoguang Wang", "Bing Li", "Xindong Wu", "IEEE Transactions on Knowledge and Data Engineering"]}, {"Event": "Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston published 'Retrieval augmentation reduces hallucination in conversation' in November 2021 in Findings of ACL: EMNLP 2021.", "Entity": ["Kurt Shuster", "Spencer Poff", "Moya Chen", "Douwe Kiela", "Jason Weston", "Findings of the Association for Computational Linguistics: EMNLP 2021"]}, {"Event": "Nianwen Si, Hao Zhang, Heyu Chang, Wenlin Zhang, Dan Qu, and Weiqiang Zhang published 'Knowledge unlearning for LLMs: Tasks, methods, and challenges' in 2023 on arXiv.", "Entity": ["Nianwen Si", "Hao Zhang", "Heyu Chang", "Wenlin Zhang", "Dan Qu", "Weiqiang Zhang", "arXiv"]}, {"Event": "Amit Singhal introduced 'the knowledge graph: Things, not strings' on the Google The Keyword Blog in May 2012.", "Entity": ["Amit Singhal", "Google The Keyword Blog"]}, {"Event": "Richard Sutton wrote 'The bitter lesson' on the Incomplete Ideas blog in 2019.", "Entity": ["Richard Sutton", "Incomplete Ideas (blog)"]}, {"Event": "Vinitra Swamy, Angelika Romanou, and Martin Jaggi published 'Interpreting language models through knowledge graph extraction' in 2021 on arXiv.", "Entity": ["Vinitra Swamy", "Angelika Romanou", "Martin Jaggi", "arXiv"]}, {"Event": "Konrad Szocik, Bartłomiej Tkacz, and Patryk Gulczyński published 'The revelation of superintelligence' in AI & Society in September 2020.", "Entity": ["Konrad Szocik", "Bartłomiej Tkacz", "Patryk Gulczyński", "AI & Society"]}, {"Event": "A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F. Tan, and D. S. W. Ting published 'Large language models in medicine' in Nature Medicine in 2023.", "Entity": ["A. J. Thirunavukarasu", "D. S. J. Ting", "K. Elangovan"]}], "event_entity_output": "[{\"Event\": \"Mayana Pereira, Sikha Pentyala, Anderson Nascimento, Rafael T. de Sousa Jr., and Martine De Cock published 'Secure multiparty computation for synthetic data generation from distributed data' in 2022 on arXiv.\", \"Entity\": [\"Mayana Pereira\", \"Sikha Pentyala\", \"Anderson Nascimento\", \"Rafael T. de Sousa Jr.\", \"Martine De Cock\", \"arXiv\"]}, {\"Event\": \"Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller published 'Language models as knowledge bases?' in 2019 in the Proceedings of EMNLP and IJCNLP conference.\", \"Entity\": [\"Fabio Petroni\", \"Tim Rocktäschel\", \"Sebastian Riedel\", \"Patrick Lewis\", \"Anton Bakhtin\", \"Yuxiang Wu\", \"Alexander Miller\", \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\", \"9th International Joint Conference on Natural Language Processing\"]}, {\"Event\": \"Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham published 'In-context retrieval-augmented language models' in Transactions of the Association for Computational Linguistics in 2023.\", \"Entity\": [\"Ori Ram\", \"Yoav Levine\", \"Itay Dalmedigos\", \"Dor Muhlgay\", \"Amnon Shashua\", \"Kevin Leyton-Brown\", \"Yoav Shoham\", \"Transactions of the Association for Computational Linguistics\"]}, {\"Event\": \"Qiang Rao and Tiejun Wang published 'Semantic enhancement based knowledge graph completion for graph convolutional neural networks' in 2023 in the Proceedings of the International Conference on Electrical, Mechanical and Computer Engineering.\", \"Entity\": [\"Qiang Rao\", \"Tiejun Wang\", \"Proceedings of the International Conference on Electrical, Mechanical and Computer Engineering\"]}, {\"Event\": \"Rohan Rao, Benika Hall, Sunil Patel, Christopher Brissette, and Gordana Neskovic published 'Insights, techniques, and evaluation for LLM-driven knowledge graphs' in December 2024 on the NVIDIA developer blog.\", \"Entity\": [\"Rohan Rao\", \"Benika Hall\", \"Sunil Patel\", \"Christopher Brissette\", \"Gordana Neskovic\", \"NVIDIA developer blog\"]}, {\"Event\": \"Rick Rejeleene, Xiaowei Xu, and John Talburt published 'Towards trustable language models: Investigating information quality of large language models' in 2024 on arXiv.\", \"Entity\": [\"Rick Rejeleene\", \"Xiaowei Xu\", \"John Talburt\", \"arXiv\"]}, {\"Event\": \"Cynthia Rudin published 'Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead' in Nature Machine Intelligence in 2019.\", \"Entity\": [\"Cynthia Rudin\", \"Nature Machine Intelligence\"]}, {\"Event\": \"Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, and Dhagash Mehta published 'HybridRAG: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction' in 2024 on arXiv.\", \"Entity\": [\"Bhaskarjit Sarmah\", \"Benika Hall\", \"Rohan Rao\", \"Sunil Patel\", \"Stefano Pasquali\", \"Dhagash Mehta\", \"arXiv\"]}, {\"Event\": \"Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas GoldowskyDill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, and others published 'Open problems in mechanistic interpretability' in 2025 on arXiv.\", \"Entity\": [\"Lee Sharkey\", \"Bilal Chughtai\", \"Joshua Batson\", \"Jack Lindsey\", \"Jeff Wu\", \"Lucius Bushnaq\", \"Nicholas GoldowskyDill\", \"Stefan Heimersheim\", \"Alejandro Ortega\", \"Joseph Bloom\", \"arXiv\"]}, {\"Event\": \"Jude W. Shavlik, Raymond J. Mooney, and Geoffrey G. Towell published 'Symbolic and neural learning algorithms: An experimental comparison' in Machine Learning in 1991.\", \"Entity\": [\"Jude W. Shavlik\", \"Raymond J. Mooney\", \"Geoffrey G. Towell\", \"Machine Learning journal\"]}, {\"Event\": \"Fobo Shi, Duantengchuan Li, Xiaoguang Wang, Bing Li, and Xindong Wu published 'TGformer: A graph transformer framework for knowledge graph embedding' in IEEE Transactions on Knowledge and Data Engineering in 2025.\", \"Entity\": [\"Fobo Shi\", \"Duantengchuan Li\", \"Xiaoguang Wang\", \"Bing Li\", \"Xindong Wu\", \"IEEE Transactions on Knowledge and Data Engineering\"]}, {\"Event\": \"Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston published 'Retrieval augmentation reduces hallucination in conversation' in November 2021 in Findings of ACL: EMNLP 2021.\", \"Entity\": [\"Kurt Shuster\", \"Spencer Poff\", \"Moya Chen\", \"Douwe Kiela\", \"Jason Weston\", \"Findings of the Association for Computational Linguistics: EMNLP 2021\"]}, {\"Event\": \"Nianwen Si, Hao Zhang, Heyu Chang, Wenlin Zhang, Dan Qu, and Weiqiang Zhang published 'Knowledge unlearning for LLMs: Tasks, methods, and challenges' in 2023 on arXiv.\", \"Entity\": [\"Nianwen Si\", \"Hao Zhang\", \"Heyu Chang\", \"Wenlin Zhang\", \"Dan Qu\", \"Weiqiang Zhang\", \"arXiv\"]}, {\"Event\": \"Amit Singhal introduced 'the knowledge graph: Things, not strings' on the Google The Keyword Blog in May 2012.\", \"Entity\": [\"Amit Singhal\", \"Google The Keyword Blog\"]}, {\"Event\": \"Richard Sutton wrote 'The bitter lesson' on the Incomplete Ideas blog in 2019.\", \"Entity\": [\"Richard Sutton\", \"Incomplete Ideas (blog)\"]}, {\"Event\": \"Vinitra Swamy, Angelika Romanou, and Martin Jaggi published 'Interpreting language models through knowledge graph extraction' in 2021 on arXiv.\", \"Entity\": [\"Vinitra Swamy\", \"Angelika Romanou\", \"Martin Jaggi\", \"arXiv\"]}, {\"Event\": \"Konrad Szocik, Bartłomiej Tkacz, and Patryk Gulczyński published 'The revelation of superintelligence' in AI & Society in September 2020.\", \"Entity\": [\"Konrad Szocik\", \"Bartłomiej Tkacz\", \"Patryk Gulczyński\", \"AI & Society\"]}, {\"Event\": \"A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F. Tan, and D. S. W. Ting published 'Large language models in medicine' in Nature Medicine in 2023.\", \"Entity\": [\"A. J. Thirunavukarasu\", \"D. S. J. Ting\", \"K. Elangovan\"]}]", "event_relation_dict": [{"Head": "MYCIN: A knowledge-based consultation program for infectious disease diagnosis was published in 1978", "Relation": "before", "Tail": "Symbolic and neural learning algorithms: An experimental comparison was published in 1991"}, {"Head": "Attention is all you need was published in 2017", "Relation": "before", "Tail": "Emergent abilities of large language models was published in 2022"}, {"Head": "Introducing the knowledge graph: Things, not strings was published in 2012", "Relation": "before", "Tail": "Multiple knowledge graph surveys and method papers on knowledge graph construction and quality control were published from 2021 to 2025"}, {"Head": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead was published in 2019", "Relation": "because", "Tail": "Transparency and the black box problem: Why we do not trust AI was discussed in 2021"}, {"Head": "Retrieval augmentation reduces hallucination in conversation was published in 2021", "Relation": "before", "Tail": "Subsequent works on retrieval-augmented generation and methods to overcome imperfect retrieval were published in 2024 and 2025"}, {"Head": "Language models as knowledge bases? was published in 2019", "Relation": "before", "Tail": "Many later surveys and studies on factuality and hallucination in large language models were published in 2024 and 2025"}, {"Head": "Knowledge unlearning for LLMs: Tasks, methods, and challenges was published in 2023", "Relation": "before", "Tail": "To forget or not? Towards practical knowledge unlearning for large language models was published in 2024"}, {"Head": "Emergent abilities of large language models was published in 2022", "Relation": "before", "Tail": "A survey of large language models was published in 2025"}, {"Head": "Improvements and methodologies for knowledge-augmented LLMs and knowledge graph integration were developed in papers from 2021 to 2024", "Relation": "as a result", "Tail": "Applications of LLM-driven knowledge graphs and clinical knowledge graph construction studies appeared in 2024 and 2025"}, {"Head": "Early neural network and knowledge-based system work in the 1970s through 1990s established foundational approaches", "Relation": "before", "Tail": "Modern neurosymbolic reasoning, transformers for graphs, and LLM-based knowledge extraction research appeared from 2017 through 2025"}], "event_relation_output": "[{\"Head\": \"MYCIN: A knowledge-based consultation program for infectious disease diagnosis was published in 1978\", \"Relation\": \"before\", \"Tail\": \"Symbolic and neural learning algorithms: An experimental comparison was published in 1991\"}, {\"Head\": \"Attention is all you need was published in 2017\", \"Relation\": \"before\", \"Tail\": \"Emergent abilities of large language models was published in 2022\"}, {\"Head\": \"Introducing the knowledge graph: Things, not strings was published in 2012\", \"Relation\": \"before\", \"Tail\": \"Multiple knowledge graph surveys and method papers on knowledge graph construction and quality control were published from 2021 to 2025\"}, {\"Head\": \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead was published in 2019\", \"Relation\": \"because\", \"Tail\": \"Transparency and the black box problem: Why we do not trust AI was discussed in 2021\"}, {\"Head\": \"Retrieval augmentation reduces hallucination in conversation was published in 2021\", \"Relation\": \"before\", \"Tail\": \"Subsequent works on retrieval-augmented generation and methods to overcome imperfect retrieval were published in 2024 and 2025\"}, {\"Head\": \"Language models as knowledge bases? was published in 2019\", \"Relation\": \"before\", \"Tail\": \"Many later surveys and studies on factuality and hallucination in large language models were published in 2024 and 2025\"}, {\"Head\": \"Knowledge unlearning for LLMs: Tasks, methods, and challenges was published in 2023\", \"Relation\": \"before\", \"Tail\": \"To forget or not? Towards practical knowledge unlearning for large language models was published in 2024\"}, {\"Head\": \"Emergent abilities of large language models was published in 2022\", \"Relation\": \"before\", \"Tail\": \"A survey of large language models was published in 2025\"}, {\"Head\": \"Improvements and methodologies for knowledge-augmented LLMs and knowledge graph integration were developed in papers from 2021 to 2024\", \"Relation\": \"as a result\", \"Tail\": \"Applications of LLM-driven knowledge graphs and clinical knowledge graph construction studies appeared in 2024 and 2025\"}, {\"Head\": \"Early neural network and knowledge-based system work in the 1970s through 1990s established foundational approaches\", \"Relation\": \"before\", \"Tail\": \"Modern neurosymbolic reasoning, transformers for graphs, and LLM-based knowledge extraction research appeared from 2017 through 2025\"}]"}
{"id": "1", "original_text": "uan Qi, Rui Ray Chen, Yongchan Kwon, and James Zou. Proper dataset valuation by pointwise mutual information, 2025. arXiv:2405.18253 [cs.LG]. - Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. A comprehensive survey on automatic knowledge graph construction. ACM Computing Surveys , 56(4), November 2023. ISSN 0360-0300. doi: 10.1145/3618295. - Kaitlyn Zhou, Kawin Ethayarajh, Dallas Card, and Dan Jurafsky. Problems with cosine as a measure of embedding similarity for high frequency words, May 2022. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) . - Lexin Zhou, Wout Schellaert, Fernando Martínez-Plumed, Yael Moros-Daval, Cèsar Ferri, and José Hernández-Orallo. Larger and more instructable language models become less reliable. Nature , 634(8032): 61-68, 2024. ISSN 1476-4687. doi: 10.1038/s41586-024-07930-y. - Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, and Ningyu Zhang. LLMs for knowledge graph construction and reasoning: Recent capabilities and future opportunities. World Wide Web , 27(5), August 2024. ISSN 1386-145X. doi: 10.1007/s11280-024-01297-w. ## Appendices ## A Training Data We exclude some relations from the UMLS KG that add little semantic value, i.e.: (i) custom-defined mappings of outdated-to-new UMLS relations for backward compatibility, which cannot be inferred from external data; (ii) relations used only for cross-vocabulary mappings; (iii) relations where tails are largely redundant with respect to heads; and (iv) relations with very few possible tails. For example, relation has\\_associated\\_finding is a redundant relation: - family history of diabetes, has\\_associated\\_finding , diabetes mellitus - parental history of diabetes, has\\_associated\\_finding , diabetes mellitus - family history of glaucoma, has\\_associated\\_finding , glaucoma - family history of hypertension, has\\_associated\\_finding , hypertensive disorder - family history of cvd, has\\_associated\\_finding , congenital heart disease In these cases, the tail subject is the same as the head subject. has\\_laterality is an example of a relation with very few possible tails, with almost all tails being 'side' . Table A1: Excluded UMLS relations | acted_on_by_process | has_scale_type | regulated_by | |--------------------------------|----------------------------------|-------------------------------| | active_ingredient_of | has_specimen | replaced_by | | associated_procedure_of | has_subject_relationship_context | replaces | | basis_of_strength_substance_of | has_temporal_context | was_a | | component_of | inverse_was_a | has_intent | | consider_from | mapped_from | referred_to_by | | direct_device_of | mapped_to | refers_to | | direct_substance_of | moved_to | characterizes | | has_associated_finding | negatively_regulated_by | substance_used_by | | has_finding_context | positively_regulated_by | specimen_source_topography_of | | has_interpretation | possibly_replaces | specimen_substance_of | | has_laterality | precise_active_ingredient_of | has_active_ingredient | | has_realization | realization_of | has_property | ``` ( ( diabetes[Abstract] OR diabetes[Body -All Words] OR diabetes[Body -Key Terms] ) OR ( ''diabetes mellitus ''[MeSH Terms] OR ''diabetes insipidus ''[MeSH Terms] ) ) OR diabetes[Title] NOT ( ''sars-cov-2''[MeSH Terms] OR ''covid -19''[MeSH Terms] ) AND ( medline[sb] AND ''2019/04/01''[PubDate] : ''2025/04/01''[PubDate] ) ``` Listing 1: PubMed search query ## B KG Injection Algorithm Input: Sequences with heads: Each head h may have multiple triples T = 〈 h, r, t 〉 = T ( seq ) in sequence seq (we cap this number at 40 triples to ensure enough diversity and leaving room for further dropping); triple embedding similarity score with respect to the sequence: score ( T ); similarity matching threshold α (a hyperparameter). Output: Each head has one injection T ( seq ) or does not have any, in all sequences. ## Preprocessing 1. Drop all triples with a score less than threshold α . 2. Make all triples unique: If a triple matches multiple sequences, retain the triple ˜ T with the highest score, i.e., in the sequence to which the triple is most relevant: <!-- formula-not-decoded --> The second preprocessing step prevents overfitting in the semantic space on common triples. Triple selection for each head: To balance contextual relevance with relation diversity: 1st priority: maximize injection score, 2nd priority: maintain relation diversity. Relation diversity is measured by the number of unique triples that contain the relation. ## Maximize diversity 1. Split relations into relation buckets based on the number of unique triples at step k and assume that within each bucket all relations are equally diverse (e.g., k = 20 implies that relations with #triples 100-120, 120-140.., are treated as equally diverse). 2. Within each relation bucket, sort all triples by score regardless of relation. 3. Start with the lowest-numbered bucket (rarest relations). Within it, start with the triple with the highest score and retain only it for its head, removing all other matched triples, which may have a higher score but may be in a higher relation bucket. As a result, one of the rarest possible relations in the dataset would survive for this head, increasing relation diversity overall. ## Maximize score then diversity 1. Order triples by score. 2. Split into score buckets: Assume that within each score bucket, triples are equally good. 3. Then, within each score bucket, apply Maximize diversity. Altogether, we group triples by how 'low' the score is (higher scores are assigned to lower-bucket IDs). Then, within each score bucket, we favor relation types that are less frequent. Finally, we choose the highest-scoring triple for each head. The algorithm is implemented using the Pandas framework and presented in Algorithm 1. In our experiments, we use score \\_ bucket \\_ size = 0 . 01, relation \\_ bucket \\_ size = 100. The bucket size and relation bucket size are chosen under the assumption that, within each bucket, score and relation diversity remain approximately balanced. ## Algorithm 1: Maximize Score then Diversity ``` Input : df (a Pandas DataFrame where each row comprises a triple ( h, r, t ), unique matched _ head _ id , and an associated score ), score _ bucket _ size , relation _ bucket _ size Output: Filtered DataFrame result max _ s ← max( df.score ); foreach row in df do row.score _ bucket ←/floorleft ( max _ s -row.score ) /score _ bucket _ size /floorright ; rel _ counts ← count occurrences of each relation_type r in df ; foreach row in df do rel _ count ← rel _ counts [ row.r ]; row.rel _ bucket ←/floorleft rel _ count/relation _ bucket _ size /floorright ; Sort df by ascending ( score _ bucket, rel _ bucket ) and by descending score ; result ← [ ]; seen _ heads ←∅ ; foreach row in sorted df do if row.matched _ head _ id / ∈ seen _ heads then append row to result ; seen _ heads ← seen _ heads ∪ { row.matched _ head _ id } ; // Equivalent to df.drop_duplicates(subset='matched_head_id', keep='first') return result ; ``` Table B1: Seed KG: Relation statistics for α = 0 . 55 in the training split (Qwen3-32B) | # | Relation | # injections | |-----|---------------------------|----------------| | 1 | isa | 8627 | | 2 | inverse_isa | 5512 | | 3 | cause_of | 1440 | | 4 | interprets | 1268 | | 5 | associated_finding_of | 1145 | | 6 | has_disposition | 1084 | | 7 | focus_of | 1038 | | 8 | is_interpreted_by | 962 | | 9 | has_associated_morphology | 863 | | 10 | causative_agent_of | 809 | | 11 | finding_site_of | 741 | | 12 | associated_morphology_of | 598 | | 13 | has_method | 515 | | 14 | has_finding_site | 477 | | # | Relation | # injections | |-----|------------------------|----------------| | 15 | possibly_equivalent_to | 446 | | 16 | has_component | 433 | | 17 | due_to | 365 | | 18 | has_part | 350 | | 19 | has_modification | 310 | | 20 | associated_with | 254 | | 21 | part_of | 211 | | 22 | plays_role | 194 | | 23 | occurs_before | 187 | | 24 | has_clinical_course | 144 | | 25 | occurs_in | 138 | | 26 | same_as | 134 | | 27 | has_causative_agent | 127 | | 28 | has_focus | 118 | Figure C1: Relation distribution in the GraphMERT -extracted KG vs. seed KG. The shapes differ: While 'isa' prevails in the seed KG, the GraphMERT KG is heavily skewed towards 'associated\\_with.' This reflects the helper LLM's inclination to select 'associated\\_with' during relation matching as the most appropriate, given a sequence. <!-- image --> ## C Extracted KGs ## C.1 Relation Distribution: GraphMERT-extracted KG vs. Seed KG Fig. C1 shows the relation distribution on a logarithmic scale. While 'isa' is the most represented relation in the training data, in the to-be-extracted KG, the helper LLM tends to select 'associated\\_with' most frequently during relation matching. ## C.2 Sanity Check We ran a lightweight screening with GPT-5 Thinking on small, comparable samples from each KG. This screening should be viewed as complementary to benchmark-based verification, providing useful diagnostic signals but not replacing factual evaluation. Setup: For each KG, we retrieved all triples whose head contains the keywords 'insulin-like growth factor 1 (IGF-1)' and 'glucocorticoid receptor (GR).' These terms are highly relevant to diabetes, yield comparable sample sizes per KG (22-29), and remain small enough for human inspection. Prompt. Evaluate if these medical KG triples are valid (yes/no/maybe) and give a very short reason why: 〈 list of triples 〉 . Table C1: Example of GraphMERT -extracted triple with novel tail vocabulary from a 128-token sequence. The seed KG does not include the token 'nlrp3' - it was learned and extracted from the text. 'Pathway' is a token that GraphMERT learned from the training corpus. Here, 'pathway' is implicitly supported: The phrase 'specific inhibitors of NLRP3 inflammasome activation' links the activation to NLRP3-mediated signaling (i.e., the NLRP3 pathway). Sequence: . . . inflammasome activation and regulation is highlighted, including its putative roles in adipose tissue dysfunction and insulin resistance. Specific inhibitors of NLRP3 inflammasome activation which can potentially be used to treat metabolic disorders are also discussed. Identifying a quantitative biomarker of neuropsychiatric dysfunction in people with HIV (PWH) remains a significant challenge in the neuroHIV field. The strongest evidence to date implicates the role of monocytes in central nervous system (CNS) dysfunction in HIV, yet no study has examined monocyte subsets in blood as a correlate and/or predictor of neuropsychiatric function in virally suppressed PWH. METHODS In 2 independent cohorts of virologically suppressed women with HIV (vsWWH. . . | Head | Relation | Tail | |-------------------------|-----------------|---------------| | inflammasome activation | associated_with | nlrp3 pathway | Table C2: GPT-5 Thinking screening (counts with proportions) | Keyword | KG | Yes | Maybe | No | Total | |-----------|-----------|-----------|-----------|-----------|---------| | IGF-1 | LLM | 8 (0.28) | 3 (0.10) | 18 (0.62) | 29 | | IGF-1 | GraphMERT | 15 (0.68) | 0 (0.00) | 7 (0.32) | 22 | | GR | LLM | 4 (0.17) | 12 (0.50) | 8 (0.33) | 24 | | GR | GraphMERT | 15 (0.54) | 7 (0.25) | 6 (0.21) | 28 | Table C2 summarizes screening results. Tables C3, C4, C5, C6 provide GPT-5 Thinking responses for each triple in the GraphMERT and LLM KG samples. Table C3: GraphMERT KG. Sanity check with GPT-5 Thinking. We select all KG triples that contain 'insulin-like growth factor-1,' 22 triples in total, yes/no/maybe: 15/0/7 . | Triple | Verdict | GPT-5 explanation | |------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|-------------------------------------------------| | insulin-like growth factor 1, isa, peptide hormone | yes | 70-aa peptide hormone. | | insulin-like growth factor 1, isa, growth factor | yes | Canonical growth factor. | | insulin-like growth factor 1, associated_with, insulin resistance | yes | Correlates with IR. | | insulin-like growth factor 1 receptor (IGF1R), plays_role, target | maybe | 'Target' is vague. | | insulin-like growth factor 1 (IGF-1), associated_with, diabetes mellitus | yes | Linked with DM. | | insulin-like growth factor 1 (IGF-1), associated_with, | maybe | Biomarker is a role. | | biomarker insulin-like growth factor 1 (IGF-1), associated_with, insulin | yes | Strong crosstalk. | | insulin-like growth factor 1 (IGF-1), associated_with, type 2 diabetes | yes | Epidemiologic link. | | insulin-like growth factor 1 (IGF-1), associated_with, insulin resistance | yes | Well supported. | | insulin-like growth factor 1, plays_role, growth factor | yes | Acts as growth factor. | | insulin-like growth factor 1 (IGF-1), plays_role, biomarkers insulin/insulin-like growth factor 1 (IGF-1) signaling pathway, has_component, IGF-1 receptor | maybe yes | Plural/ontology mismatch. IGF-1R is in pathway. | | insulin-like growth factor 1 (IGF-1), associated_with, insulin | yes | Duplicate; supported. | | insulin-like growth factor 1, plays_role, growth hormone action | yes | Mediates GH effects. | | insulin-like growth factor 1 receptor (IGF1R), plays_role, signaling receptor | yes | RTK signaling receptor. | | insulin-like growth factor 1 receptor, plays_role, signaling | yes | Mediates signaling. | | insulin-like growth factor 1 (IGF1), associated_with, androgen | maybe | Context-specifi", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "Proper dataset valuation by pointwise mutual information", "Relation": "authored_by", "Tail": "Juan Qi; Rui Ray Chen; Yongchan Kwon; James Zou"}, {"Head": "A comprehensive survey on automatic knowledge graph construction", "Relation": "authored_by", "Tail": "Lingfeng Zhong; Jia Wu; Qian Li; Hao Peng; Xindong Wu"}, {"Head": "Problems with cosine as a measure of embedding similarity for high frequency words", "Relation": "authored_by", "Tail": "Kaitlyn Zhou; Kawin Ethayarajh; Dallas Card; Dan Jurafsky"}, {"Head": "Larger and more instructable language models become less reliable", "Relation": "authored_by", "Tail": "Lexin Zhou; Wout Schellaert; Fernando Martínez-Plumed; Yael Moros-Daval; Cèsar Ferri; José Hernández-Orallo"}, {"Head": "LLMs for knowledge graph construction and reasoning: Recent capabilities and future opportunities", "Relation": "authored_by", "Tail": "Yuqi Zhu; Xiaohan Wang; Jing Chen; Shuofei Qiao; Yixin Ou; Yunzhi Yao; Shumin Deng; Huajun Chen; Ningyu Zhang"}, {"Head": "UMLS relation has_associated_finding", "Relation": "characteristic", "Tail": "redundant_when_tail_equals_head"}, {"Head": "UMLS relation has_laterality", "Relation": "characteristic", "Tail": "few_possible_tails_mostly_side"}, {"Head": "Excluded UMLS relations list", "Relation": "includes", "Tail": "acted_on_by_process; active_ingredient_of; associated_procedure_of; basis_of_strength_substance_of; component_of; consider_from; direct_device_of; direct_substance_of; has_associated_finding; has_finding_context; has_interpretation; has_laterality; has_realization; has_scale_type; has_specimen; has_subject_relationship_context; has_temporal_context; inverse_was_a; mapped_from; mapped_to; moved_to; negatively_regulated_by; positively_regulated_by; possibly_replaces; precise_active_ingredient_of; realization_of; regulated_by; replaced_by; replaces; was_a; has_intent; referred_to_by; refers_to; characterizes; substance_used_by; specimen_source_topography_of; specimen_substance_of; has_active_ingredient; has_property"}, {"Head": "PubMed search query", "Relation": "filters", "Tail": "diabetes_terms AND NOT sars-cov-2_or_covid-19 within 2019-04-01 to 2025-04-01 medline"}, {"Head": "KG Injection Algorithm", "Relation": "inputs", "Tail": "sequences_with_heads; triples_T_per_sequence; triple_embedding_similarity_score; similarity_threshold_alpha"}, {"Head": "KG Injection Algorithm", "Relation": "outputs", "Tail": "at_most_one_injected_triple_per_head_per_sequence"}, {"Head": "Preprocessing step 1", "Relation": "operation", "Tail": "drop_triples_with_score_below_alpha"}, {"Head": "Preprocessing step 2", "Relation": "operation", "Tail": "retain_unique_triple_with_highest_score_when_matching_multiple_sequences"}, {"Head": "Triple selection policy", "Relation": "priority_order", "Tail": "maximize_injection_score_then_maintain_relation_diversity"}, {"Head": "Maximize diversity procedure", "Relation": "method", "Tail": "bucket_relations_by_unique_triple_counts_select_rarest_relation_highest_score_in_bucket"}, {"Head": "Maximize score then diversity", "Relation": "method", "Tail": "bucket_by_score_then_apply_maximize_diversity_within_score_buckets_then_choose_highest_scoring_per_head"}, {"Head": "Algorithm implementation", "Relation": "framework", "Tail": "Pandas"}, {"Head": "Seed KG relation distribution (α=0.55)", "Relation": "dominant_relation", "Tail": "isa"}, {"Head": "GraphMERT-extracted KG relation distribution", "Relation": "dominant_relation", "Tail": "associated_with"}, {"Head": "GraphMERT helper LLM", "Relation": "biases_towards", "Tail": "selecting_associated_with_during_relation_matching"}, {"Head": "Sanity screening with GPT-5 Thinking", "Relation": "evaluated", "Tail": "small_samples_of_triples_for_IGF-1_and_GR_from_each_KG"}, {"Head": "GPT-5 screening_results_for_IGF-1", "Relation": "comparison", "Tail": "GraphMERT_higher_yes_proportion_than_LLM_KG"}, {"Head": "GPT-5 screening_results_for_GR", "Relation": "comparison", "Tail": "GraphMERT_higher_yes_and_lower_no_proportion_than_LLM_KG"}, {"Head": "Example GraphMERT-extracted triple", "Relation": "asserts", "Tail": "inflammasome_activation associated_with nlrp3_pathway"}, {"Head": "Seed KG", "Relation": "lacks_token", "Tail": "nlrp3"}, {"Head": "GraphMERT", "Relation": "learned_token", "Tail": "nlrp3"}, {"Head": "Score_bucket_size_and_relation_bucket_size", "Relation": "set_to", "Tail": "0.01_and_100_respectively_in_experiments"}, {"Head": "Table B1 top relation", "Relation": "reports_count", "Tail": "isa_8627_injections"}], "entity_relation_output": "[{\"Head\": \"Proper dataset valuation by pointwise mutual information\", \"Relation\": \"authored_by\", \"Tail\": \"Juan Qi; Rui Ray Chen; Yongchan Kwon; James Zou\"}, {\"Head\": \"A comprehensive survey on automatic knowledge graph construction\", \"Relation\": \"authored_by\", \"Tail\": \"Lingfeng Zhong; Jia Wu; Qian Li; Hao Peng; Xindong Wu\"}, {\"Head\": \"Problems with cosine as a measure of embedding similarity for high frequency words\", \"Relation\": \"authored_by\", \"Tail\": \"Kaitlyn Zhou; Kawin Ethayarajh; Dallas Card; Dan Jurafsky\"}, {\"Head\": \"Larger and more instructable language models become less reliable\", \"Relation\": \"authored_by\", \"Tail\": \"Lexin Zhou; Wout Schellaert; Fernando Martínez-Plumed; Yael Moros-Daval; Cèsar Ferri; José Hernández-Orallo\"}, {\"Head\": \"LLMs for knowledge graph construction and reasoning: Recent capabilities and future opportunities\", \"Relation\": \"authored_by\", \"Tail\": \"Yuqi Zhu; Xiaohan Wang; Jing Chen; Shuofei Qiao; Yixin Ou; Yunzhi Yao; Shumin Deng; Huajun Chen; Ningyu Zhang\"}, {\"Head\": \"UMLS relation has_associated_finding\", \"Relation\": \"characteristic\", \"Tail\": \"redundant_when_tail_equals_head\"}, {\"Head\": \"UMLS relation has_laterality\", \"Relation\": \"characteristic\", \"Tail\": \"few_possible_tails_mostly_side\"}, {\"Head\": \"Excluded UMLS relations list\", \"Relation\": \"includes\", \"Tail\": \"acted_on_by_process; active_ingredient_of; associated_procedure_of; basis_of_strength_substance_of; component_of; consider_from; direct_device_of; direct_substance_of; has_associated_finding; has_finding_context; has_interpretation; has_laterality; has_realization; has_scale_type; has_specimen; has_subject_relationship_context; has_temporal_context; inverse_was_a; mapped_from; mapped_to; moved_to; negatively_regulated_by; positively_regulated_by; possibly_replaces; precise_active_ingredient_of; realization_of; regulated_by; replaced_by; replaces; was_a; has_intent; referred_to_by; refers_to; characterizes; substance_used_by; specimen_source_topography_of; specimen_substance_of; has_active_ingredient; has_property\"}, {\"Head\": \"PubMed search query\", \"Relation\": \"filters\", \"Tail\": \"diabetes_terms AND NOT sars-cov-2_or_covid-19 within 2019-04-01 to 2025-04-01 medline\"}, {\"Head\": \"KG Injection Algorithm\", \"Relation\": \"inputs\", \"Tail\": \"sequences_with_heads; triples_T_per_sequence; triple_embedding_similarity_score; similarity_threshold_alpha\"}, {\"Head\": \"KG Injection Algorithm\", \"Relation\": \"outputs\", \"Tail\": \"at_most_one_injected_triple_per_head_per_sequence\"}, {\"Head\": \"Preprocessing step 1\", \"Relation\": \"operation\", \"Tail\": \"drop_triples_with_score_below_alpha\"}, {\"Head\": \"Preprocessing step 2\", \"Relation\": \"operation\", \"Tail\": \"retain_unique_triple_with_highest_score_when_matching_multiple_sequences\"}, {\"Head\": \"Triple selection policy\", \"Relation\": \"priority_order\", \"Tail\": \"maximize_injection_score_then_maintain_relation_diversity\"}, {\"Head\": \"Maximize diversity procedure\", \"Relation\": \"method\", \"Tail\": \"bucket_relations_by_unique_triple_counts_select_rarest_relation_highest_score_in_bucket\"}, {\"Head\": \"Maximize score then diversity\", \"Relation\": \"method\", \"Tail\": \"bucket_by_score_then_apply_maximize_diversity_within_score_buckets_then_choose_highest_scoring_per_head\"}, {\"Head\": \"Algorithm implementation\", \"Relation\": \"framework\", \"Tail\": \"Pandas\"}, {\"Head\": \"Seed KG relation distribution (α=0.55)\", \"Relation\": \"dominant_relation\", \"Tail\": \"isa\"}, {\"Head\": \"GraphMERT-extracted KG relation distribution\", \"Relation\": \"dominant_relation\", \"Tail\": \"associated_with\"}, {\"Head\": \"GraphMERT helper LLM\", \"Relation\": \"biases_towards\", \"Tail\": \"selecting_associated_with_during_relation_matching\"}, {\"Head\": \"Sanity screening with GPT-5 Thinking\", \"Relation\": \"evaluated\", \"Tail\": \"small_samples_of_triples_for_IGF-1_and_GR_from_each_KG\"}, {\"Head\": \"GPT-5 screening_results_for_IGF-1\", \"Relation\": \"comparison\", \"Tail\": \"GraphMERT_higher_yes_proportion_than_LLM_KG\"}, {\"Head\": \"GPT-5 screening_results_for_GR\", \"Relation\": \"comparison\", \"Tail\": \"GraphMERT_higher_yes_and_lower_no_proportion_than_LLM_KG\"}, {\"Head\": \"Example GraphMERT-extracted triple\", \"Relation\": \"asserts\", \"Tail\": \"inflammasome_activation associated_with nlrp3_pathway\"}, {\"Head\": \"Seed KG\", \"Relation\": \"lacks_token\", \"Tail\": \"nlrp3\"}, {\"Head\": \"GraphMERT\", \"Relation\": \"learned_token\", \"Tail\": \"nlrp3\"}, {\"Head\": \"Score_bucket_size_and_relation_bucket_size\", \"Relation\": \"set_to\", \"Tail\": \"0.01_and_100_respectively_in_experiments\"}, {\"Head\": \"Table B1 top relation\", \"Relation\": \"reports_count\", \"Tail\": \"isa_8627_injections\"}]", "event_entity_dict": [{"Event": "uan Qi, Rui Ray Chen, Yongchan Kwon, and James Zou published Proper dataset valuation by pointwise mutual information in 2025 on arXiv", "Entity": ["uan Qi", "Rui Ray Chen", "Yongchan Kwon", "James Zou", "Proper dataset valuation by pointwise mutual information", "arXiv", "2025"]}, {"Event": "Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu published A comprehensive survey on automatic knowledge graph construction in ACM Computing Surveys in November 2023", "Entity": ["Lingfeng Zhong", "Jia Wu", "Qian Li", "Hao Peng", "Xindong Wu", "A comprehensive survey on automatic knowledge graph construction", "ACM Computing Surveys", "November 2023"]}, {"Event": "Kaitlyn Zhou, Kawin Ethayarajh, Dallas Card, and Dan Jurafsky presented Problems with cosine as a measure of embedding similarity for high frequency words at the 60th Annual Meeting of the Association for Computational Linguistics in May 2022", "Entity": ["Kaitlyn Zhou", "Kawin Ethayarajh", "Dallas Card", "Dan Jurafsky", "Problems with cosine as a measure of embedding similarity for high frequency words", "60th Annual Meeting of the Association for Computational Linguistics", "May 2022"]}, {"Event": "Lexin Zhou, Wout Schellaert, Fernando Martínez-Plumed, Yael Moros-Daval, Cèsar Ferri, and José Hernández-Orallo published Larger and more instructable language models become less reliable in Nature in 2024", "Entity": ["Lexin Zhou", "Wout Schellaert", "Fernando Martínez-Plumed", "Yael Moros-Daval", "Cèsar Ferri", "José Hernández-Orallo", "Larger and more instructable language models become less reliable", "Nature", "2024"]}, {"Event": "Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, and Ningyu Zhang published LLMs for knowledge graph construction and reasoning in World Wide Web in August 2024", "Entity": ["Yuqi Zhu", "Xiaohan Wang", "Jing Chen", "Shuofei Qiao", "Yixin Ou", "Yunzhi Yao", "Shumin Deng", "Huajun Chen", "Ningyu Zhang", "LLMs for knowledge graph construction and reasoning", "World Wide Web", "August 2024"]}, {"Event": "The authors excluded some relations from the UMLS KG because they add little semantic value", "Entity": ["authors", "relations", "UMLS KG"]}, {"Event": "has_associated_finding was identified as a redundant relation where the tail subject is the same as the head subject", "Entity": ["has_associated_finding", "tail subject", "head subject"]}, {"Event": "has_laterality was given as an example of a relation with very few possible tails", "Entity": ["has_laterality", "tails", "'side'"]}, {"Event": "The paper presented a Table A1 listing excluded UMLS relations", "Entity": ["Table A1", "Excluded UMLS relations"]}, {"Event": "A PubMed search query was specified to retrieve diabetes-related records excluding SARS-CoV-2 and COVID-19 between 2019/04/01 and 2025/04/01", "Entity": ["PubMed search query", "diabetes", "SARS-CoV-2", "COVID-19", "2019/04/01", "2025/04/01", "medline"]}, {"Event": "The KG injection algorithm input included sequences with heads, triples per head capped at 40, triple embedding similarity scores, and a similarity matching threshold α", "Entity": ["KG injection algorithm", "sequences with heads", "triples", "score(T)", "α", "40"]}, {"Event": "Preprocessing step 1 dropped all triples with a score less than threshold α", "Entity": ["preprocessing step 1", "triples", "score", "α"]}, {"Event": "Preprocessing step 2 made all triples unique by retaining the triple with the highest score when a triple matched multiple sequences", "Entity": ["preprocessing step 2", "triples", "sequences", "score"]}, {"Event": "Triple selection prioritized maximizing injection score first and relation diversity second", "Entity": ["triple selection", "injection score", "relation diversity"]}, {"Event": "Maximize diversity split relations into buckets by number of unique triples and retained the highest-scoring triple from the rarest bucket for each head", "Entity": ["Maximize diversity", "relations", "relation buckets", "triples", "heads"]}, {"Event": "Maximize score then diversity ordered triples by score into buckets and applied Maximize diversity within each score bucket", "Entity": ["Maximize score then diversity", "triples", "score buckets"]}, {"Event": "The algorithm was implemented using the Pandas framework and presented as Algorithm 1", "Entity": ["algorithm", "Pandas framework", "Algorithm 1"]}, {"Event": "Table B1 reported seed KG relation injection counts for α = 0.55 in the training split", "Entity": ["Table B1", "seed KG", "relation injection counts", "α = 0.55", "training split", "Qwen3-32B"]}, {"Event": "Figure C1 compared relation distributions between the GraphMERT-extracted KG and the seed KG and noted differing prevalent relations", "Entity": ["Figure C1", "GraphMERT-extracted KG", "seed KG", "isa", "associated_with"]}, {"Event": "A lightweight screening with GPT-5 Thinking was run on small comparable samples from each KG as a sanity check complementary to benchmark-based verification", "Entity": ["lightweight screening", "GPT-5 Thinking", "GraphMERT KG", "LLM KG", "sanity check", "benchmark-based verification"]}, {"Event": "For each KG, triples with heads containing 'insulin-like growth factor 1 (IGF-1)' and 'glucocorticoid receptor (GR)' were retrieved for human-inspectable samples", "Entity": ["KG", "triples", "insulin-like growth factor 1 (IGF-1)", "glucocorticoid receptor (GR)"]}, {"Event": "The prompt asked evaluators to judge if medical KG triples are valid (yes/no/maybe) and provide a very short reason", "Entity": ["prompt", "evaluators", "medical KG triples", "yes/no/maybe"]}, {"Event": "Table C1 presented an example GraphMERT-extracted triple where the seed KG did not include the token 'nlrp3' which was learned from text", "Entity": ["Table C1", "GraphMERT-extracted triple", "nlrp3", "seed KG", "pathway", "inflammasome activation", "nlrp3 pathway"]}, {"Event": "Table C2 summarized GPT-5 Thinking screening counts and proportions for IGF-1 and GR across LLM and GraphMERT KGs", "Entity": ["Table C2", "GPT-5 Thinking", "IGF-1", "GR", "LLM KG", "GraphMERT KG"]}], "event_entity_output": "[{\"Event\": \"uan Qi, Rui Ray Chen, Yongchan Kwon, and James Zou published Proper dataset valuation by pointwise mutual information in 2025 on arXiv\", \"Entity\": [\"uan Qi\", \"Rui Ray Chen\", \"Yongchan Kwon\", \"James Zou\", \"Proper dataset valuation by pointwise mutual information\", \"arXiv\", \"2025\"]}, {\"Event\": \"Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu published A comprehensive survey on automatic knowledge graph construction in ACM Computing Surveys in November 2023\", \"Entity\": [\"Lingfeng Zhong\", \"Jia Wu\", \"Qian Li\", \"Hao Peng\", \"Xindong Wu\", \"A comprehensive survey on automatic knowledge graph construction\", \"ACM Computing Surveys\", \"November 2023\"]}, {\"Event\": \"Kaitlyn Zhou, Kawin Ethayarajh, Dallas Card, and Dan Jurafsky presented Problems with cosine as a measure of embedding similarity for high frequency words at the 60th Annual Meeting of the Association for Computational Linguistics in May 2022\", \"Entity\": [\"Kaitlyn Zhou\", \"Kawin Ethayarajh\", \"Dallas Card\", \"Dan Jurafsky\", \"Problems with cosine as a measure of embedding similarity for high frequency words\", \"60th Annual Meeting of the Association for Computational Linguistics\", \"May 2022\"]}, {\"Event\": \"Lexin Zhou, Wout Schellaert, Fernando Martínez-Plumed, Yael Moros-Daval, Cèsar Ferri, and José Hernández-Orallo published Larger and more instructable language models become less reliable in Nature in 2024\", \"Entity\": [\"Lexin Zhou\", \"Wout Schellaert\", \"Fernando Martínez-Plumed\", \"Yael Moros-Daval\", \"Cèsar Ferri\", \"José Hernández-Orallo\", \"Larger and more instructable language models become less reliable\", \"Nature\", \"2024\"]}, {\"Event\": \"Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, and Ningyu Zhang published LLMs for knowledge graph construction and reasoning in World Wide Web in August 2024\", \"Entity\": [\"Yuqi Zhu\", \"Xiaohan Wang\", \"Jing Chen\", \"Shuofei Qiao\", \"Yixin Ou\", \"Yunzhi Yao\", \"Shumin Deng\", \"Huajun Chen\", \"Ningyu Zhang\", \"LLMs for knowledge graph construction and reasoning\", \"World Wide Web\", \"August 2024\"]}, {\"Event\": \"The authors excluded some relations from the UMLS KG because they add little semantic value\", \"Entity\": [\"authors\", \"relations\", \"UMLS KG\"]}, {\"Event\": \"has_associated_finding was identified as a redundant relation where the tail subject is the same as the head subject\", \"Entity\": [\"has_associated_finding\", \"tail subject\", \"head subject\"]}, {\"Event\": \"has_laterality was given as an example of a relation with very few possible tails\", \"Entity\": [\"has_laterality\", \"tails\", \"'side'\"]}, {\"Event\": \"The paper presented a Table A1 listing excluded UMLS relations\", \"Entity\": [\"Table A1\", \"Excluded UMLS relations\"]}, {\"Event\": \"A PubMed search query was specified to retrieve diabetes-related records excluding SARS-CoV-2 and COVID-19 between 2019/04/01 and 2025/04/01\", \"Entity\": [\"PubMed search query\", \"diabetes\", \"SARS-CoV-2\", \"COVID-19\", \"2019/04/01\", \"2025/04/01\", \"medline\"]}, {\"Event\": \"The KG injection algorithm input included sequences with heads, triples per head capped at 40, triple embedding similarity scores, and a similarity matching threshold α\", \"Entity\": [\"KG injection algorithm\", \"sequences with heads\", \"triples\", \"score(T)\", \"α\", \"40\"]}, {\"Event\": \"Preprocessing step 1 dropped all triples with a score less than threshold α\", \"Entity\": [\"preprocessing step 1\", \"triples\", \"score\", \"α\"]}, {\"Event\": \"Preprocessing step 2 made all triples unique by retaining the triple with the highest score when a triple matched multiple sequences\", \"Entity\": [\"preprocessing step 2\", \"triples\", \"sequences\", \"score\"]}, {\"Event\": \"Triple selection prioritized maximizing injection score first and relation diversity second\", \"Entity\": [\"triple selection\", \"injection score\", \"relation diversity\"]}, {\"Event\": \"Maximize diversity split relations into buckets by number of unique triples and retained the highest-scoring triple from the rarest bucket for each head\", \"Entity\": [\"Maximize diversity\", \"relations\", \"relation buckets\", \"triples\", \"heads\"]}, {\"Event\": \"Maximize score then diversity ordered triples by score into buckets and applied Maximize diversity within each score bucket\", \"Entity\": [\"Maximize score then diversity\", \"triples\", \"score buckets\"]}, {\"Event\": \"The algorithm was implemented using the Pandas framework and presented as Algorithm 1\", \"Entity\": [\"algorithm\", \"Pandas framework\", \"Algorithm 1\"]}, {\"Event\": \"Table B1 reported seed KG relation injection counts for α = 0.55 in the training split\", \"Entity\": [\"Table B1\", \"seed KG\", \"relation injection counts\", \"α = 0.55\", \"training split\", \"Qwen3-32B\"]}, {\"Event\": \"Figure C1 compared relation distributions between the GraphMERT-extracted KG and the seed KG and noted differing prevalent relations\", \"Entity\": [\"Figure C1\", \"GraphMERT-extracted KG\", \"seed KG\", \"isa\", \"associated_with\"]}, {\"Event\": \"A lightweight screening with GPT-5 Thinking was run on small comparable samples from each KG as a sanity check complementary to benchmark-based verification\", \"Entity\": [\"lightweight screening\", \"GPT-5 Thinking\", \"GraphMERT KG\", \"LLM KG\", \"sanity check\", \"benchmark-based verification\"]}, {\"Event\": \"For each KG, triples with heads containing 'insulin-like growth factor 1 (IGF-1)' and 'glucocorticoid receptor (GR)' were retrieved for human-inspectable samples\", \"Entity\": [\"KG\", \"triples\", \"insulin-like growth factor 1 (IGF-1)\", \"glucocorticoid receptor (GR)\"]}, {\"Event\": \"The prompt asked evaluators to judge if medical KG triples are valid (yes/no/maybe) and provide a very short reason\", \"Entity\": [\"prompt\", \"evaluators\", \"medical KG triples\", \"yes/no/maybe\"]}, {\"Event\": \"Table C1 presented an example GraphMERT-extracted triple where the seed KG did not include the token 'nlrp3' which was learned from text\", \"Entity\": [\"Table C1\", \"GraphMERT-extracted triple\", \"nlrp3\", \"seed KG\", \"pathway\", \"inflammasome activation\", \"nlrp3 pathway\"]}, {\"Event\": \"Table C2 summarized GPT-5 Thinking screening counts and proportions for IGF-1 and GR across LLM and GraphMERT KGs\", \"Entity\": [\"Table C2\", \"GPT-5 Thinking\", \"IGF-1\", \"GR\", \"LLM KG\", \"GraphMERT KG\"]}]", "event_relation_dict": [{"Head": "We exclude some relations from the UMLS KG that add little semantic value", "Relation": "because", "Tail": "custom-defined mappings of outdated-to-new UMLS relations for backward compatibility cannot be inferred from external data"}, {"Head": "We exclude some relations from the UMLS KG that add little semantic value", "Relation": "because", "Tail": "relations used only for cross-vocabulary mappings add little semantic value"}, {"Head": "has_associated_finding is a redundant relation", "Relation": "because", "Tail": "in these cases the tail subject is the same as the head subject"}, {"Head": "has_laterality is an example of a relation with very few possible tails", "Relation": "as a result", "Tail": "almost all tails are 'side'"}, {"Head": "The second preprocessing step prevents overfitting in the semantic space on common triples", "Relation": "because", "Tail": "it retains for a triple the sequence to which the triple is most relevant when a triple matches multiple sequences"}, {"Head": "Drop all triples with a score less than threshold α", "Relation": "before", "Tail": "make all triples unique by retaining the triple with the highest score when a triple matches multiple sequences"}, {"Head": "To balance contextual relevance with relation diversity we prioritize maximize injection score then maintain relation diversity", "Relation": "before", "Tail": "we measure relation diversity by the number of unique triples that contain the relation"}, {"Head": "Split relations into relation buckets based on the number of unique triples", "Relation": "before", "Tail": "within each relation bucket sort all triples by score regardless of relation"}, {"Head": "Start with the lowest-numbered bucket and retain only the highest-score triple for its head", "Relation": "as a result", "Tail": "one of the rarest possible relations in the dataset would survive for this head, increasing relation diversity overall"}, {"Head": "Order triples by score and split into score buckets", "Relation": "before", "Tail": "within each score bucket apply Maximize diversity"}, {"Head": "Altogether, we group triples by how 'low' the score is and then favor less frequent relation types within each score bucket", "Relation": "as a result", "Tail": "we choose the highest-scoring triple for each head"}, {"Head": "The algorithm is implemented using the Pandas framework and presented in Algorithm 1", "Relation": "at the same time", "Tail": "In our experiments, we use score_bucket_size = 0.01 and relation_bucket_size = 100"}, {"Head": "Figure C1 shows the relation distribution on a logarithmic scale", "Relation": "because", "Tail": "it illustrates that while 'isa' is most represented in the training data, the helper LLM tends to select 'associated_with' most frequently during relation matching"}, {"Head": "This reflects the helper LLM's inclination to select 'associated_with' during relation matching", "Relation": "as a result", "Tail": "the GraphMERT KG is heavily skewed towards 'associated_with' compared to the seed KG"}, {"Head": "We ran a lightweight screening with GPT-5 Thinking on small, comparable samples from each KG", "Relation": "before", "Tail": "this screening should be viewed as complementary to benchmark-based verification"}, {"Head": "For each KG we retrieved all triples whose head contains the keywords 'insulin-like growth factor 1 (IGF-1)' and 'glucocorticoid receptor (GR)'", "Relation": "before", "Tail": "the screening evaluated if these medical KG triples are valid and gave a very short reason why"}, {"Head": "Table C2 summarizes screening results", "Relation": "after", "Tail": "we present counts and proportions of yes/maybe/no judgments for IGF-1 and GR across KGs"}, {"Head": "Table C1 shows an example GraphMERT-extracted triple with novel tail vocabulary", "Relation": "because", "Tail": "the seed KG does not include the token 'nlrp3' and 'pathway' was learned and extracted from the text"}], "event_relation_output": "[{\"Head\": \"We exclude some relations from the UMLS KG that add little semantic value\", \"Relation\": \"because\", \"Tail\": \"custom-defined mappings of outdated-to-new UMLS relations for backward compatibility cannot be inferred from external data\"}, {\"Head\": \"We exclude some relations from the UMLS KG that add little semantic value\", \"Relation\": \"because\", \"Tail\": \"relations used only for cross-vocabulary mappings add little semantic value\"}, {\"Head\": \"has_associated_finding is a redundant relation\", \"Relation\": \"because\", \"Tail\": \"in these cases the tail subject is the same as the head subject\"}, {\"Head\": \"has_laterality is an example of a relation with very few possible tails\", \"Relation\": \"as a result\", \"Tail\": \"almost all tails are 'side'\"}, {\"Head\": \"The second preprocessing step prevents overfitting in the semantic space on common triples\", \"Relation\": \"because\", \"Tail\": \"it retains for a triple the sequence to which the triple is most relevant when a triple matches multiple sequences\"}, {\"Head\": \"Drop all triples with a score less than threshold α\", \"Relation\": \"before\", \"Tail\": \"make all triples unique by retaining the triple with the highest score when a triple matches multiple sequences\"}, {\"Head\": \"To balance contextual relevance with relation diversity we prioritize maximize injection score then maintain relation diversity\", \"Relation\": \"before\", \"Tail\": \"we measure relation diversity by the number of unique triples that contain the relation\"}, {\"Head\": \"Split relations into relation buckets based on the number of unique triples\", \"Relation\": \"before\", \"Tail\": \"within each relation bucket sort all triples by score regardless of relation\"}, {\"Head\": \"Start with the lowest-numbered bucket and retain only the highest-score triple for its head\", \"Relation\": \"as a result\", \"Tail\": \"one of the rarest possible relations in the dataset would survive for this head, increasing relation diversity overall\"}, {\"Head\": \"Order triples by score and split into score buckets\", \"Relation\": \"before\", \"Tail\": \"within each score bucket apply Maximize diversity\"}, {\"Head\": \"Altogether, we group triples by how 'low' the score is and then favor less frequent relation types within each score bucket\", \"Relation\": \"as a result\", \"Tail\": \"we choose the highest-scoring triple for each head\"}, {\"Head\": \"The algorithm is implemented using the Pandas framework and presented in Algorithm 1\", \"Relation\": \"at the same time\", \"Tail\": \"In our experiments, we use score_bucket_size = 0.01 and relation_bucket_size = 100\"}, {\"Head\": \"Figure C1 shows the relation distribution on a logarithmic scale\", \"Relation\": \"because\", \"Tail\": \"it illustrates that while 'isa' is most represented in the training data, the helper LLM tends to select 'associated_with' most frequently during relation matching\"}, {\"Head\": \"This reflects the helper LLM's inclination to select 'associated_with' during relation matching\", \"Relation\": \"as a result\", \"Tail\": \"the GraphMERT KG is heavily skewed towards 'associated_with' compared to the seed KG\"}, {\"Head\": \"We ran a lightweight screening with GPT-5 Thinking on small, comparable samples from each KG\", \"Relation\": \"before\", \"Tail\": \"this screening should be viewed as complementary to benchmark-based verification\"}, {\"Head\": \"For each KG we retrieved all triples whose head contains the keywords 'insulin-like growth factor 1 (IGF-1)' and 'glucocorticoid receptor (GR)'\", \"Relation\": \"before\", \"Tail\": \"the screening evaluated if these medical KG triples are valid and gave a very short reason why\"}, {\"Head\": \"Table C2 summarizes screening results\", \"Relation\": \"after\", \"Tail\": \"we present counts and proportions of yes/maybe/no judgments for IGF-1 and GR across KGs\"}, {\"Head\": \"Table C1 shows an example GraphMERT-extracted triple with novel tail vocabulary\", \"Relation\": \"because\", \"Tail\": \"the seed KG does not include the token 'nlrp3' and 'pathway' was learned and extracted from the text\"}]"}
{"id": "1", "original_text": "c crosstalk. | | insulin-like growth factor 1 (IGF1), associated_with, transcription | maybe | Indirect gene-expression effects. | | insulin-like growth factor 1 (IGF-1), associated_with, hyperglycemia | maybe | Context dependent. | | insulin-like growth factor 1 level, associated_with, growth hormone treatment | yes | GH raises IGF-1. | | insulin/insulin-like growth factor 1 (IGF-1) signaling pathway, has_component, insulin receptor | yes | IR is in pathway. | | insulin-like growth factor 1 (IGF1), plays_role, downstream target | maybe | Phrasing vague (GH downstream). | Table C4: (Part 1 of 2). LLM KG (Qwen3-32B). Sanity check with GPT-5 Thinking. We select all KG triples that contain 'insulin-like growth factor-1,' 29 triples in total, yes/no/maybe: 8/18/3 . /negationslash | Triple | Verdict | GPT-5 explanation | |-------------------------------------------------------------------------------------------------------------|-----------|------------------------------------| | insulin-like growth factor 1, associated_with, diabetes | yes | Linked with DM. | | insulin-like growth factor 1 (IGF-1), has_direct_substance, type 2 diabetes | no | Disease = substance. | | insulin-like growth factor 1, associated_with, insulin resistance | yes | Strong physiologic link. | | insulin-like growth factor 1, associated_with, metabolic syndrome | yes | Levels track MetS. | | insulin-like growth factor 1 (IGF-1), associated_with, chronic kidney disease | yes | GH/IGF axis altered. | | insulin-like growth factor 1 (IGF-1), has_direct_substance, gestational diabetes mellitus (GDM) | no | Disease = substance. | | insulin-like growth factor 1 (IGF1), has_direct_substance, angiogenesis | no | Process, not substance. | | insulin-like growth factor 1 (IGF-1), has_direct_substance, short-chain fatty acids (SCFAs) | no | Unrelated metabolites. | | insulin-like growth factor 1 (IGF-1), has_component, insulin signaling pathway | no | Pathway = component of ligand. | | insulin-like growth factor 1 (IGF-1), plays_role, cardiovascular health | maybe | Broad/context-dependent. | | insulin-like growth factor 1 (IGF-1), associated_with, bone metabolism | yes | Anabolic for bone. | | insulin-like growth factor 1, has_part, growth hormone | no | GH regulates; not part. | | insulin-like growth factor 1 (IGF-1), cause_of, prostate cancer (PCA) | no | Association = causation. | | insulin-like growth factor 1 (IGF-1), has_modification, left ventricular global longitudinal strain (LVGLS) | no | Clinical metric, not modification. | | insulin-like growth factor 1 receptor, cause_of, epithelial-mesenchymal transition | maybe | Signaling can induce EMT. | | insulin-like growth factor 1 (IGF-1), has_modification, HAAT-MSCs | no | Not a molecular modification. | | insulin-like growth factor 1, has_direct_substance, testis | no | Organ produces IGF-1. | | insulin-like growth factor 1, plays_role, endocrine-related cancers | maybe | Vague class-level claim. | /negationslash /negationslash /negationslash Table C4: (Part 2 of 2). LLM KG (Qwen3-32B). (continued) | Triple | Verdict | GPT-5 explanation | |-----------------------------------------------------------------------------------------------------------------------|-----------|--------------------------------------------| | insulin-like growth factor 1, associated_with, oocyte cohort quality | yes | Follicular IGF-1 correlates. | | insulin-like growth factor 1 (IGF1), has_component, phosphoinositide 3-kinase (PI3K) | no | Downstream effector, not component. | | insulin-like growth factor 1 receptor, isa, receptor | yes | Canonical RTK. | | insulin-like growth factor 1 receptor, has_direct_substance, lactate dehydrogenase a | no | Not a receptor substance. | | insulin-like growth factor 1 (IGF1), has_pathological_process, core body temperature | no | Not a pathology. | | insulin-like growth factor 1 (IGF1), has_component, IGF-binding protein 3 (IGFBP3) | no | Binding partner, not component. | | insulin-like growth factor 1 receptor, has_method, JAKS2/STAT3 pathway | no | Wrong relation/atypical pathway. | | insulin-like growth factor 1 (IGF1), has_component, ZYG11A | no | Unrelated protein. | | insulin-like growth factor 1 receptor (IGF-1R), has_part, nositide 3-kinase (PI3K) | no | PI3K is recruited, not part. | | IGF-1 (insulin-like growth factor 1), has_direct_substance, PPAR γ (peroxisome proliferator-activated receptor gamma) | no | transcription factor = substance of IGF-1. | | insulin-like growth factor 1, plays_role, cardiac development | yes | Supports cardiac growth. | /negationslash Table C5: GraphMERT KG. Sanity check with GPT-5 Thinking. We select all KG triples that contain 'glucocorticoid receptor,' 28 triples in total, yes/no/maybe: 15/6/7 . | Triple | Verdict | GPT-5 explanation | |-------------------------------------------------------------------------------------------|-----------|--------------------------------------------------------| | endothelial glucocorticoid receptor, plays_role, therapeutic role | maybe | Role is vague/context-dependent. | | endothelial glucocorticoid receptor, plays_role, | yes | Mediates GC signaling in endothelium. | | glucocorticoid signaling endothelial glucocorticoid receptor, plays_role, protective role | maybe | Protective effects reported but not universal. | | glucocorticoid receptor (GR), plays_role, glucocorticoid signaling | yes | Canonical function. | | glucocorticoid receptor, associated_with, insulin signaling | yes | Well-known pathway crosstalk. | | glucocorticoid receptor, has_part, ligand-binding | maybe | Should be 'ligand-binding domain.' | | endothelial glucocorticoid receptor, has_disposition, signaling | no | Wrong relation; participates in signaling. | | glucocorticoid receptor, plays_role, glucocorticoid receptor signaling | yes | Tautologically true. | | glucocorticoid receptor (GR), plays_role, hypothalamic signaling | maybe | HPA feedback involvement but broad. | | endothelial glucocorticoid receptor, has_disposition, immunomodulator | no | 'Immunomodulator' is an agent role, not a disposition. | | glucocorticoid receptor (GR), plays_role, steroid signaling | yes | Nuclear steroid receptor pathway. | | glucocorticoid receptor (GR), associated_with, glucocorticoids | yes | Binds GC ligands. | | glucocorticoid receptor agonists, plays_role, therapeutic | yes | Used clinically. | | glucocorticoid receptor (GR), plays_role, steroid hormone receptor | no | This is an is_a identity, not a role. | | glucocorticoid receptor gene (NR3C1), associated_with, hormone receptor | maybe | Gene encodes one; relation imprecise. | | glucocorticoid receptor, plays_role, signaling | yes | Ligand-activated signaling/TF activity. are steroids. | | glucocorticoid receptor (GR), associated_with, steroid | yes | Glucocorticoids | | selective glucocorticoid receptor agonists, plays_role, | maybe | Class intended for therapy; phrasing vague. | | therapeutic role endothelial glucocorticoid receptor, cause_of, renal fibrosis | no | GR generally anti-fibrotic; causation unsupported. | | selective glucocorticoid receptor modulators, plays_role, pharmacological modulator | no | Category is is_a, not a role. | | glucocorticoid receptor, associated_with, glucocorticoids | yes | Duplicate; correct. | | glucocorticoid receptor (GR), plays_role, glucocorticoid signaling | yes | Duplicate; correct. | | glucocorticoid receptor α , plays_role, steroid receptor | no | α isoform is_a steroid receptor, not a role. | | glucocorticoid receptor (GR), associated_with, transcription | yes | Ligand-activated transcription factor. | | glucocorticoid receptor, plays_role, signaling | yes | Duplicate; correct. | | glucocorticoid receptor (GR), associated_with, hormone | yes | Responds to hormones (GCs). | | glucocorticoid receptor (GR), associated_with, signaling | yes | Broad but true. | | selective glucocorticoid receptor modulators, plays_role, pharmacological modulator | no | Duplicate; is_a, not a role. | Table C6: LLM KG (Qwen3-32B). Sanity check with GPT-5 Thinking. We select all KG triples that contain 'glucocorticoid receptor,' 24 triples in total, yes/no/maybe: 4/18/2 . /negationslash | Triple | Verdict | GPT-5 explanation | |------------------------------------------------------------------------------------------------------------------|-----------|---------------------------------------------------------------| | glucocorticoid receptor haploinsufficiency, cause_of, hypertension | yes | GR resistance drives mineralocorticoid excess → hypertension. | | glucocorticoid receptor, associated_with, insulin resistance | yes | GC/GR signaling induces IR. | | glucocorticoid receptor locus (GRL) polymorphisms, associated_with, type 2 diabetes (T2D) | yes | NR3C1 variants linked to T2D risk. | | podocyte-specific glucocorticoid receptor knockout (GR pKO) mice, has_pathological_process, diabetic nephropathy | yes | Podocyte GR loss worsens DN phenotype. | | glucocorticoid receptor, has_component, autophagy | no | Autophagy is a process, not a receptor component. | | glucocorticoid receptor (GR), finding_site_of, liver | no | Relation reversed; GR is located in liver. | | glucocorticoid receptor, has_component, diabetic complications (GR), | no | Diseases aren't receptor components. | | endothelial glucocorticoid receptor has_causative_agent, renal fibrosis | no | Relation misuse; fibrosis doesn't 'cause' the receptor. | | glucocorticoid receptor, has_disposition, cortisol | no | Cortisol is a ligand, not a disposition. | | glucocorticoid receptor alpha, has_component, coronavirus disease 2019 | no | COVID-19 isn't a component. | | glucocorticoid receptor, has_component, estrogen endothelial glucocorticoid receptor (GR), | no | Hormone = receptor component. WNT signaling isn't inherently | | has_pathological_process, WNT signaling glucocorticoid receptor, | no | pathological. | | has_pathological_process, osteoporosis (OP) | maybe | Excess GR signaling leads to GC-induced OP; relation loose. | | glucocorticoid receptor, has_direct_substance, PEPCK | no | GR regulates PEPCK expression; not a substance of GR. | | glucocorticoid receptor (GR), has_direct_substance, Kupffer cells | no | Cells aren't receptor substances. | | glucocorticoid receptor (GR), has_component, Leydig cells | no | Tissues/cells aren't components of a receptor. | | glucocorticoid receptor, has_direct_substance, stress response | no | Process = substance. | | glucocorticoid receptor, associated_with, miR-32-5p | maybe | Limited, context-specific miRNA linkage. | | glucocorticoid receptor, has_direct_substance, G6P | no | Metabolite isn't a receptor substance. | | glucocorticoid receptor, has_component, SETD1A/COMPASS complex | no | Possible cofactor interaction, not a component. | | glucocorticoid receptor (GR), has_direct_substance, STAT6 | no | TF interactor, not a substance of GR. | | glucocorticoid receptor (GR), has_direct_substance, adipose tissue macrophage (ATM) | no | Cells = substances. | | glucocorticoid receptor (GR), has_component, peripheral sensory neurons | no | Neurons aren't receptor components. | | glucocorticoid receptor β (GR β )has_direct_substancers948820149 | no | SNP pertains to gene, not isoform 'substance.' | /negationslash /negationslash ## D GraphRAG evaluation on Medical Benchmarks Table D1: GraphRAG KG evaluation on public benchmarks | # Questions | MedMCQA 61 | MedQA 75 | MMLU (medical) 62 | |-------------------|--------------|------------|---------------------| | LLM KG (baseline) | 72.1 | 85.3 | 71 | | Seed KG | 76.5 | 81.3 | 73.1 | | GraphMERT | 73.8 | 88 | 74.7 | In this evaluation, we select questions related to diabetes and its comorbidities from popular medical benchmarks and run GraphRAG evaluation on the selected questions. We first filter the benchmarks with the Qwen3-32B model, as stated in Section 5.3.2, and then manually review and remove some questions that are irrelevant to diabetes. ## E Helper LLM prompts We include only one example for all few-shot settings. For each prompt, all examples are mined from the dataset. Then, we prompt GPT-o3 with the zero-shot prompt, edit the reply if needed, and include it as a few-shot example. All sequences in our datasets are lower-case; here, we use normal case to improve readability. ## Entity Discovery Prompt You are a medical-domain extractor building a diabetes KG of 〈 head, relation, tail 〉 . You possess advanced medical academic knowledge. Given an input sequence, identify entities specifically relevant to diabetes, its complications, comorbidities, therapeutics, and related biomedical entities that help to clarify or contextualize them. Output a Python list of up to 6-word entity 'heads' following these rules: 1. Select a precise and medically-specific span (e.g., 'myocardial infarction,' not 'infarction'). Avoid generic terms like 'disease,' 'condition,' 'patients,' and 'comorbidity' without a specific context. When encountering vague descriptors like 'complication,' 'symptom,' or 'effect,' always prefer explicitly named conditions or symptoms directly linked to diabetes pathology or diabetes comorbidities. 2. Keep original spelling, casing, and abbreviations from the sequence. 3. Choose only entities that add meaningful medical knowledge to the diabetes KG. Do not include COVIDrelated terms. Do not include head entities that describe findings in animal models (mice, rats, etc.). 4. A few examples of low-value entities you should not include: - ' ≥ 10 % weight reduction' (too context-dependent). - 'nhanes 2015 -2018' (dataset/survey, not a medical entity). - 'semaglutide 2.4 mg' (includ", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "associated_with", "Tail": "diabetes"}, {"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "associated_with", "Tail": "insulin resistance"}, {"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "associated_with", "Tail": "metabolic syndrome"}, {"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "associated_with", "Tail": "chronic kidney disease"}, {"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "plays_role", "Tail": "bone metabolism"}, {"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "plays_role", "Tail": "cardiac development"}, {"Head": "insulin-like growth factor 1 level", "Relation": "increased_by", "Tail": "growth hormone treatment"}, {"Head": "insulin/insulin-like growth factor 1 (IGF-1) signaling pathway", "Relation": "has_component", "Tail": "insulin receptor"}, {"Head": "insulin-like growth factor 1 (IGF-1)", "Relation": "associated_with", "Tail": "oocyte cohort quality"}, {"Head": "insulin-like growth factor 1 receptor (IGF-1R)", "Relation": "isa", "Tail": "receptor"}, {"Head": "glucocorticoid receptor (GR)", "Relation": "plays_role", "Tail": "glucocorticoid signaling"}, {"Head": "glucocorticoid receptor (GR)", "Relation": "associated_with", "Tail": "insulin signaling"}, {"Head": "glucocorticoid receptor (GR)", "Relation": "associated_with", "Tail": "insulin resistance"}, {"Head": "glucocorticoid receptor (GR)", "Relation": "associated_with", "Tail": "glucocorticoids"}, {"Head": "glucocorticoid receptor haploinsufficiency", "Relation": "cause_of", "Tail": "hypertension"}, {"Head": "glucocorticoid receptor locus (NR3C1) polymorphisms", "Relation": "associated_with", "Tail": "type 2 diabetes"}, {"Head": "podocyte-specific glucocorticoid receptor knockout", "Relation": "has_pathological_process", "Tail": "diabetic nephropathy"}, {"Head": "endothelial glucocorticoid receptor", "Relation": "plays_role", "Tail": "endothelial glucocorticoid signaling"}, {"Head": "glucocorticoid receptor (GR)", "Relation": "plays_role", "Tail": "transcription"}], "entity_relation_output": "[{\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"associated_with\", \"Tail\": \"diabetes\"}, {\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"associated_with\", \"Tail\": \"insulin resistance\"}, {\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"associated_with\", \"Tail\": \"metabolic syndrome\"}, {\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"associated_with\", \"Tail\": \"chronic kidney disease\"}, {\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"plays_role\", \"Tail\": \"bone metabolism\"}, {\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"plays_role\", \"Tail\": \"cardiac development\"}, {\"Head\": \"insulin-like growth factor 1 level\", \"Relation\": \"increased_by\", \"Tail\": \"growth hormone treatment\"}, {\"Head\": \"insulin/insulin-like growth factor 1 (IGF-1) signaling pathway\", \"Relation\": \"has_component\", \"Tail\": \"insulin receptor\"}, {\"Head\": \"insulin-like growth factor 1 (IGF-1)\", \"Relation\": \"associated_with\", \"Tail\": \"oocyte cohort quality\"}, {\"Head\": \"insulin-like growth factor 1 receptor (IGF-1R)\", \"Relation\": \"isa\", \"Tail\": \"receptor\"}, {\"Head\": \"glucocorticoid receptor (GR)\", \"Relation\": \"plays_role\", \"Tail\": \"glucocorticoid signaling\"}, {\"Head\": \"glucocorticoid receptor (GR)\", \"Relation\": \"associated_with\", \"Tail\": \"insulin signaling\"}, {\"Head\": \"glucocorticoid receptor (GR)\", \"Relation\": \"associated_with\", \"Tail\": \"insulin resistance\"}, {\"Head\": \"glucocorticoid receptor (GR)\", \"Relation\": \"associated_with\", \"Tail\": \"glucocorticoids\"}, {\"Head\": \"glucocorticoid receptor haploinsufficiency\", \"Relation\": \"cause_of\", \"Tail\": \"hypertension\"}, {\"Head\": \"glucocorticoid receptor locus (NR3C1) polymorphisms\", \"Relation\": \"associated_with\", \"Tail\": \"type 2 diabetes\"}, {\"Head\": \"podocyte-specific glucocorticoid receptor knockout\", \"Relation\": \"has_pathological_process\", \"Tail\": \"diabetic nephropathy\"}, {\"Head\": \"endothelial glucocorticoid receptor\", \"Relation\": \"plays_role\", \"Tail\": \"endothelial glucocorticoid signaling\"}, {\"Head\": \"glucocorticoid receptor (GR)\", \"Relation\": \"plays_role\", \"Tail\": \"transcription\"}]", "event_entity_dict": [{"Event": "Insulin-like growth factor 1 (IGF1) is associated with transcription.", "Entity": ["insulin-like growth factor 1 (IGF1)", "transcription"]}, {"Event": "Insulin-like growth factor 1 (IGF-1) is associated with hyperglycemia.", "Entity": ["insulin-like growth factor 1 (IGF-1)", "hyperglycemia"]}, {"Event": "Insulin-like growth factor 1 level is associated with growth hormone treatment.", "Entity": ["insulin-like growth factor 1 level", "growth hormone treatment"]}, {"Event": "The insulin/insulin-like growth factor 1 (IGF-1) signaling pathway has the insulin receptor as a component.", "Entity": ["insulin/insulin-like growth factor 1 (IGF-1) signaling pathway", "insulin receptor"]}, {"Event": "Insulin-like growth factor 1 (IGF1) is described as playing the role of a downstream target.", "Entity": ["insulin-like growth factor 1 (IGF1)", "downstream target"]}, {"Event": "Insulin-like growth factor 1 is associated with diabetes.", "Entity": ["insulin-like growth factor 1", "diabetes"]}, {"Event": "Insulin-like growth factor 1 is associated with insulin resistance.", "Entity": ["insulin-like growth factor 1", "insulin resistance"]}, {"Event": "Insulin-like growth factor 1 is associated with metabolic syndrome.", "Entity": ["insulin-like growth factor 1", "metabolic syndrome"]}, {"Event": "Insulin-like growth factor 1 (IGF-1) is associated with chronic kidney disease.", "Entity": ["insulin-like growth factor 1 (IGF-1)", "chronic kidney disease"]}, {"Event": "Insulin-like growth factor 1 (IGF-1) is associated with bone metabolism.", "Entity": ["insulin-like growth factor 1 (IGF-1)", "bone metabolism"]}, {"Event": "Insulin-like growth factor 1 is reported as causing prostate cancer in one triple but this causal claim is rejected.", "Entity": ["insulin-like growth factor 1", "prostate cancer"]}, {"Event": "Insulin-like growth factor 1 is reported in relation to left ventricular global longitudinal strain but the relation is rejected.", "Entity": ["insulin-like growth factor 1", "left ventricular global longitudinal strain (LVGLS)"]}, {"Event": "Insulin-like growth factor 1 receptor is reported as possibly causing epithelial-mesenchymal transition.", "Entity": ["insulin-like growth factor 1 receptor", "epithelial-mesenchymal transition"]}, {"Event": "Insulin-like growth factor 1 is reported as playing a role in cardiovascular health.", "Entity": ["insulin-like growth factor 1", "cardiovascular health"]}, {"Event": "Insulin-like growth factor 1 (IGF-1) is noted as having been linked to oocyte cohort quality.", "Entity": ["insulin-like growth factor 1 (IGF-1)", "oocyte cohort quality"]}, {"Event": "Insulin-like growth factor 1 (IGF1) is reported as having cardiac development roles.", "Entity": ["insulin-like growth factor 1 (IGF1)", "cardiac development"]}, {"Event": "Insulin-like growth factor 1 receptor is categorized as a receptor (isa relation).", "Entity": ["insulin-like growth factor 1 receptor", "receptor"]}, {"Event": "Glucocorticoid receptor (GR) plays a role in glucocorticoid signaling.", "Entity": ["glucocorticoid receptor (GR)", "glucocorticoid signaling"]}, {"Event": "Endothelial glucocorticoid receptor is described as mediating glucocorticoid signaling in endothelium.", "Entity": ["endothelial glucocorticoid receptor", "glucocorticoid signaling", "endothelium"]}, {"Event": "Endothelial glucocorticoid receptor is discussed as having a possible therapeutic role.", "Entity": ["endothelial glucocorticoid receptor", "therapeutic role"]}, {"Event": "Glucocorticoid receptor is associated with insulin signaling.", "Entity": ["glucocorticoid receptor", "insulin signaling"]}, {"Event": "Glucocorticoid receptor plays a role in steroid signaling.", "Entity": ["glucocorticoid receptor (GR)", "steroid signaling"]}, {"Event": "Glucocorticoid receptor is associated with glucocorticoids.", "Entity": ["glucocorticoid receptor (GR)", "glucocorticoids"]}, {"Event": "Glucocorticoid receptor agonists play a therapeutic role.", "Entity": ["glucocorticoid receptor agonists", "therapeutic role"]}, {"Event": "Glucocorticoid receptor plays a role in transcription as a ligand-activated transcription factor.", "Entity": ["glucocorticoid receptor (GR)", "transcription"]}, {"Event": "Glucocorticoid receptor plays a role in general signaling functions.", "Entity": ["glucocorticoid receptor", "signaling"]}, {"Event": "Glucocorticoid receptor haploinsufficiency is reported to cause hypertension.", "Entity": ["glucocorticoid receptor haploinsufficiency", "hypertension"]}, {"Event": "Glucocorticoid receptor is associated with insulin resistance.", "Entity": ["glucocorticoid receptor", "insulin resistance"]}, {"Event": "Glucocorticoid receptor locus polymorphisms are associated with type 2 diabetes (T2D).", "Entity": ["glucocorticoid receptor locus (GRL) polymorphisms", "type 2 diabetes (T2D)"]}, {"Event": "Podocyte-specific glucocorticoid receptor knockout mice exhibit a pathological process of diabetic nephropathy.", "Entity": ["podocyte-specific glucocorticoid receptor knockout (GR pKO) mice", "diabetic nephropathy"]}, {"Event": "Glucocorticoid receptor is reported as associated with miR-32-5p in a context-specific manner.", "Entity": ["glucocorticoid receptor", "miR-32-5p"]}, {"Event": "Glucocorticoid receptor is discussed in relation to osteoporosis as a possible pathological process when signaling is excessive.", "Entity": ["glucocorticoid receptor", "osteoporosis (OP)"]}], "event_entity_output": "[{\"Event\": \"Insulin-like growth factor 1 (IGF1) is associated with transcription.\", \"Entity\": [\"insulin-like growth factor 1 (IGF1)\", \"transcription\"]}, {\"Event\": \"Insulin-like growth factor 1 (IGF-1) is associated with hyperglycemia.\", \"Entity\": [\"insulin-like growth factor 1 (IGF-1)\", \"hyperglycemia\"]}, {\"Event\": \"Insulin-like growth factor 1 level is associated with growth hormone treatment.\", \"Entity\": [\"insulin-like growth factor 1 level\", \"growth hormone treatment\"]}, {\"Event\": \"The insulin/insulin-like growth factor 1 (IGF-1) signaling pathway has the insulin receptor as a component.\", \"Entity\": [\"insulin/insulin-like growth factor 1 (IGF-1) signaling pathway\", \"insulin receptor\"]}, {\"Event\": \"Insulin-like growth factor 1 (IGF1) is described as playing the role of a downstream target.\", \"Entity\": [\"insulin-like growth factor 1 (IGF1)\", \"downstream target\"]}, {\"Event\": \"Insulin-like growth factor 1 is associated with diabetes.\", \"Entity\": [\"insulin-like growth factor 1\", \"diabetes\"]}, {\"Event\": \"Insulin-like growth factor 1 is associated with insulin resistance.\", \"Entity\": [\"insulin-like growth factor 1\", \"insulin resistance\"]}, {\"Event\": \"Insulin-like growth factor 1 is associated with metabolic syndrome.\", \"Entity\": [\"insulin-like growth factor 1\", \"metabolic syndrome\"]}, {\"Event\": \"Insulin-like growth factor 1 (IGF-1) is associated with chronic kidney disease.\", \"Entity\": [\"insulin-like growth factor 1 (IGF-1)\", \"chronic kidney disease\"]}, {\"Event\": \"Insulin-like growth factor 1 (IGF-1) is associated with bone metabolism.\", \"Entity\": [\"insulin-like growth factor 1 (IGF-1)\", \"bone metabolism\"]}, {\"Event\": \"Insulin-like growth factor 1 is reported as causing prostate cancer in one triple but this causal claim is rejected.\", \"Entity\": [\"insulin-like growth factor 1\", \"prostate cancer\"]}, {\"Event\": \"Insulin-like growth factor 1 is reported in relation to left ventricular global longitudinal strain but the relation is rejected.\", \"Entity\": [\"insulin-like growth factor 1\", \"left ventricular global longitudinal strain (LVGLS)\"]}, {\"Event\": \"Insulin-like growth factor 1 receptor is reported as possibly causing epithelial-mesenchymal transition.\", \"Entity\": [\"insulin-like growth factor 1 receptor\", \"epithelial-mesenchymal transition\"]}, {\"Event\": \"Insulin-like growth factor 1 is reported as playing a role in cardiovascular health.\", \"Entity\": [\"insulin-like growth factor 1\", \"cardiovascular health\"]}, {\"Event\": \"Insulin-like growth factor 1 (IGF-1) is noted as having been linked to oocyte cohort quality.\", \"Entity\": [\"insulin-like growth factor 1 (IGF-1)\", \"oocyte cohort quality\"]}, {\"Event\": \"Insulin-like growth factor 1 (IGF1) is reported as having cardiac development roles.\", \"Entity\": [\"insulin-like growth factor 1 (IGF1)\", \"cardiac development\"]}, {\"Event\": \"Insulin-like growth factor 1 receptor is categorized as a receptor (isa relation).\", \"Entity\": [\"insulin-like growth factor 1 receptor\", \"receptor\"]}, {\"Event\": \"Glucocorticoid receptor (GR) plays a role in glucocorticoid signaling.\", \"Entity\": [\"glucocorticoid receptor (GR)\", \"glucocorticoid signaling\"]}, {\"Event\": \"Endothelial glucocorticoid receptor is described as mediating glucocorticoid signaling in endothelium.\", \"Entity\": [\"endothelial glucocorticoid receptor\", \"glucocorticoid signaling\", \"endothelium\"]}, {\"Event\": \"Endothelial glucocorticoid receptor is discussed as having a possible therapeutic role.\", \"Entity\": [\"endothelial glucocorticoid receptor\", \"therapeutic role\"]}, {\"Event\": \"Glucocorticoid receptor is associated with insulin signaling.\", \"Entity\": [\"glucocorticoid receptor\", \"insulin signaling\"]}, {\"Event\": \"Glucocorticoid receptor plays a role in steroid signaling.\", \"Entity\": [\"glucocorticoid receptor (GR)\", \"steroid signaling\"]}, {\"Event\": \"Glucocorticoid receptor is associated with glucocorticoids.\", \"Entity\": [\"glucocorticoid receptor (GR)\", \"glucocorticoids\"]}, {\"Event\": \"Glucocorticoid receptor agonists play a therapeutic role.\", \"Entity\": [\"glucocorticoid receptor agonists\", \"therapeutic role\"]}, {\"Event\": \"Glucocorticoid receptor plays a role in transcription as a ligand-activated transcription factor.\", \"Entity\": [\"glucocorticoid receptor (GR)\", \"transcription\"]}, {\"Event\": \"Glucocorticoid receptor plays a role in general signaling functions.\", \"Entity\": [\"glucocorticoid receptor\", \"signaling\"]}, {\"Event\": \"Glucocorticoid receptor haploinsufficiency is reported to cause hypertension.\", \"Entity\": [\"glucocorticoid receptor haploinsufficiency\", \"hypertension\"]}, {\"Event\": \"Glucocorticoid receptor is associated with insulin resistance.\", \"Entity\": [\"glucocorticoid receptor\", \"insulin resistance\"]}, {\"Event\": \"Glucocorticoid receptor locus polymorphisms are associated with type 2 diabetes (T2D).\", \"Entity\": [\"glucocorticoid receptor locus (GRL) polymorphisms\", \"type 2 diabetes (T2D)\"]}, {\"Event\": \"Podocyte-specific glucocorticoid receptor knockout mice exhibit a pathological process of diabetic nephropathy.\", \"Entity\": [\"podocyte-specific glucocorticoid receptor knockout (GR pKO) mice\", \"diabetic nephropathy\"]}, {\"Event\": \"Glucocorticoid receptor is reported as associated with miR-32-5p in a context-specific manner.\", \"Entity\": [\"glucocorticoid receptor\", \"miR-32-5p\"]}, {\"Event\": \"Glucocorticoid receptor is discussed in relation to osteoporosis as a possible pathological process when signaling is excessive.\", \"Entity\": [\"glucocorticoid receptor\", \"osteoporosis (OP)\"]}]", "event_relation_dict": [{"Head": "growth hormone treatment raises IGF-1", "Relation": "before", "Tail": "IGF-1 is associated with diabetes"}, {"Head": "IGF-1 is associated with insulin resistance", "Relation": "as a result", "Tail": "IGF-1 is associated with hyperglycemia"}, {"Head": "the insulin/insulin-like growth factor 1 signaling pathway includes the insulin receptor", "Relation": "at the same time", "Tail": "the insulin receptor is a component of the insulin/IGF-1 signaling pathway"}], "event_relation_output": "[{\"Head\": \"growth hormone treatment raises IGF-1\", \"Relation\": \"before\", \"Tail\": \"IGF-1 is associated with diabetes\"}, {\"Head\": \"IGF-1 is associated with insulin resistance\", \"Relation\": \"as a result\", \"Tail\": \"IGF-1 is associated with hyperglycemia\"}, {\"Head\": \"the insulin/insulin-like growth factor 1 signaling pathway includes the insulin receptor\", \"Relation\": \"at the same time\", \"Tail\": \"the insulin receptor is a component of the insulin/IGF-1 signaling pathway\"}]"}
{"id": "1", "original_text": "es a dosage, which can vary). - '60+ women' ('60+' is too context-dependent). - 'anxiety,' 'home births,' 'pregnant women,' 'neonatal deaths,' 'general practitioners' (not specific enough to diabetes; only include if explicitly related to diabetes). 5. If it is not clear whether a term adds diabetes-specific knowledge, look at the context. If the text explicitly links the term to a diabetes-specific concept, include it. Otherwise, exclude it when mentioned only in a generic context. Include such terms when the sequence clearly links them to a diabetes-relevant gene, pathway, cell type, or therapeutic effect. You will be provided with incorrect output examples beginning with 'Output (Incorrect).' Use them to avoid the common mistakes. Wrap your intermediate reasoning steps clearly within 〈 think 〉 ... 〈 /think 〉 tags. Be strict and discard any entity about which you are uncertain and that is not relevant to diabetes. After generating, verify your output. ## Steps: 1. Identify candidate spans. 2. Filter by medical precision and relevance rules. 3. Confirm the entity's relevance and contribution to the diabetes KG; discard low-value entities. Input format: sequence Output format: ['head1', 'head2', ...] . If none, output [] . ## Input: sequence: . . . , its upstream regulator has the opposite effect (Han et al., 2013). Previous studies suggest that CHOP deteriorates ER stress and accelerates cell death via promoting protein synthesis and oxidative stress (Han et al., 2013). In addition, ER stress damages β -cells, possibly through altering Ca 2+ homeostasis. It has been indicated that ER stress interferes with the function of RyR located in the membrane of the ER and causes leakage of ER Ca 2+ (Yamamoto et al., 2019). The destruction of β -cell ER Ca 2+ homeostasis results in impaired insulin secretion and further promotion of β -cell death . . . ``` Output: [''chop,'' ``` ''er stress,'' ''ryr,'' ''$\\beta$-cells,'' ''impaired insulin secretion''] The rationale behind the output: Candidates: CHOP; ER stress; β -cells; RyR; impaired insulin secretion; oxidative stress; protein synthesis. Keep precise diabetes-relevant entities: CHOP (ER stress regulator), ER stress, β -cells, RyR, impaired insulin secretion. ## Relation Matching Prompt You are a medical intelligence with academic knowledge in diabetes and comorbidities. We are building a diabetes knowledge graph of triples 〈 head, relation, tail 〉 . ## Given: - a sequence including biomedical context, - a list of heads, return, for each head, all relations chosen from the list below that could form a plausible KG triple and are supported by the sequence. ## Allowed relations: ### | associated_finding_of | has_associated_morphology | inverse_isa | |--------------------------|-----------------------------|------------------------| | associated_morphology_of | has_component | is_interpreted_by | | associated_with | has_disposition | isa | | causative_agent_of | has_finding_site | occurs_before | | cause_of | has_method | part_of | | due_to | has_modification | plays_role | | finding_site_of | has_part | possibly_equivalent_to | | focus_of | interprets | | ## ### The relations are taken from UMLS and have the same meaning as in UMLS. Examples: ------------- - carotid artery stenosis | associated\\_finding\\_of | history of carotid artery stenosis - fibrosis | associated\\_morphology\\_of | endomyocardial fibrosis - cancer | associated\\_with | anemia in malignant neoplastic disease - Mycobacterium tuberculosis | causative\\_agent\\_of | Tuberculosis - diabetes mellitus | cause\\_of | diabetic foot - hypoglycemic alcoholic ketoacidosis | due\\_to | acute alcohol intoxication - adipose tissue | finding\\_site\\_of | lipoatrophy - renal failure | focus\\_of | emergency hemofiltration ## Few-shot Example for Entity Discovery Prompt - hepatitis A | has\\_associated\\_morphology | Hepatocellular necrosis - fasting triglyceride | has\\_component | triacylglycerol - tumor necrosis factor | has\\_disposition | immunomodulator - melanoma | has\\_finding\\_site | skin - bariatric surgery | has\\_method | surgical action - glucagon | has\\_modification | glucagon hydrochloride - nephron | has\\_part | glomerulus - overweight | interprets | body weight measure - adiponectin | inverse\\_isa | high molecular weight adiponectin - blood eosinophil counts | is\\_interpreted\\_by | asthmatic pulmonary eosinophilia - empagliflozin | isa | sodium glucose cotransporter subtype 2 inhibitor - cardiac amyloidosis | occurs\\_in | old age - coronary syndrome | possibly\\_equivalent\\_to | preinfarction syndrome - MI | same\\_as | Myocardial infarction ------------- Note the meaning of some relations in UMLS: isa and inverse\\_isa are exact inverses of each other. - isa - points up the hierarchy: 'Diabetic retinopathy' isa 'Retinal disease.' (specific → general) - inverse\\_isa - points down the hierarchy: 'Retinal disease' inverse\\_isa 'Diabetic retinopathy.' - cause\\_of - directional link where the source concept is understood to directly or indirectly produce, trigger, or give rise to the target concept. - due\\_to - causal link: the subject condition, finding, or situation results from the object. Inverse: cause\\_of . - associated\\_with -non-directional link indicating that two concepts are statistically or clinically linked without asserting a clear cause-and-effect direction. - has\\_associated\\_morphology - links a pathological or clinical entity (typically a disease, syndrome, or injury) to the characteristic structural change ('morphology') it produces. Concretely: source = disorder concept; target = morphologic abnormality (e.g., 'Necrosis,' 'Hyperplasia,' 'Fibrosis'). Inverse: associated\\_morphology\\_of . - associated\\_finding\\_of - reads as: 'X associated\\_finding\\_of Y' 'Finding X is the clinical finding for which procedure Y is performed.' ``` -------------Input format: sequence heads: [head1, head2, ...] Output format: { ''head 1'': [''relation 1,'' ''relation 2,'' ...], ''head 2'': [...], } ``` Steps: 1. Understand Input - Clearly understand the biomedical context from the sequence. - For each head, find explicit mentions in the text. - Check if each head is explicitly linked to other concepts or relations. 2. Use the list of allowed relations. Evaluate each head individually. Do not overuse the relation associated\\_with - apply it only when appropriate. 3. For each head, list only plausible and supported relations. Return [] if none apply. Think concisely within 〈 think 〉 ... 〈 /think 〉 . Immediately after, output JSON. ## Input: . . . interleukin-1 R6, and receptor activator of nuclear factor kappa-B (RANK). Together, proteomic data suggest the targeting of several key regulators of inflammation, bone, and adipose turnover, via transforming growth factor-beta/SMAD, and Wingless-related integration site/be-catenin signaling pathways. To the best of the knowledge, this is first evidence of an intervention that drives against bone loss via RANK. Metatranscriptomic analyses of the gut microbiota show P7C3 increased Porphyromonadaceae bacterium, Candidatus Melainabacteria, and Ruminococcaceae bacterium abundance, potentially contributing to the favorable inflammatory. . . ``` heads: ['interleukin-1 r6,' 'receptor activator of nuclear factor kappa-b,' 'transforming growth factor-beta'] Output: { ''interleukin-1 r6'': [''associated_with''], ''receptor activator of nuclear factor kappa-b'': [''cause_of''], ''transforming growth factor-beta'': [''part_of''], } The rationale behind this output: ``` interleukin-1 r6 → associated\\_with → Named as a 'key regulator of inflammation,' which links it to the inflammatory process without stating direction or hierarchy, so the non-causal associated\\_with relation fits best. receptor activator of nuclear factor κ -B (RANK) → cause\\_of → The text says the intervention prevents bone loss via RANK, implying that RANK signalling produces or drives bone loss; therefore cause\\_of is appropriate. transforming growth factor-beta → part\\_of → Explicitly mentioned within the 'TGFβ /Smad signalling pathway,' so it is a constituent component ( part\\_of ) of that pathway. No additional relations are warranted. ## Combining GraphMERT -predicted Top Tokens Prompt You are completing triples for a medical knowledge graph on diabetes and its comorbidities. For each sample, you're given a sequence, a head entity in that sequence, a relation, and a list of candidate tokens. The relations are from UMLS and have the same meaning. ``` Your task is to output a filtered list of high-quality and factual tails in the format: [''tail 1,'' ''tail 2,'' ...] or [] . ``` ## To form the list of candidates: Step 1: Analyze the sequence to understand the context and identify the head entity and relation. Step 2: Choose candidate tails. You can combine tokens from the candidate list to get the most precise, relevant, and meaningful tails in the context of the head and relation. Combine subword tokens, too. Step 3: Verify each candidate. ## Verification. Each tail must: - Be causally and factually related to the head via the specified relation. Make sure the relation direction is correct: the head implies the tail given the relation. Note that isa is a subclass → class relation, and inverse\\_isa is a class → subclass relation. ## Few-shot Example for the Relation Matching Prompt - Be supported by the sequence, but you can rely on well-established medical knowledge even if the sequence does not spell it out verbatim. If no reliable support exists, reject the tail. - Add valuable medical knowledge to the graph. Tails must be non-redundant. When all tails are factual, prefer specific tails over general and vague (e.g., 'proliferative diabetic retinopathy' over 'retinopathy'). Terms that include 'level,' 'disease,' 'disorder,' or 'complication' are too vague and rarely add useful knowledge to the KG. - Include only tokens from the list of candidates. Reason step by step within &lt;think&gt;...&lt;/think&gt; . You will see incorrect outputs labeled 'Output (Incorrect).' Avoid similar errors. ## Before finalizing: - Ensure all output constraints are met. - Validate that each tail is logically, contextually, and factually aligned with the head and relation. - Confirm that each triple adds meaningful knowledge to the graph. Note the meaning of some UMLS relations you may encounter in the input: - isa and inverse\\_isa are exact inverses of each other. - -isa - points up the hierarchy: 'Diabetic retinopathy' isa 'Retinal disease.' (specific → general) - -inverse\\_isa - points down the hierarchy: 'Retinal disease' inverse\\_isa 'Diabetic retinopathy.' - cause\\_of - directional link where the source concept directly or indirectly produces, triggers, or gives rise to the target concept. - due\\_to - causal link: the subject condition, finding, or situation results from the object. Inverse: cause\\_of . - associated\\_with - non-directional link indicating that two concepts are statistically or clinically linked without asserting a clear cause-effect direction. - • - has\\_associated\\_morphology - links a pathological or clinical entity (typically a disease, syndrome, or injury) to the characteristic structural change ('morphology') it produces. Concretely: source = a disorder concept; target = a Morphologic Abnormality concept (e.g., 'Necrosis,' 'Hyperplasia,' 'Fibrosis'). Inverse: associated\\_morphology\\_of . - associated\\_finding\\_of - reads as: - 'X associated\\_finding\\_of Y' ⇒ 'Finding X is the clinical finding for which procedure Y is performed.' ## Few-Shot Example for Combining GraphMERT -predicted Top Tokens Prompt ## Input: sequence: . . . 2+ binding to S100A1 EF-hand motifs, the conformation of S100A1 changes and promotes interactions with target proteins. RAGE consists of three domains: the cytoplasmic, transmembrane, and extracellular domains. The extracellular domain consists of C1, C2, and V domains. V domains are the primary receptors for the S100 protein. It was reported several years ago that S100A1 and RAGE V domains interact in a pathway involving S100A1-RAGE signaling, whereby S100A1 binds to the V domain, resulting in RAGE dimerization. The autophosphorylation of the cytoplasmic domain initiates a signaling cascade that regulates cell proliferation, cell growth, and tumor formation. In this study. . . head: [''s100a1''] relation: associated\\_with predictions: protein receptor hydrolase structure process pathway factor complex glycoprotein s100a family domain oxidoreductase proteinase ligand extracellular signaling calcium apolipoprotein s100 ## Output: ## [''calcium signaling pathway''] ## The rationale behind this output: Available tokens let us build terms such as: - 'calcium signaling pathway' (calcium + signaling + pathway) - 'extracellular signaling' (extracellular + signaling) - too broad - 's100a family' - classification, not an association Other tokens ('glycoprotein,' 'oxidoreductase,' etc.) do not represent well-known processes linked to S100A1. ## Preference &amp; verification: 'S100A1 modulates intracellular Ca 2+ handling and is well-documented to participate in the calcium signaling pathway, especially in cardiac and skeletal muscle.' This is a concrete biological pathway association that adds value to the graph. ## F GraphRAG Prompts ## -Role- You are an AI assistant specialized in extracting structured information from biomedical texts to build a knowledge graph about diabetes. ## -Goal- Given some medical paper abstracts, a predefined list of entity types, and a predefined list of relations, identify all entities of those types and the medically meaningful rela", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "CHOP", "Relation": "promotes", "Tail": "protein synthesis"}, {"Head": "CHOP", "Relation": "promotes", "Tail": "oxidative stress"}, {"Head": "CHOP", "Relation": "worsens", "Tail": "ER stress"}, {"Head": "CHOP", "Relation": "accelerates", "Tail": "β-cell death"}, {"Head": "ER stress", "Relation": "damages", "Tail": "β-cells"}, {"Head": "ER stress", "Relation": "interferes_with", "Tail": "RyR function"}, {"Head": "RyR", "Relation": "causes", "Tail": "leakage of ER Ca2+"}, {"Head": "Leakage of ER Ca2+", "Relation": "disrupts", "Tail": "β-cell ER Ca2+ homeostasis"}, {"Head": "Disruption of β-cell ER Ca2+ homeostasis", "Relation": "results_in", "Tail": "impaired insulin secretion"}, {"Head": "Impaired insulin secretion", "Relation": "promotes", "Tail": "β-cell death"}], "entity_relation_output": "[{\"Head\": \"CHOP\", \"Relation\": \"promotes\", \"Tail\": \"protein synthesis\"}, {\"Head\": \"CHOP\", \"Relation\": \"promotes\", \"Tail\": \"oxidative stress\"}, {\"Head\": \"CHOP\", \"Relation\": \"worsens\", \"Tail\": \"ER stress\"}, {\"Head\": \"CHOP\", \"Relation\": \"accelerates\", \"Tail\": \"β-cell death\"}, {\"Head\": \"ER stress\", \"Relation\": \"damages\", \"Tail\": \"β-cells\"}, {\"Head\": \"ER stress\", \"Relation\": \"interferes_with\", \"Tail\": \"RyR function\"}, {\"Head\": \"RyR\", \"Relation\": \"causes\", \"Tail\": \"leakage of ER Ca2+\"}, {\"Head\": \"Leakage of ER Ca2+\", \"Relation\": \"disrupts\", \"Tail\": \"β-cell ER Ca2+ homeostasis\"}, {\"Head\": \"Disruption of β-cell ER Ca2+ homeostasis\", \"Relation\": \"results_in\", \"Tail\": \"impaired insulin secretion\"}, {\"Head\": \"Impaired insulin secretion\", \"Relation\": \"promotes\", \"Tail\": \"β-cell death\"}]", "event_entity_dict": [{"Event": "Its upstream regulator has the opposite effect.", "Entity": ["upstream regulator", "CHOP", "opposite effect"]}, {"Event": "Previous studies suggest that CHOP deteriorates ER stress and accelerates cell death via promoting protein synthesis and oxidative stress.", "Entity": ["CHOP", "ER stress", "cell death", "protein synthesis", "oxidative stress"]}, {"Event": "ER stress damages β-cells, possibly through altering Ca2+ homeostasis.", "Entity": ["ER stress", "β-cells", "Ca2+ homeostasis"]}, {"Event": "ER stress interferes with the function of RyR located in the membrane of the ER and causes leakage of ER Ca2+.", "Entity": ["ER stress", "RyR", "ER membrane", "ER Ca2+ leakage"]}, {"Event": "The destruction of β-cell ER Ca2+ homeostasis results in impaired insulin secretion and further promotion of β-cell death.", "Entity": ["destruction of β-cell ER Ca2+ homeostasis", "impaired insulin secretion", "β-cell death"]}], "event_entity_output": "[{\"Event\": \"Its upstream regulator has the opposite effect.\", \"Entity\": [\"upstream regulator\", \"CHOP\", \"opposite effect\"]}, {\"Event\": \"Previous studies suggest that CHOP deteriorates ER stress and accelerates cell death via promoting protein synthesis and oxidative stress.\", \"Entity\": [\"CHOP\", \"ER stress\", \"cell death\", \"protein synthesis\", \"oxidative stress\"]}, {\"Event\": \"ER stress damages β-cells, possibly through altering Ca2+ homeostasis.\", \"Entity\": [\"ER stress\", \"β-cells\", \"Ca2+ homeostasis\"]}, {\"Event\": \"ER stress interferes with the function of RyR located in the membrane of the ER and causes leakage of ER Ca2+.\", \"Entity\": [\"ER stress\", \"RyR\", \"ER membrane\", \"ER Ca2+ leakage\"]}, {\"Event\": \"The destruction of β-cell ER Ca2+ homeostasis results in impaired insulin secretion and further promotion of β-cell death.\", \"Entity\": [\"destruction of β-cell ER Ca2+ homeostasis\", \"impaired insulin secretion\", \"β-cell death\"]}]", "event_relation_dict": [{"Head": "CHOP promotes protein synthesis and oxidative stress", "Relation": "because", "Tail": "CHOP deteriorates ER stress and accelerates cell death"}, {"Head": "CHOP deteriorates ER stress and accelerates cell death", "Relation": "before", "Tail": "ER stress damages β-cells by altering Ca2+ homeostasis"}, {"Head": "ER stress interferes with RyR function and causes leakage of ER Ca2+", "Relation": "because", "Tail": "ER stress damages β-cells by altering Ca2+ homeostasis"}, {"Head": "ER stress interferes with RyR function and causes leakage of ER Ca2+", "Relation": "before", "Tail": "Destruction of β-cell ER Ca2+ homeostasis results in impaired insulin secretion"}, {"Head": "Impaired insulin secretion", "Relation": "as a result", "Tail": "further promotion of β-cell death"}], "event_relation_output": "[{\"Head\": \"CHOP promotes protein synthesis and oxidative stress\", \"Relation\": \"because\", \"Tail\": \"CHOP deteriorates ER stress and accelerates cell death\"}, {\"Head\": \"CHOP deteriorates ER stress and accelerates cell death\", \"Relation\": \"before\", \"Tail\": \"ER stress damages β-cells by altering Ca2+ homeostasis\"}, {\"Head\": \"ER stress interferes with RyR function and causes leakage of ER Ca2+\", \"Relation\": \"because\", \"Tail\": \"ER stress damages β-cells by altering Ca2+ homeostasis\"}, {\"Head\": \"ER stress interferes with RyR function and causes leakage of ER Ca2+\", \"Relation\": \"before\", \"Tail\": \"Destruction of β-cell ER Ca2+ homeostasis results in impaired insulin secretion\"}, {\"Head\": \"Impaired insulin secretion\", \"Relation\": \"as a result\", \"Tail\": \"further promotion of β-cell death\"}]"}
{"id": "1", "original_text": "tionships explicitly described among the identified entities within the abstract. You should only extract entities that are relevant to diabetes, its complications, and comorbidites. ## -Entitiy Types- You should extract entities from the following 5 entity types: Organism, Anatomical Structure, Manufactured Object, Substance, Conceptual Entity. Use the subcategories listed below SOLELY as guidance to help you determine the correct main entity type. Only use the 5 main entity types in your output. 1. Organism: Plant; Fungus; Virus; Bacterium; Archaeon; Eukaryote; Vertebrate; Amphibian; Bird; Fish; Reptile; Mammal; Human 2. Anatomical Structure: Embryonic Structure; Anatomical Abnormality; Congenital Abnormality; Acquired Abnormality; Fully Formed Anatomical Structure; Body Part, Organ, or Organ Component; Tissue; Cell; Cell Component; Gene or Genome 3. Manufactured Object: Medical Device; Drug Delivery Device; Research Device; Clinical Drug 4. Substance: Chemical; Pharmacologic Substance; Antibiotic; Biomedical or Dental Material; Biologically Active Substance; Hormone; Enzyme; Vitamin; Immunologic Factor; Receptor; Indicator, Reagent, or Diagnostic Aid; Organic Chemical; Nucleic Acid, Nucleoside, or Nucleotide; Amino Acid, Peptide, or Protein; Inorganic Chemical; Element, Ion, or Isotope; Body Substance; Food 5. Conceptual Entity: Idea or Concept; Body System; Body Space or Junction; Body Location or Region; Molecular Sequence; Nucleotide Sequence; Amino Acid Sequence; Carbohydrate Sequence; Geographic Area; Finding; Laboratory or Test Result; Sign or Symptom; Organism Attribute; Clinical Attribute; Intellectual Product; Occupation or Discipline; Organization; Group ## -Relation Types- Please only identify the following 35 relations: ['associated\\_finding\\_of,' 'associated\\_morphology\\_of,' 'as-sociated\\_with,' 'causative\\_agent\\_of,' 'cause\\_of,' 'direct\\_procedure\\_site\\_of,' 'due\\_to,' 'finding\\_site\\_of,' 'focus\\_of,' 'has\\_associated\\_morphology,' 'has\\_causative\\_agent,' 'has\\_clinical\\_course,' 'has\\_component,' 'has\\_direct\\_procedure\\_site,' 'has\\_direct\\_substance,' 'has\\_disposition,' 'has\\_entire\\_anatomy\\_structure,' 'has\\_finding\\_site,' 'has\\_focus,' 'has\\_method,' 'has\\_modification,' 'has\\_part,' 'has\\_pathological\\_process,' 'interprets,' 'inverse\\_isa,' 'is\\_interpreted\\_by,' 'is\\_modification\\_of,' 'isa,' 'method\\_of,' 'occurs\\_before', 'oc-curs\\_in,' 'part\\_of,' 'plays\\_role,' 'possibly\\_equivalent\\_to,' 'same\\_as'] The following provides one example for each type of relation, formatted as 'head, relation, tail': fetal growth restriction (fgr), associated\\_finding\\_of, history of fetal growth retardation tumors, associated\\_morphology\\_of, neoplastic disease neutropenia, associated\\_with, neutropenic sepsis s. epidermidis, causative\\_agent\\_of, staphylococcus epidermidis ventriculitis chronic kidney disease (ckd), cause\\_of, renal retinopathy gastric fundus, direct\\_procedure\\_site\\_of, laparoscopic fundoplication diabetic cardiomyopathy (dbcm), due\\_to, diabetes mellitus endocrine pancreas, finding\\_site\\_of, extreme insulin resistance type a gait abnormalities, focus\\_of, prosthetic gait training pyoderma gangrenosum, has\\_associated\\_morphology, neutrophilic infiltration chronic chagas disease cardiomyopathy, has\\_causative\\_agent, trypanosoma cruzi membranous nephropathy, has\\_clinical\\_course, chronic ## E1: GraphRAG Index Prompt serum creatinine level, has\\_component, creatinine fmt, has\\_direct\\_procedure\\_site, gastrointestinal tract structure high-intensity statins, has\\_direct\\_substance, hmg-coa reductase inhibitor resveratrol (res), has\\_disposition, platelet aggregation inhibitor middle occipital gyrus, has\\_entire\\_anatomy\\_structure, entire lateral occipital gyrus diabetes retinopathy, has\\_finding\\_site, retinal structure on-line hemodiafiltration, has\\_focus, renal failure syndrome islet cell transplant, has\\_method, surgical transplantation uric acid, has\\_modification, calcium urate anaerobic glycolysis, has\\_part, pyruvate kinase activity evans syndrome, has\\_pathological\\_process, autoimmune process endocrine hypertension, interprets, blood pressure adaptive thermogenesis, inverse\\_isa, diet induced thermogenesis serum triglyceride, is\\_interpreted\\_by, serum triglyceride levels tau, is\\_modification\\_of, uridine t cell receptors, isa, antigen receptor amputation, method\\_of, cineplastic amputation renal transplantation, occurs\\_before, accelerated rejection of renal transplant paediatric obesity, occurs\\_in, childhood bone resorption, part\\_of, bone remodeling everolimus (eve), plays\\_role, antineoplastic therapeutic role non-alcoholic fatty liver disease, possibly\\_equivalent\\_to, fatty liver retinal cotton wool spots, same\\_as, retinal exudates ## -Steps- 1. Identify all entities corresponding to one of the 5 main entity types and relevant to diabetes, using the subcategory examples as guidance for classification. For each identified entity, extract the following information: - entity\\_name: Name of the entity, lowercase - entity\\_type: One of the following types: Organism, Anatomical Structure, Manufactured Object, Substance, Conceptual Entity. 3. -entity\\_description: concise description of the entity's attributes and activities. Format each entity as ('entity'&lt;|&gt;&lt;entity\\_name&gt;&lt;|&gt;&lt;entity\\_type&gt;&lt;|&gt;&lt;entity\\_description&gt;) 2. From the entities identified in step 1, identify all pairs of (source\\_entity, target\\_entity) that are clearly related to each other according to the given text, and are medically meaningful. Only use the 35 relationships that are in the predefined list. Avoid relationships that are attached to entities that are too general, for example: patients, bodily functions, parameters, management, optimization. Only keep the relationships that state facts, represent the main idea in the text, or other important relationships that are in the predefined list. It's acceptable if some entities identified in the previous step are not used. For each pair of related entities, extract the following information: - source\\_entity: name of the source entity, as identified in step 1 - target\\_entity: name of the target entity, as identified in step 1 - relationship: one relation that is in the predefined list, according to the given text - relationship\\_strength: a numeric score out of 10 indicating the strength of the relationship between the source entity and target entity Format each relationship as ('relationship'&lt;|&gt;&lt;source\\_entity&gt;&lt;|&gt;&lt;target\\_entity&gt;&lt;|&gt;&lt;relationship\\_description&gt;&lt;|&gt; &lt;relationship\\_strength&gt;) 3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use ## as the list delimiter. 4. When finished, output &lt;|COMPLETE|&gt; - Constraints and Guidelines - Strict Textual Grounding: Base all extractions only on the provided medical abstract. Do not use external knowledge or make assumptions beyond what is written. - -Entity Filtering: Only extract the entities whose type is present in the provided 5 Entity Type, and only extract entities that are relevant to diabetes, its complications, and comorbidites. - Relationship Filtering: Extract only the 35 relationships as defined. Exclude all other relationships. - Delimiter Usage: Strictly adhere to the specified tuple\\_delimiter within tuples and record\\_delimiter between records. ## E2: GraphRAG Index Example ## Input: ## ###################### Entity\\_types: Organism, Anatomical Structure, Manufactured Object, Substance, Conceptual Entity Text: CMR imaging enables comprehensive detection of myocardial remodeling in patients undergoing TAVR. Regression of LV matrix volume as a surrogate for reversible diffuse myocardial fibrosis is accompanied by increase of myocardial function and recovery from heart failure. Further data are required to define the value of these parameters as therapeutic targets for optimized management of TAVR patients. ## ###################### Output: Output: ('entity'&lt;|&gt;cmr imaging&lt;|&gt;Conceptual Entity&lt;|&gt;A medical imaging technology that allows for the comprehensive detection of myocardial remodeling.) ## ('entity'&lt;|&gt;myocardial remodeling&lt;|&gt;Conceptual Entity&lt;|&gt;A pathological process involving changes in the heart muscle, observed in patients undergoing TAVR.) ## ('entity'&lt;|&gt;tavr&lt;|&gt;Conceptual Entity&lt;|&gt;Transcatheter Aortic Valve Replacement, a medical procedure undergone by patients with myocardial remodeling.) ## ('entity'&lt;|&gt;regression of LV matrix volume&lt;|&gt;Conceptual Entity&lt;|&gt;The reduction in the volume of the left ventricular matrix.) ## ('entity'&lt;|&gt;reversible diffuse myocardial fibrosis&lt;|&gt;Conceptual Entity&lt;|&gt;A condition of the heart muscle for which the regression of LV matrix volume acts as a surrogate.) ## ('entity'&lt;|&gt;myocardial function&lt;|&gt;Conceptual Entity&lt;|&gt;The physiological performance of the heart muscle.) ## ('entity'&lt;|&gt;heart failure&lt;|&gt;Conceptual Entity&lt;|&gt;A clinical condition from which recovery is observed along with the regression of LV matrix volume.) ## ('relationship'&lt;|&gt;myocardial remodeling&lt;|&gt;cmr imaging&lt;|&gt;has\\_method&lt;|&gt;9) ## ('relationship'&lt;|&gt;regression of LV matrix volume&lt;|&gt;reversible diffuse myocardial fibrosis&lt;|&gt;is\\_interpreted\\_by&lt;|&gt;9) ## ('relationship'&lt;|&gt;regression of LV matrix volume&lt;|&gt;myocardial function&lt;|&gt;associated\\_with &lt;|&gt;10) ## ('relationship'&lt;|&gt;regression of LV matrix volume&lt;|&gt;heart failure&lt;|&gt;associated\\_with&lt;|&gt;10) ## ('relationship'&lt;|&gt;tavr&lt;|&gt;myocardial remodeling&lt;|&gt;occurs\\_before&lt;|&gt;8) ## &lt;|COMPLETE|&gt; ## E3: GraphRAG Query Prompt -RoleYou are a helpful assistant responding to questions about data in the tables provided. -Data tables-{context\\_data} -GoalGenerate a response in the specified target format that answers the user's question using only the information provided in the tables. Do not use any external knowledge. If any prior knowledge conflicts with the tables, always rely on the tables as the sole source of truth. If you cannot get the answer based on the tables, just say so. Do not make anything up. Points supported by data should list their data references as follows: 'This is an example sentence supported by multiple data references [Data: &lt;dataset name&gt; (record ids); &lt;dataset name&gt; (record ids)] . ' Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add '+more' to indicate that there are more. For example: 'Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Entities (5, 7); Relationships (2, 7, 34, 46, 64, +more)] . ' where 5, 7, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record. Do not include information where the supporting evidence for it is not provided. -Target response formatResponse type: multiple paragraphs. Provide a concise answer using \\boxed{} , select only the correct letter from A, B, C, D. (e.g., \\boxed{C} ) Reference data points that support your answer using the given format (e.g., [Data: Relationships (2, 3, 4); Entities (35, 36, 37, 39, 55, +more)] ). If no relevant information from the table supports your answer, leave the reference empty (e.g., [] ). ## E4: GraphRAG Context Example ``` --Relationships-source - (relation) -> target chemotherapy - (cause_of) -> peripheral neuropathy due to and following chemotherapy chemotherapy - induced peripheral neuropathy -(due_to) -> administration of antineoplastic agent antineoplastic drugs - (associated_with) -> resistance to antineoplastic drug chemotherapy - induced peripheral neuropathies - (due_to) -> administration of antineoplastic agent hematologic malignancies - (isa) -> neoplastic disease lymphoid leukaemia - (associated_finding_of) -> history of lymphoid leukemia leukemia -(associated_finding_of) -> history of leukemia cancer -(focus_of) -> oral chemotherapy for malignant neoplasm cancer -(associated_with) -> restrictive cardiomyopathy secondary to malignancy cancer -(associated_with) -> cancer related fatigue imatinib -(plays_role) -> antineoplastic therapeutic role imatinib -(isa) -> antineoplastic agent vorinostat -(plays_role) -> antineoplastic therapeutic role nivolumab - (plays_role) -> antineoplastic therapeutic role rucaparib - (plays_role) -> antineoplastic therapeutic role ``` ``` nivolumab - (isa) -> antineoplastic agent rucaparib", "metadata": {"lang": "en"}, "entity_relation_dict": [{"Head": "diabetic cardiomyopathy", "Relation": "due_to", "Tail": "diabetes mellitus"}, {"Head": "diabetes retinopathy", "Relation": "has_finding_site", "Tail": "retinal structure"}, {"Head": "islet cell transplant", "Relation": "has_method", "Tail": "surgical transplantation"}, {"Head": "endocrine pancreas", "Relation": "finding_site_of", "Tail": "extreme insulin resistance type a"}, {"Head": "on-line hemodiafiltration", "Relation": "has_focus", "Tail": "renal failure syndrome"}, {"Head": "serum creatinine level", "Relation": "has_component", "Tail": "creatinine"}], "entity_relation_output": "[{\"Head\": \"diabetic cardiomyopathy\", \"Relation\": \"due_to\", \"Tail\": \"diabetes mellitus\"}, {\"Head\": \"diabetes retinopathy\", \"Relation\": \"has_finding_site\", \"Tail\": \"retinal structure\"}, {\"Head\": \"islet cell transplant\", \"Relation\": \"has_method\", \"Tail\": \"surgical transplantation\"}, {\"Head\": \"endocrine pancreas\", \"Relation\": \"finding_site_of\", \"Tail\": \"extreme insulin resistance type a\"}, {\"Head\": \"on-line hemodiafiltration\", \"Relation\": \"has_focus\", \"Tail\": \"renal failure syndrome\"}, {\"Head\": \"serum creatinine level\", \"Relation\": \"has_component\", \"Tail\": \"creatinine\"}]", "event_entity_dict": [{"Event": "You should only extract entities that are relevant to diabetes, its complications, and comorbidites.", "Entity": ["diabetes"]}, {"Event": "diabetic cardiomyopathy (dbcm), due_to, diabetes mellitus", "Entity": ["diabetic cardiomyopathy", "diabetes mellitus"]}, {"Event": "diabetes retinopathy, has_finding_site, retinal structure", "Entity": ["diabetes retinopathy", "retinal structure"]}, {"Event": "islet cell transplant, has_method, surgical transplantation", "Entity": ["islet cell transplant"]}, {"Event": "endocrine pancreas, finding_site_of, extreme insulin resistance type a", "Entity": ["endocrine pancreas", "extreme insulin resistance type a"]}], "event_entity_output": "[{\"Event\": \"You should only extract entities that are relevant to diabetes, its complications, and comorbidites.\", \"Entity\": [\"diabetes\"]}, {\"Event\": \"diabetic cardiomyopathy (dbcm), due_to, diabetes mellitus\", \"Entity\": [\"diabetic cardiomyopathy\", \"diabetes mellitus\"]}, {\"Event\": \"diabetes retinopathy, has_finding_site, retinal structure\", \"Entity\": [\"diabetes retinopathy\", \"retinal structure\"]}, {\"Event\": \"islet cell transplant, has_method, surgical transplantation\", \"Entity\": [\"islet cell transplant\"]}, {\"Event\": \"endocrine pancreas, finding_site_of, extreme insulin resistance type a\", \"Entity\": [\"endocrine pancreas\", \"extreme insulin resistance type a\"]}]", "event_relation_dict": [], "event_relation_output": "[]"}
